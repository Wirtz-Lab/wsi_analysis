{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Code from create_poc_dataset.ipynb:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-06-02T17:49:23.653440Z",
     "end_time": "2023-06-02T17:49:23.949996Z"
    }
   },
   "outputs": [],
   "source": [
    "### Code from create_poc_dataset.ipynb, exactly the same workflow, except that we now leave one out for test and use all the dataset for training. Note that after picking OTS_14684_6 as entirety, should pick only the tiles with compositions not in ECM, Fat, and White are chosen (from the excel sheet).\n",
    "### Main dataset, selecting all images but 1 WSI to train the US2mask segmentation model. Create the US-mask pair dataset below and create the train and test df to be used in training/inference:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def calculate_tissue_composition(mask_image, num_classes=12):\n",
    "    total_pixels = mask_image.size\n",
    "    composition = np.zeros(num_classes)\n",
    "\n",
    "    for label in range(1, num_classes + 1):\n",
    "        mask = np.array(mask_image == label, dtype=np.uint8)\n",
    "        label_pixels = np.sum(mask)\n",
    "        composition[label - 1] = label_pixels / total_pixels\n",
    "    composition = np.round(composition, 3)\n",
    "    composition_freq = (composition > 0).astype('int')\n",
    "    return composition, composition_freq\n",
    "\n",
    "\n",
    "def create_train_test_df(train_mask_src_list, train_US_src_list):\n",
    "    \"\"\"\n",
    "    Assumes train_mask_src and train_US_src split is known b/w train and test, and they must be both equal lists of the filepaths to the mask and the US images.\n",
    "    \"\"\"\n",
    "    # initialize/create empty_df with column names:\n",
    "    all_df = pd.DataFrame(columns=[\"id\", \"wsi_name\", \"image_path\", \"mask_path\", \"composition\", \"composition_freq\"])\n",
    "\n",
    "    for src_idx in tqdm(range(len(train_mask_src_list)), colour='red', desc='WSI Processed'):\n",
    "        train_df = pd.DataFrame(columns=[\"id\", \"wsi_name\", \"image_path\", \"mask_path\"])  # reinitilize every WSI\n",
    "        train_df = train_df.reindex(range(len(train_mask_src_list)))\n",
    "        train_mask_src = train_mask_src_list[src_idx]\n",
    "        train_US_src = train_US_src_list[src_idx]\n",
    "        train_masklist = [os.path.join(train_mask_src, x) for x in os.listdir(train_mask_src)]\n",
    "        train_masklist = [x for x in train_masklist if x.endswith(\".png\")]\n",
    "        train_USlist = [os.path.join(train_US_src, x) for x in os.listdir(train_US_src)]\n",
    "        train_USlist = [x for x in train_USlist if x.endswith(\".png\")]\n",
    "        if len(train_USlist) != len(train_masklist):\n",
    "            print(\"Recheck the mask and US pair, number of files in one of the pairs is not equal for {} and {}\".format(\n",
    "                train_US_src, train_mask_src))\n",
    "        id_list, wsi_name_list, image_path_list, mask_path_list = [], [], [], []  # reinitialize every new WSI\n",
    "        for img_idx in tqdm(range(len(train_masklist)), colour='red', desc=\"Masks Processed per WSI\"):\n",
    "            masksrc = train_masklist[img_idx]\n",
    "            imgsrc = train_USlist[img_idx]\n",
    "            mask_img = np.array(Image.open(masksrc))\n",
    "            composition, composition_freq = calculate_tissue_composition(mask_img)\n",
    "            id = masksrc.split(\"\\\\\")[-1].split(\".png\")[0]\n",
    "            wsi_name = masksrc.split(\"\\\\\")[-2]\n",
    "            image_path = imgsrc\n",
    "            mask_path = masksrc\n",
    "            id_list.append(id)\n",
    "            wsi_name_list.append(wsi_name)\n",
    "            image_path_list.append(image_path)\n",
    "            mask_path_list.append(mask_path)\n",
    "            composition = np.array2string(composition)\n",
    "            composition_freq = np.array2string(composition_freq)\n",
    "            train_df.loc[img_idx, \"composition\"] = composition\n",
    "            train_df.loc[img_idx, \"composition_freq\"] = composition_freq\n",
    "        train_df[\"id\"] = id_list\n",
    "        train_df[\"wsi_name\"] = wsi_name_list\n",
    "        train_df[\"image_path\"] = image_path_list\n",
    "        train_df[\"mask_path\"] = mask_path_list\n",
    "        all_df = pd.concat([all_df, train_df], axis=0)\n",
    "    return all_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "masksrc = r\"\\\\shelter\\Kyu\\unstain2mask\\masks\"\n",
    "USsrc = r\"\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_tiles\\US\"\n",
    "allmasksrc = [os.path.join(masksrc, x) for x in os.listdir(masksrc)]\n",
    "allUSsrc = [os.path.join(USsrc, x) for x in os.listdir(masksrc)]\n",
    "allUSsrc\n",
    "# # Let's just choose everything but OTS_14684_3 (that will be test data)\n",
    "del (allmasksrc[2])\n",
    "del (allUSsrc[2])\n",
    "poc_train_df = create_train_test_df(allmasksrc, allUSsrc)\n",
    "poc_train_df\n",
    "dst_src = r\"\\\\shelter\\Kyu\\unstain2mask\\main\"\n",
    "poc_train_df.to_excel(os.path.join(dst_src, \"train_df.xlsx\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# do the same for inference to create test_df:\n",
    "masksrc = r\"\\\\shelter\\Kyu\\unstain2mask\\masks\"\n",
    "USsrc = r\"\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_tiles\\US\"\n",
    "allmasksrc = [os.path.join(masksrc, x) for x in os.listdir(masksrc)]\n",
    "allUSsrc = [os.path.join(USsrc, x) for x in os.listdir(masksrc)]\n",
    "# Let's just choose OTS_14684_3!\n",
    "poc_masksrc = allmasksrc[2]\n",
    "poc_USsrc = allUSsrc[2]\n",
    "poc_test_df = create_train_test_df([poc_masksrc], [poc_USsrc])\n",
    "poc_test_df\n",
    "dst_src = r\"\\\\shelter\\Kyu\\unstain2mask\\main\"\n",
    "poc_test_df.to_excel(os.path.join(dst_src, \"test_df.xlsx\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# now edit train_df so that except for OTS_14684_3, the rest 4 of the WSIs don't sample ECM, Fat, and Whitespace tiles.\n",
    "dst_src = r\"\\\\shelter\\Kyu\\unstain2mask\\main\"\n",
    "saved_train_df_src = os.path.join(dst_src, \"train_df.xlsx\")\n",
    "saved_train_df = pd.read_excel(saved_train_df_src)\n",
    "saved_train_df\n",
    "wsi_names = np.unique(saved_train_df[\"wsi_name\"])\n",
    "wsi_names_skip = list(wsi_names[0:2]) + list(\n",
    "    wsi_names[3:5])  # leave out OTS_14684_6 (sincve we will use all tiles of OTS_14684_6)\n",
    "wsi_names_skip\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create an empty dataframe with the desired columns\n",
    "new_train_df = pd.DataFrame(columns=[\"id\", \"wsi_name\", \"image_path\", \"mask_path\", \"composition\", \"composition_freq\"])\n",
    "\n",
    "# Iterate over the rows of saved_train_df\n",
    "for idx, row in tqdm(saved_train_df.iterrows(), total=saved_train_df.shape[0]):\n",
    "    if \"OTS_14684_6\" in row[\"wsi_name\"]:\n",
    "        # Don't edit rows with wsi_name \"OTS_14684_6\", simply append them to the new dataframe\n",
    "        new_train_df = new_train_df.append(row, ignore_index=True)\n",
    "    else:\n",
    "        string_array = row[\"composition\"]\n",
    "        pattern = r'(\\d+\\.\\d+|\\d+)'  # Regular expression pattern to match floating-point numbers\n",
    "        matches = re.findall(pattern, string_array)\n",
    "        numpy_array = np.array([float(x) for x in matches])\n",
    "        if np.sum(numpy_array[9:12]) > 0.7:\n",
    "            continue\n",
    "        else:\n",
    "            new_train_df = new_train_df.append(row, ignore_index=True)\n",
    "\n",
    "new_train_df\n",
    "dst_src = r\"\\\\shelter\\Kyu\\unstain2mask\\main\"\n",
    "saved_train_df_src = os.path.join(dst_src, \"new_train_df.xlsx\")\n",
    "new_train_df.to_excel(saved_train_df_src)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trying to drop some of the whitespace tiles..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "       Unnamed: 0                  id     wsi_name   \n0               0   15969_41747xy0688  OTS_14684_1  \\\n1               1   15969_42771xy0689  OTS_14684_1   \n2               2   15969_43795xy0690  OTS_14684_1   \n3               3   15969_44819xy0691  OTS_14684_1   \n4               4   15969_45843xy0692  OTS_14684_1   \n...           ...                 ...          ...   \n14099       14099  137729_84016xy9191  OTS_14684_8   \n14100       14100  138753_84016xy9283  OTS_14684_8   \n14101       14101  139777_82992xy9374  OTS_14684_8   \n14102       14102  140801_82992xy9466  OTS_14684_8   \n14103       14103  141825_82992xy9558  OTS_14684_8   \n\n                                              image_path   \n0      \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...  \\\n1      \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n2      \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n3      \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n4      \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n...                                                  ...   \n14099  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n14100  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n14101  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n14102  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n14103  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n\n                                               mask_path   \n0      \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...  \\\n1      \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...   \n2      \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...   \n3      \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...   \n4      \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...   \n...                                                  ...   \n14099  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...   \n14100  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...   \n14101  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...   \n14102  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...   \n14103  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...   \n\n                                             composition   \n0      [0.231 0.164 0.    0.    0.005 0.    0.    0.1...  \\\n1      [0.36  0.13  0.    0.    0.007 0.    0.    0. ...   \n2      [0.193 0.156 0.    0.    0.014 0.    0.    0.2...   \n3      [0.33  0.167 0.    0.    0.02  0.    0.    0.1...   \n4      [0.334 0.39  0.    0.    0.027 0.    0.    0.1...   \n...                                                  ...   \n14099  [0.188 0.232 0.    0.004 0.01  0.    0.    0.0...   \n14100  [0.176 0.176 0.    0.063 0.001 0.    0.    0.0...   \n14101  [0.108 0.186 0.    0.069 0.01  0.    0.    0.1...   \n14102  [0.159 0.345 0.    0.    0.004 0.    0.    0.1...   \n14103  [0.12  0.141 0.    0.053 0.    0.    0.007 0.0...   \n\n                composition_freq  \n0      [1 1 0 0 1 0 0 1 0 0 0 1]  \n1      [1 1 0 0 1 0 0 0 0 0 0 1]  \n2      [1 1 0 0 1 0 0 1 0 0 0 1]  \n3      [1 1 0 0 1 0 0 1 0 1 0 1]  \n4      [1 1 0 0 1 0 0 1 1 1 0 1]  \n...                          ...  \n14099  [1 1 0 1 1 0 0 1 0 1 0 1]  \n14100  [1 1 0 1 1 0 0 1 0 1 0 1]  \n14101  [1 1 0 1 1 0 0 1 0 1 0 1]  \n14102  [1 1 0 0 1 0 0 1 0 1 0 1]  \n14103  [1 1 0 1 0 0 1 1 0 1 0 1]  \n\n[14104 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>wsi_name</th>\n      <th>image_path</th>\n      <th>mask_path</th>\n      <th>composition</th>\n      <th>composition_freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>15969_41747xy0688</td>\n      <td>OTS_14684_1</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...</td>\n      <td>[0.231 0.164 0.    0.    0.005 0.    0.    0.1...</td>\n      <td>[1 1 0 0 1 0 0 1 0 0 0 1]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>15969_42771xy0689</td>\n      <td>OTS_14684_1</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...</td>\n      <td>[0.36  0.13  0.    0.    0.007 0.    0.    0. ...</td>\n      <td>[1 1 0 0 1 0 0 0 0 0 0 1]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>15969_43795xy0690</td>\n      <td>OTS_14684_1</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...</td>\n      <td>[0.193 0.156 0.    0.    0.014 0.    0.    0.2...</td>\n      <td>[1 1 0 0 1 0 0 1 0 0 0 1]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>15969_44819xy0691</td>\n      <td>OTS_14684_1</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...</td>\n      <td>[0.33  0.167 0.    0.    0.02  0.    0.    0.1...</td>\n      <td>[1 1 0 0 1 0 0 1 0 1 0 1]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>15969_45843xy0692</td>\n      <td>OTS_14684_1</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...</td>\n      <td>[0.334 0.39  0.    0.    0.027 0.    0.    0.1...</td>\n      <td>[1 1 0 0 1 0 0 1 1 1 0 1]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14099</th>\n      <td>14099</td>\n      <td>137729_84016xy9191</td>\n      <td>OTS_14684_8</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...</td>\n      <td>[0.188 0.232 0.    0.004 0.01  0.    0.    0.0...</td>\n      <td>[1 1 0 1 1 0 0 1 0 1 0 1]</td>\n    </tr>\n    <tr>\n      <th>14100</th>\n      <td>14100</td>\n      <td>138753_84016xy9283</td>\n      <td>OTS_14684_8</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...</td>\n      <td>[0.176 0.176 0.    0.063 0.001 0.    0.    0.0...</td>\n      <td>[1 1 0 1 1 0 0 1 0 1 0 1]</td>\n    </tr>\n    <tr>\n      <th>14101</th>\n      <td>14101</td>\n      <td>139777_82992xy9374</td>\n      <td>OTS_14684_8</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...</td>\n      <td>[0.108 0.186 0.    0.069 0.01  0.    0.    0.1...</td>\n      <td>[1 1 0 1 1 0 0 1 0 1 0 1]</td>\n    </tr>\n    <tr>\n      <th>14102</th>\n      <td>14102</td>\n      <td>140801_82992xy9466</td>\n      <td>OTS_14684_8</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...</td>\n      <td>[0.159 0.345 0.    0.    0.004 0.    0.    0.1...</td>\n      <td>[1 1 0 0 1 0 0 1 0 1 0 1]</td>\n    </tr>\n    <tr>\n      <th>14103</th>\n      <td>14103</td>\n      <td>141825_82992xy9558</td>\n      <td>OTS_14684_8</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...</td>\n      <td>[0.12  0.141 0.    0.053 0.    0.    0.007 0.0...</td>\n      <td>[1 1 0 1 0 0 1 1 0 1 0 1]</td>\n    </tr>\n  </tbody>\n</table>\n<p>14104 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = r\"\\\\shelter\\Kyu\\unstain2mask\\main\"\n",
    "saved_train_df_src = os.path.join(src, \"new_train_df.xlsx\")\n",
    "saved_train_df = pd.read_excel(saved_train_df_src)\n",
    "saved_train_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T18:04:15.546530Z",
     "end_time": "2023-06-02T18:04:16.434555Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import random\n",
    "def set_seed(seed = 42):\n",
    "    np.random.seed(seed) #numpy specific random\n",
    "    random.seed(seed) # python specific random (also for albumentation augmentations)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # set a fixed value for the hash seed, for hases like dictionary\n",
    "\n",
    "set_seed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T18:04:16.438452Z",
     "end_time": "2023-06-02T18:04:16.455083Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0                  id     wsi_name   \n0              0   15969_41747xy0688  OTS_14684_1  \\\n1              1   15969_42771xy0689  OTS_14684_1   \n2              2   15969_43795xy0690  OTS_14684_1   \n3              3   15969_44819xy0691  OTS_14684_1   \n4              4   15969_45843xy0692  OTS_14684_1   \n...          ...                 ...          ...   \n6598       14099  137729_84016xy9191  OTS_14684_8   \n6599       14100  138753_84016xy9283  OTS_14684_8   \n6600       14101  139777_82992xy9374  OTS_14684_8   \n6601       14102  140801_82992xy9466  OTS_14684_8   \n6602       14103  141825_82992xy9558  OTS_14684_8   \n\n                                             image_path   \n0     \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...  \\\n1     \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n2     \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n3     \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n4     \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n...                                                 ...   \n6598  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n6599  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n6600  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n6601  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n6602  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n\n                                              mask_path   \n0     \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...  \\\n1     \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...   \n2     \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...   \n3     \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...   \n4     \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...   \n...                                                 ...   \n6598  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...   \n6599  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...   \n6600  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...   \n6601  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...   \n6602  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...   \n\n                                            composition   \n0     [0.231 0.164 0.    0.    0.005 0.    0.    0.1...  \\\n1     [0.36  0.13  0.    0.    0.007 0.    0.    0. ...   \n2     [0.193 0.156 0.    0.    0.014 0.    0.    0.2...   \n3     [0.33  0.167 0.    0.    0.02  0.    0.    0.1...   \n4     [0.334 0.39  0.    0.    0.027 0.    0.    0.1...   \n...                                                 ...   \n6598  [0.188 0.232 0.    0.004 0.01  0.    0.    0.0...   \n6599  [0.176 0.176 0.    0.063 0.001 0.    0.    0.0...   \n6600  [0.108 0.186 0.    0.069 0.01  0.    0.    0.1...   \n6601  [0.159 0.345 0.    0.    0.004 0.    0.    0.1...   \n6602  [0.12  0.141 0.    0.053 0.    0.    0.007 0.0...   \n\n               composition_freq  \n0     [1 1 0 0 1 0 0 1 0 0 0 1]  \n1     [1 1 0 0 1 0 0 0 0 0 0 1]  \n2     [1 1 0 0 1 0 0 1 0 0 0 1]  \n3     [1 1 0 0 1 0 0 1 0 1 0 1]  \n4     [1 1 0 0 1 0 0 1 1 1 0 1]  \n...                         ...  \n6598  [1 1 0 1 1 0 0 1 0 1 0 1]  \n6599  [1 1 0 1 1 0 0 1 0 1 0 1]  \n6600  [1 1 0 1 1 0 0 1 0 1 0 1]  \n6601  [1 1 0 0 1 0 0 1 0 1 0 1]  \n6602  [1 1 0 1 0 0 1 1 0 1 0 1]  \n\n[6603 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>wsi_name</th>\n      <th>image_path</th>\n      <th>mask_path</th>\n      <th>composition</th>\n      <th>composition_freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>15969_41747xy0688</td>\n      <td>OTS_14684_1</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...</td>\n      <td>[0.231 0.164 0.    0.    0.005 0.    0.    0.1...</td>\n      <td>[1 1 0 0 1 0 0 1 0 0 0 1]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>15969_42771xy0689</td>\n      <td>OTS_14684_1</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...</td>\n      <td>[0.36  0.13  0.    0.    0.007 0.    0.    0. ...</td>\n      <td>[1 1 0 0 1 0 0 0 0 0 0 1]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>15969_43795xy0690</td>\n      <td>OTS_14684_1</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...</td>\n      <td>[0.193 0.156 0.    0.    0.014 0.    0.    0.2...</td>\n      <td>[1 1 0 0 1 0 0 1 0 0 0 1]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>15969_44819xy0691</td>\n      <td>OTS_14684_1</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...</td>\n      <td>[0.33  0.167 0.    0.    0.02  0.    0.    0.1...</td>\n      <td>[1 1 0 0 1 0 0 1 0 1 0 1]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>15969_45843xy0692</td>\n      <td>OTS_14684_1</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_1\\1...</td>\n      <td>[0.334 0.39  0.    0.    0.027 0.    0.    0.1...</td>\n      <td>[1 1 0 0 1 0 0 1 1 1 0 1]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6598</th>\n      <td>14099</td>\n      <td>137729_84016xy9191</td>\n      <td>OTS_14684_8</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...</td>\n      <td>[0.188 0.232 0.    0.004 0.01  0.    0.    0.0...</td>\n      <td>[1 1 0 1 1 0 0 1 0 1 0 1]</td>\n    </tr>\n    <tr>\n      <th>6599</th>\n      <td>14100</td>\n      <td>138753_84016xy9283</td>\n      <td>OTS_14684_8</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...</td>\n      <td>[0.176 0.176 0.    0.063 0.001 0.    0.    0.0...</td>\n      <td>[1 1 0 1 1 0 0 1 0 1 0 1]</td>\n    </tr>\n    <tr>\n      <th>6600</th>\n      <td>14101</td>\n      <td>139777_82992xy9374</td>\n      <td>OTS_14684_8</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...</td>\n      <td>[0.108 0.186 0.    0.069 0.01  0.    0.    0.1...</td>\n      <td>[1 1 0 1 1 0 0 1 0 1 0 1]</td>\n    </tr>\n    <tr>\n      <th>6601</th>\n      <td>14102</td>\n      <td>140801_82992xy9466</td>\n      <td>OTS_14684_8</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...</td>\n      <td>[0.159 0.345 0.    0.    0.004 0.    0.    0.1...</td>\n      <td>[1 1 0 0 1 0 0 1 0 1 0 1]</td>\n    </tr>\n    <tr>\n      <th>6602</th>\n      <td>14103</td>\n      <td>141825_82992xy9558</td>\n      <td>OTS_14684_8</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_8\\1...</td>\n      <td>[0.12  0.141 0.    0.053 0.    0.    0.007 0.0...</td>\n      <td>[1 1 0 1 0 0 1 1 0 1 0 1]</td>\n    </tr>\n  </tbody>\n</table>\n<p>6603 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "\n",
    "new_train_df = saved_train_df.copy()\n",
    "for index, row in new_train_df.iterrows():\n",
    "    string_array = row[\"composition\"]\n",
    "    pattern = r'(\\d+\\.\\d+|\\d+)'  # Regular expression pattern to match floating-point numbers\n",
    "    matches = re.findall(pattern, string_array)\n",
    "    numpy_array = np.array([float(x) for x in matches])\n",
    "    if numpy_array[11] > 0.999:\n",
    "        # 50% chance to drop the row\n",
    "        if random.random() < 0.8:\n",
    "            new_train_df.drop(index, inplace=True)\n",
    "new_train_df.reset_index(drop=True, inplace=True)\n",
    "new_train_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T18:04:16.809710Z",
     "end_time": "2023-06-02T18:04:23.362049Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "src = r\"\\\\shelter\\Kyu\\unstain2mask\\main\"\n",
    "saved_train_df_src = os.path.join(src, \"new_train_df2.xlsx\")\n",
    "new_train_df.to_excel(saved_train_df_src)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T18:04:23.387491Z",
     "end_time": "2023-06-02T18:04:24.403087Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
