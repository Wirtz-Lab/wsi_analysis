{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:36.557191Z",
     "end_time": "2023-05-29T17:52:38.510396Z"
    }
   },
   "outputs": [],
   "source": [
    "# first import all of the packages required in this entire project:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "import seaborn as sns\n",
    "import random\n",
    "from glob import glob\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import copy\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim import lr_scheduler\n",
    "import timm\n",
    "import cv2\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "import segmentation_models_pytorch as smp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load train_df and calculate mean_std_dataset if not calculated:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0                  id     wsi_name   \n0              0   44930_16605xy0001  OTS_14684_3  \\\n1              1   44930_17629xy0002  OTS_14684_3   \n2              2   44930_18653xy0003  OTS_14684_3   \n3              3   44930_19677xy0004  OTS_14684_3   \n4              4   44930_20701xy0005  OTS_14684_3   \n...          ...                 ...          ...   \n7195        7195  142210_89309xy7197  OTS_14684_3   \n7196        7196  142210_90333xy7198  OTS_14684_3   \n7197        7197  142210_91357xy7199  OTS_14684_3   \n7198        7198  142210_92381xy7200  OTS_14684_3   \n7199        7199   98178_73949xy3957  OTS_14684_3   \n\n                                             image_path   \n0     \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...  \\\n1     \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n2     \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n3     \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n4     \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n...                                                 ...   \n7195  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n7196  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n7197  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n7198  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n7199  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n\n                                              mask_path   \n0     \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...  \\\n1     \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...   \n2     \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...   \n3     \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...   \n4     \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...   \n...                                                 ...   \n7195  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\1...   \n7196  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\1...   \n7197  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\1...   \n7198  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\1...   \n7199  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\9...   \n\n                                            composition   \n0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \\\n1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n...                                                 ...   \n7195  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n7196  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n7197  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n7198  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n7199  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n\n                                       composition_freq  \n0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n...                                                 ...  \n7195  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n7196  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n7197  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n7198  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n7199  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n\n[7200 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>wsi_name</th>\n      <th>image_path</th>\n      <th>mask_path</th>\n      <th>composition</th>\n      <th>composition_freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>44930_16605xy0001</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>44930_17629xy0002</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>44930_18653xy0003</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>44930_19677xy0004</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>44930_20701xy0005</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7195</th>\n      <td>7195</td>\n      <td>142210_89309xy7197</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\1...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>7196</th>\n      <td>7196</td>\n      <td>142210_90333xy7198</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\1...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>7197</th>\n      <td>7197</td>\n      <td>142210_91357xy7199</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\1...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>7198</th>\n      <td>7198</td>\n      <td>142210_92381xy7200</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\1...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>7199</th>\n      <td>7199</td>\n      <td>98178_73949xy3957</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\9...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>7200 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_src = r\"\\\\shelter\\Kyu\\unstain2mask\\poc\\train_df.xlsx\"\n",
    "train_df = pd.read_excel(train_df_src)\n",
    "# de-string the comp and comp_freq:\n",
    "train_df[\"composition\"] = train_df[\"composition\"].apply(lambda x: np.fromstring(x[1:-1],dtype=np.float32, sep= ' '))\n",
    "train_df[\"composition_freq\"] = train_df[\"composition_freq\"].apply(lambda x: np.fromstring(x[1:-1],dtype=np.float32, sep= ' '))\n",
    "train_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:38.510396Z",
     "end_time": "2023-05-29T17:52:39.198021Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "find_mean_std_dataset = False# if false, already found it. Turn to true if you want to find std of mean of another dataset.\n",
    "\n",
    "if find_mean_std_dataset:\n",
    "    class Unstain2StainData(Dataset):\n",
    "        def __init__(self,df,transform=None):\n",
    "            self.df = df\n",
    "            self.directory = df[\"image_path\"].tolist()\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return int(len(self.directory))\n",
    "\n",
    "        def __getitem__(self,idx):\n",
    "            path = self.directory[idx]\n",
    "            image = cv2.imread(path, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if self.transform is not None:\n",
    "                image = self.transform(image = image)['image']\n",
    "            return image\n",
    "\n",
    "    device      = torch.device('cpu')\n",
    "    num_workers = 0\n",
    "    image_size  = 384\n",
    "    batch_size  = 4\n",
    "\n",
    "    augmentations = A.Compose([A.Resize(height= image_size ,width = image_size ),\n",
    "                                       A.Normalize(mean=(0,0,0), std=(1,1,1)),\n",
    "                                       ToTensorV2()])\n",
    "\n",
    "    unstain2stain_dataset = Unstain2StainData(df = train_df, transform = augmentations)# data loader\n",
    "    image_loader = DataLoader(unstain2stain_dataset,\n",
    "                              batch_size  = batch_size,\n",
    "                              shuffle     = False,\n",
    "                              num_workers = num_workers,\n",
    "                              pin_memory  = True)\n",
    "\n",
    "    images = next(iter(image_loader))\n",
    "    print(\"Images have a tensor size of {}.\".\n",
    "          format(images.size()))\n",
    "    # placeholders\n",
    "    psum    = torch.tensor([0.0, 0.0, 0.0])\n",
    "    psum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
    "\n",
    "    # loop through images\n",
    "    for inputs in tqdm(image_loader,colour='red'):\n",
    "        psum    += inputs.sum(axis = [0, 2, 3]) # sum over axis 1\n",
    "        psum_sq += (inputs ** 2).sum(axis = [0, 2, 3]) # sum over axis 1\n",
    "\n",
    "    # pixel count\n",
    "    count = len(train_df) * image_size * image_size\n",
    "\n",
    "    # mean and std\n",
    "    total_mean = psum / count\n",
    "    total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "    total_std  = torch.sqrt(total_var)\n",
    "\n",
    "    # output\n",
    "    print('mean: ' + str(total_mean))\n",
    "    print('std:  ' + str(total_std))\n",
    "\n",
    "    #mean=[0.8989, 0.9101, 0.9236], std=[0.0377, 0.0389, 0.0389]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:39.204256Z",
     "end_time": "2023-05-29T17:52:39.219915Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# all model configs go here so that they can be changed when we want to:\n",
    "class model_config:\n",
    "    seed = 42\n",
    "    encoder_name = \"tu-efficientnetv2_m\" # from https://smp.readthedocs.io/en/latest/encoders_timm.html\n",
    "    train_batch_size = 16\n",
    "    valid_batch_size = 32\n",
    "    epochs = 5\n",
    "    learning_rate = 0.001\n",
    "    scheduler = \"CosineAnnealingLR\"\n",
    "    T_max = int(30000/train_batch_size*epochs) # for cosineannealingLR, explore different values\n",
    "    weight_decay = 1e-6 # explore different weight decay (Adam optimizer)\n",
    "    n_accumulate = 1\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    iters_to_accumulate = max(1,32//train_batch_size) # for scaling accumulated gradients\n",
    "    eta_min = 1e-5\n",
    "    model_save_directory = os.path.join(os.getcwd(),\"model\") #assuming os.getcwd is the current training script directory"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:39.219915Z",
     "end_time": "2023-05-29T17:52:39.276190Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# sets the seed of the entire notebook so results are the same every time we run for reproducibility. no randomness, everything is controlled.\n",
    "def set_seed(seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # when running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(model_config.seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:39.260557Z",
     "end_time": "2023-05-29T17:52:39.276190Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# add stratifiedkfold to df:\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "new_df_train = train_df.copy(deep=True)\n",
    "strat_kfold = StratifiedKFold(shuffle = True, random_state = 42) #use default n_split = 5, random_state for reproducibility\n",
    "composition_array = np.stack(new_df_train[\"composition\"])  # Convert composition column to a numpy array\n",
    "target_array = np.sum(composition_array, axis=1)\n",
    "est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')  # Adjust n_bins as needed\n",
    "target_array = est.fit_transform(target_array.reshape(-1, 1)).flatten().astype(int)\n",
    "\n",
    "#split on white and non-white and add a new column fold to it:\n",
    "for each_fold, (idx1,idx2) in enumerate(strat_kfold.split(X = composition_array, y = target_array)):\n",
    "    new_df_train.loc[idx2,'fold'] = int(each_fold) #create new fold column with the fold number (up to 5)\n",
    "\n",
    "new_df_train[\"fold\"] = new_df_train[\"fold\"].apply(lambda x: int(x)) # somehow doesn't turn to int, so change to int, fold from 0~4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:39.276190Z",
     "end_time": "2023-05-29T17:52:39.322924Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0                  id     wsi_name   \n0              0   44930_16605xy0001  OTS_14684_3  \\\n1              1   44930_17629xy0002  OTS_14684_3   \n2              2   44930_18653xy0003  OTS_14684_3   \n3              3   44930_19677xy0004  OTS_14684_3   \n4              4   44930_20701xy0005  OTS_14684_3   \n...          ...                 ...          ...   \n7195        7195  142210_89309xy7197  OTS_14684_3   \n7196        7196  142210_90333xy7198  OTS_14684_3   \n7197        7197  142210_91357xy7199  OTS_14684_3   \n7198        7198  142210_92381xy7200  OTS_14684_3   \n7199        7199   98178_73949xy3957  OTS_14684_3   \n\n                                             image_path   \n0     \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...  \\\n1     \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n2     \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n3     \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n4     \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n...                                                 ...   \n7195  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n7196  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n7197  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n7198  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n7199  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n\n                                              mask_path   \n0     \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...  \\\n1     \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...   \n2     \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...   \n3     \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...   \n4     \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...   \n...                                                 ...   \n7195  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\1...   \n7196  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\1...   \n7197  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\1...   \n7198  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\1...   \n7199  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\9...   \n\n                                            composition   \n0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \\\n1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n...                                                 ...   \n7195  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n7196  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n7197  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n7198  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n7199  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n\n                                       composition_freq  fold  \n0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     4  \n1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     3  \n2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     2  \n3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     1  \n4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     0  \n...                                                 ...   ...  \n7195  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     2  \n7196  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     3  \n7197  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     3  \n7198  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     3  \n7199  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     0  \n\n[7200 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>wsi_name</th>\n      <th>image_path</th>\n      <th>mask_path</th>\n      <th>composition</th>\n      <th>composition_freq</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>44930_16605xy0001</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>44930_17629xy0002</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>44930_18653xy0003</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>44930_19677xy0004</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>44930_20701xy0005</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\4...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7195</th>\n      <td>7195</td>\n      <td>142210_89309xy7197</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\1...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7196</th>\n      <td>7196</td>\n      <td>142210_90333xy7198</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\1...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7197</th>\n      <td>7197</td>\n      <td>142210_91357xy7199</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\1...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7198</th>\n      <td>7198</td>\n      <td>142210_92381xy7200</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\1...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7199</th>\n      <td>7199</td>\n      <td>98178_73949xy3957</td>\n      <td>OTS_14684_3</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_3\\9...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7200 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:39.291765Z",
     "end_time": "2023-05-29T17:52:39.322924Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "[  1.5899998   5.238       1.324       2.36        1.8030001   3.1499999\n",
      "   2.331       3.2239997   2.3339996 327.50507   271.42706   817.7072   ]\n",
      "\n",
      "Fold 1:\n",
      "[  1.0839999    6.839999     0.67499995   2.2100005    2.14\n",
      "   6.6909995    2.472        3.0980005    3.2470005  314.01602\n",
      " 283.8301     813.69354   ]\n",
      "\n",
      "Fold 2:\n",
      "[  1.1129999    8.576        0.69799995   1.78         1.7740002\n",
      "   4.311        1.555        2.0419998    3.1969998  309.63898\n",
      " 249.54204    855.7682    ]\n",
      "\n",
      "Fold 3:\n",
      "[  1.274       7.598999    0.477       1.6050003   1.401       3.5679998\n",
      "   2.4810002   3.373       2.6530004 305.5111    279.68707   830.3657   ]\n",
      "\n",
      "Fold 4:\n",
      "[  1.2839999    5.8419995    0.92099994   2.2459998    1.581\n",
      "   5.245        2.1039999    2.4509997    2.4040003  324.2182\n",
      " 253.2021     838.4972    ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, precision=8)\n",
    "fold_composition_sum = new_df_train.groupby('fold')['composition'].sum()\n",
    "for fold, composition_sum in fold_composition_sum.items():\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(composition_sum)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:39.307421Z",
     "end_time": "2023-05-29T17:52:39.322924Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "### As we can see above, while not perfect, the stratification is pretty good! We can save this dataframe as well:\n",
    "save = False\n",
    "if save:\n",
    "    new_df_train.to_excel(r\"\\\\shelter\\Kyu\\unstain2mask\\poc\\train_df_stratified.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:39.322924Z",
     "end_time": "2023-05-29T17:52:39.369688Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now define transforms:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#define transforms/image augmentation for the dataset\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(512), # try 512 x 512 random crop...cant afford to lose resolution\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomVerticalFlip(0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.8989, 0.9101, 0.9236], std=[0.0377, 0.0389, 0.0389]) #calculated above mean & std\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    " # validate at 1024 x 1024, you want to use val dataset to real world application, but maybe resize to 384 if performance is bad.\n",
    "    #transforms.Resize(384),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.8989, 0.9101, 0.9236], std=[0.0377, 0.0389, 0.0389]) #calculated above mean & std\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:39.338552Z",
     "end_time": "2023-05-29T17:52:39.416641Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# build train dataset\n",
    "class TrainDataSet(Dataset):\n",
    "    # initialize df, label, imagepath and transforms\n",
    "    def __init__(self, df, label=True, transforms = None):\n",
    "        self.df = df\n",
    "        self.label = label\n",
    "        self.imagepaths = df[\"image_path\"].tolist()\n",
    "        self.maskpaths = df[\"mask_path\"].tolist()\n",
    "        self.transforms = transforms\n",
    "    # define length, which is simply length of all imagepaths\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    # define main function to read image and label, apply transform function and return the transformed images.\n",
    "    def __getitem__(self,idx):\n",
    "        image_path = self.imagepaths[idx]\n",
    "        img = cv2.imread(image_path, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(img)\n",
    "        if self.label:\n",
    "            mask_path = self.maskpaths[idx]\n",
    "            mask = cv2.imread(mask_path)\n",
    "            mask = Image.fromarray(mask)\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(img) # apply train_transform\n",
    "            mask = self.transforms(mask) # apply train_transform\n",
    "        return image, mask # return tensors of image arrays, image should be 1024 x 1024 x 3, mask 1024 x 1024"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:39.354056Z",
     "end_time": "2023-05-29T17:52:39.416641Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# define dataloading function:\n",
    "def load_dataset(fold):\n",
    "    model_df_train = new_df_train.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "    model_df_val = new_df_train.query(\"fold==@fold\").reset_index(drop=True)\n",
    "    train_dataset = TrainDataSet(df = model_df_train, transforms = train_transform)\n",
    "    val_dataset = TrainDataSet(df = model_df_val, transforms = val_transform)\n",
    "    train_dataloader = DataLoader(dataset = train_dataset,\n",
    "        batch_size = model_config.train_batch_size, # pin_memory= true allows faster data transport from cpu to gpu\n",
    "        num_workers = 0, pin_memory = True, shuffle = True)\n",
    "    val_dataloader = DataLoader(dataset = val_dataset,\n",
    "        batch_size = model_config.valid_batch_size,\n",
    "        num_workers = 0, pin_memory = True, shuffle = True)\n",
    "    return train_dataloader, val_dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:39.369688Z",
     "end_time": "2023-05-29T17:52:39.416641Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images have a tensor size of torch.Size([16, 3, 512, 512]), and Labels have a tensor size of torch.Size([16, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader = load_dataset(fold = 0)\n",
    "image, labels = next(iter(train_dataloader))\n",
    "print(\"Images have a tensor size of {}, and Labels have a tensor size of {}\".\n",
    "      format(image.size(),labels.size()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:39.385307Z",
     "end_time": "2023-05-29T17:52:41.276194Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images have a tensor size of torch.Size([32, 3, 1024, 1024]), and Labels have a tensor size of torch.Size([32, 3, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(val_dataloader))\n",
    "print(\"Images have a tensor size of {}, and Labels have a tensor size of {}\".\n",
    "      format(images.size(),labels.size()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:41.276194Z",
     "end_time": "2023-05-29T17:52:43.573139Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now our problem is multilabel since labels are not mutually exclusive (each image can have more than one right answer, or label/classes). Therefore, we use sigmoid activation function for our logits (logits = raw output of model)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = smp.UnetPlusPlus(encoder_name=model_config.encoder_name,encoder_weights = None, activation = \"sigmoid\", in_channels=3,classes=12)\n",
    "    model.to(model_config.device) # model to gpu\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:43.573139Z",
     "end_time": "2023-05-29T17:52:43.635472Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnetPlusPlus(\n",
      "  (encoder): TimmUniversalEncoder(\n",
      "    (model): EfficientNetFeatures(\n",
      "      (conv_stem): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNormAct2d(\n",
      "        24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (drop): Identity()\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (blocks): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): ConvBnAct(\n",
      "            (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvBnAct(\n",
      "            (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): ConvBnAct(\n",
      "            (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): EdgeResidual(\n",
      "            (conv_exp): Conv2d(24, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): Identity()\n",
      "            (conv_pwl): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): EdgeResidual(\n",
      "            (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): Identity()\n",
      "            (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): EdgeResidual(\n",
      "            (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): Identity()\n",
      "            (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (3): EdgeResidual(\n",
      "            (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): Identity()\n",
      "            (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (4): EdgeResidual(\n",
      "            (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): Identity()\n",
      "            (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): EdgeResidual(\n",
      "            (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): Identity()\n",
      "            (conv_pwl): Conv2d(192, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): EdgeResidual(\n",
      "            (conv_exp): Conv2d(80, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): Identity()\n",
      "            (conv_pwl): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): EdgeResidual(\n",
      "            (conv_exp): Conv2d(80, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): Identity()\n",
      "            (conv_pwl): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (3): EdgeResidual(\n",
      "            (conv_exp): Conv2d(80, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): Identity()\n",
      "            (conv_pwl): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (4): EdgeResidual(\n",
      "            (conv_exp): Conv2d(80, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): Identity()\n",
      "            (conv_pwl): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): InvertedResidual(\n",
      "            (conv_pw): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=320, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(320, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(20, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): InvertedResidual(\n",
      "            (conv_pw): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(640, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(40, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): InvertedResidual(\n",
      "            (conv_pw): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(640, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(40, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (3): InvertedResidual(\n",
      "            (conv_pw): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(640, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(40, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (4): InvertedResidual(\n",
      "            (conv_pw): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(640, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(40, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (5): InvertedResidual(\n",
      "            (conv_pw): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(640, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(40, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (6): InvertedResidual(\n",
      "            (conv_pw): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(640, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(40, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "        (4): Sequential(\n",
      "          (0): InvertedResidual(\n",
      "            (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(960, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (3): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (4): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (5): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (6): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (7): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (8): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (9): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (10): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (11): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (12): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (13): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "        (5): Sequential(\n",
      "          (0): InvertedResidual(\n",
      "            (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1056, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1056, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (3): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (4): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (5): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (6): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (7): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (8): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (9): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (10): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (11): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (12): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (13): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (14): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (15): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (16): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (17): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "        (6): Sequential(\n",
      "          (0): InvertedResidual(\n",
      "            (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(1824, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): InvertedResidual(\n",
      "            (conv_pw): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): InvertedResidual(\n",
      "            (conv_pw): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (3): InvertedResidual(\n",
      "            (conv_pw): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (4): InvertedResidual(\n",
      "            (conv_pw): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNormAct2d(\n",
      "              3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (conv_dw): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
      "            (bn2): BatchNormAct2d(\n",
      "              3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (se): SqueezeExcite(\n",
      "              (conv_reduce): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act1): SiLU(inplace=True)\n",
      "              (conv_expand): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv_pwl): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNormAct2d(\n",
      "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): UnetPlusPlusDecoder(\n",
      "    (center): Identity()\n",
      "    (blocks): ModuleDict(\n",
      "      (x_0_0): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(688, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (x_0_1): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(416, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (x_1_1): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (x_0_2): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(272, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (x_1_2): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(176, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (x_2_2): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(128, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (x_0_3): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (x_1_3): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(120, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (x_2_3): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(96, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (x_3_3): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(72, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (x_0_4): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (segmentation_head): SegmentationHead(\n",
      "    (0): Conv2d(16, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Identity()\n",
      "    (2): Activation(\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:43.595260Z",
     "end_time": "2023-05-29T17:52:44.088626Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dice loss will measure overlap b/w predicted and GT segmentation mask and will punish inaccurate segmentations by class. Also works great for imbalanced classes, as it gives equal importance to all classes. Helps us get correct segmentation and boundaries. BCE loss is also similar, and does BCE for each class."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# both loss func utilizes N * C * H * W tensors for y_pred and y_true, which is indeed our case.\n",
    "dice_loss_func = smp.losses.DiceLoss(mode='multilabel')\n",
    "bce_loss_func = smp.losses.SoftBCEWithLogitsLoss()\n",
    "\n",
    "def loss_func(y_pred,y_true): #weighted avg of the two, maybe explore different weighting if possible?\n",
    "    return  0.5 * dice_loss_func (y_pred,y_true) + 0.5 * bce_loss_func(y_pred,y_true)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:44.090588Z",
     "end_time": "2023-05-29T17:52:44.151101Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dice coef: 2*(A intersect B)/(A+B) for stratified K-fold CV to pick out best model:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, thr=0.5, dim=(2,3), epsilon=0.001):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32) # binary tensor\n",
    "    intersection = (y_true*y_pred).sum(dim=dim) # calculate overlapping pixels b/w pred and true for height and width\n",
    "    den = y_true.sum(dim=dim) + y_pred.sum(dim=dim) # denominator, A+B along height and width\n",
    "    dice = ((2*intersection+epsilon)/(den+epsilon)).mean(dim=(1,0)) # avg over batch & channel to return scalar\n",
    "    return dice"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:44.119969Z",
     "end_time": "2023-05-29T17:52:44.151101Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training & Validation One Epoch:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "#from: https://pytorch.org/docs/stable/notes/amp_examples.html in \"working with scaled gradients\"\n",
    "def epoch_train(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train() # set mode to train\n",
    "    dataset_size = 0 #initialize\n",
    "    running_loss = 0.0 #initialize\n",
    "    scaler = GradScaler() # enable GradScaler\n",
    "    pbar = tqdm(enumerate(dataloader), total = len(dataloader), desc='Train')\n",
    "    for idx, (images, masks) in pbar:\n",
    "        images = images.to(device, dtype=torch.float) # move tensor to gpu\n",
    "        masks  = masks.to(device, dtype=torch.float) # move tensor to gpu\n",
    "        batch_size = images.size(0) # return batch size N.\n",
    "\n",
    "        with autocast(enabled=True,dtype=torch.float16): # enable autocast for forward pass\n",
    "            y_pred = model(images) # forward pass, get y_pred from input\n",
    "            loss   = loss_func(y_pred, masks) # compute losses from y_pred\n",
    "            loss   = loss / model_config.iters_to_accumulate # need to normalize since accumulating gradients\n",
    "        scaler.scale(loss).backward() # accumulates the scaled gradients\n",
    "\n",
    "        if (idx + 1) % model_config.iters_to_accumulate == 0: # scale updates should only happen at batch granularity\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update() # update scale for next iteration\n",
    "            optimizer.zero_grad() # zero the accumulated scaled gradients\n",
    "            scheduler.step() # change lr,make sure to call this after scaler.step\n",
    "\n",
    "        running_loss += (loss.item() * batch_size) # update current running loss for all images in batch\n",
    "        dataset_size += batch_size # update current datasize\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size # get current epoch average loss\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(train_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}')\n",
    "\n",
    "    torch.cuda.empty_cache() #clear gpu memory after every epoch\n",
    "    gc.collect()\n",
    "\n",
    "    return epoch_loss #return loss for this epoch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:44.135473Z",
     "end_time": "2023-05-29T17:52:44.166609Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "@torch.no_grad() # disable gradient calc for validation\n",
    "def epoch_valid(model, dataloader, device, epoch):\n",
    "    model.eval() # set mode to eval\n",
    "    dataset_size = 0 #initialize\n",
    "    running_loss = 0.0 #initialize\n",
    "    valid_score_history = [] #keep validation score\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Validation')\n",
    "    for idx, (images, masks) in pbar:\n",
    "        images  = images.to(device, dtype=torch.float)\n",
    "        masks   = masks.to(device, dtype=torch.float)\n",
    "        batch_size = images.size(0)\n",
    "        y_pred  = model(images)\n",
    "        loss    = loss_func(y_pred, masks)\n",
    "\n",
    "        running_loss += (loss.item() * batch_size) #update current running loss\n",
    "        dataset_size += batch_size #update current datasize\n",
    "        epoch_loss = running_loss / dataset_size #divide epoch loss by current datasize\n",
    "\n",
    "        y_pred = nn.Sigmoid()(y_pred) #sigmoid for multi-class\n",
    "        valid_dice = dice_coef(masks, y_pred).cpu.detach().numpy()\n",
    "        valid_score_history.append(valid_dice)\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(valid_loss=f'{epoch_loss:0.3f}',\n",
    "                        lr=f'{current_lr:0.4f}')\n",
    "    valid_score_history = np.mean(valid_score_history, axis=0)\n",
    "    torch.cuda.empty_cache() #clear gpu memory after every epoch\n",
    "    gc.collect()\n",
    "\n",
    "    return epoch_loss, valid_score_history #return loss and valid_score_history for this epoch\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:44.151101Z",
     "end_time": "2023-05-29T17:52:44.166609Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs):\n",
    "\n",
    "    start = time.time() # measure time\n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) #deepcopy\n",
    "    best_dice      = 0 # initial best score\n",
    "    best_epoch     = -1 # initial best epoch\n",
    "    history = defaultdict(list) # history defaultdict to store relevant variables\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        gc.collect()\n",
    "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
    "        train_loss = epoch_train(model, optimizer, scheduler,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           device=model_config.device, epoch=epoch)\n",
    "        valid_loss, valid_score_history = epoch_valid(model, val_dataloader,\n",
    "                                                 device=model_config.device,\n",
    "                                                 epoch=epoch)\n",
    "        valid_dice = valid_score_history\n",
    "        history['Train Loss'].append(train_loss)\n",
    "        history['Valid Loss'].append(valid_loss)\n",
    "        history['Valid Dice'].append(valid_dice)\n",
    "\n",
    "        print(f'Valid Dice: {valid_dice:0.4f}')\n",
    "\n",
    "        # if dice score improves, save the best model\n",
    "        if valid_dice >= best_dice:\n",
    "            print(f\"Valid Score Improved ({best_dice:0.4f} ---> {valid_dice:0.4f})\")\n",
    "            best_dice    = valid_dice\n",
    "            best_epoch   = epoch\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = os.path.join(model_config.model_save_directory,f\"best_epoch-{fold:02d}.pt\")\n",
    "            if not os.path.exists(model_config.model_save_directory):\n",
    "                os.makedirs(model_config.model_save_directory)\n",
    "            torch.save(model.state_dict(), PATH) #current directory (on kaggle)\n",
    "            print(\"Model Saved!\")\n",
    "\n",
    "        # save the most recent model\n",
    "        last_model_wts = copy.deepcopy(model.state_dict())\n",
    "        PATH = os.path.join(model_config.model_save_directory,f\"latest_epoch-{fold:02d}.pt\")\n",
    "        if not os.path.exists(model_config.model_save_directory):\n",
    "            os.makedirs(model_config.model_save_directory)\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "\n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60))\n",
    "    print(\"Best Dice Score: {:.4f}\".format(best_dice))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:44.166609Z",
     "end_time": "2023-05-29T17:52:44.182237Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now build model and train:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=model_config.learning_rate,\n",
    "                       weight_decay = model_config.weight_decay ) # default learning rate\n",
    "if model_config == \"CosineAnnealingLR\": # change to CosineAnnealingLR\n",
    "    scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max = model_config.T_max,\n",
    "                                               eta_min =  model_config.eta_min)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-29T17:52:44.182237Z",
     "end_time": "2023-05-29T17:52:44.744752Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Epoch 1/5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/360 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 15\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_config\u001B[38;5;241m.\u001B[39mscheduler \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCosineAnnealingLR\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;66;03m# change to CosineAnnealingLR\u001B[39;00m\n\u001B[0;32m     11\u001B[0m     scheduler \u001B[38;5;241m=\u001B[39m lr_scheduler\u001B[38;5;241m.\u001B[39mCosineAnnealingLR(optimizer,\n\u001B[0;32m     12\u001B[0m                                                T_max \u001B[38;5;241m=\u001B[39m model_config\u001B[38;5;241m.\u001B[39mT_max,\n\u001B[0;32m     13\u001B[0m                                                eta_min \u001B[38;5;241m=\u001B[39m  model_config\u001B[38;5;241m.\u001B[39meta_min)\n\u001B[1;32m---> 15\u001B[0m model, history \u001B[38;5;241m=\u001B[39m \u001B[43mrun_training\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[21], line 12\u001B[0m, in \u001B[0;36mrun_training\u001B[1;34m(model, optimizer, scheduler, device, num_epochs)\u001B[0m\n\u001B[0;32m     10\u001B[0m gc\u001B[38;5;241m.\u001B[39mcollect()\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 12\u001B[0m train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mepoch_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m valid_loss, valid_score_history \u001B[38;5;241m=\u001B[39m epoch_valid(model, val_dataloader,\n\u001B[0;32m     16\u001B[0m                                          device\u001B[38;5;241m=\u001B[39mmodel_config\u001B[38;5;241m.\u001B[39mdevice,\n\u001B[0;32m     17\u001B[0m                                          epoch\u001B[38;5;241m=\u001B[39mepoch)\n\u001B[0;32m     18\u001B[0m valid_dice \u001B[38;5;241m=\u001B[39m valid_score_history\n",
      "Cell \u001B[1;32mIn[19], line 15\u001B[0m, in \u001B[0;36mepoch_train\u001B[1;34m(model, optimizer, scheduler, dataloader, device, epoch)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast(enabled\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat16): \u001B[38;5;66;03m# enable autocast for forward pass\u001B[39;00m\n\u001B[0;32m     14\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m model(images) \u001B[38;5;66;03m# forward pass, get y_pred from input\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     loss   \u001B[38;5;241m=\u001B[39m \u001B[43mloss_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmasks\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# compute losses from y_pred\u001B[39;00m\n\u001B[0;32m     16\u001B[0m     loss   \u001B[38;5;241m=\u001B[39m loss \u001B[38;5;241m/\u001B[39m model_config\u001B[38;5;241m.\u001B[39miters_to_accumulate \u001B[38;5;66;03m# need to normalize since accumulating gradients\u001B[39;00m\n\u001B[0;32m     17\u001B[0m scaler\u001B[38;5;241m.\u001B[39mscale(loss)\u001B[38;5;241m.\u001B[39mbackward() \u001B[38;5;66;03m# accumulates the scaled gradients\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[17], line 6\u001B[0m, in \u001B[0;36mloss_func\u001B[1;34m(y_pred, y_true)\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mloss_func\u001B[39m(y_pred,y_true): \u001B[38;5;66;03m#weighted avg of the two, maybe explore different weighting if possible?\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m  \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[43mdice_loss_func\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m*\u001B[39m bce_loss_func(y_pred,y_true)\n",
      "File \u001B[1;32m~\\PycharmProjects\\wsi_analysis\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\PycharmProjects\\wsi_analysis\\venv\\lib\\site-packages\\segmentation_models_pytorch\\losses\\dice.py:106\u001B[0m, in \u001B[0;36mDiceLoss.forward\u001B[1;34m(self, y_pred, y_true)\u001B[0m\n\u001B[0;32m    103\u001B[0m         y_pred \u001B[38;5;241m=\u001B[39m y_pred \u001B[38;5;241m*\u001B[39m mask\n\u001B[0;32m    104\u001B[0m         y_true \u001B[38;5;241m=\u001B[39m y_true \u001B[38;5;241m*\u001B[39m mask\n\u001B[1;32m--> 106\u001B[0m scores \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_true\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtype_as\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msmooth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msmooth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdims\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog_loss:\n\u001B[0;32m    109\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlog(scores\u001B[38;5;241m.\u001B[39mclamp_min(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meps))\n",
      "File \u001B[1;32m~\\PycharmProjects\\wsi_analysis\\venv\\lib\\site-packages\\segmentation_models_pytorch\\losses\\dice.py:130\u001B[0m, in \u001B[0;36mDiceLoss.compute_score\u001B[1;34m(self, output, target, smooth, eps, dims)\u001B[0m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_score\u001B[39m(\u001B[38;5;28mself\u001B[39m, output, target, smooth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m, eps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-7\u001B[39m, dims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m--> 130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msoft_dice_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msmooth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdims\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\wsi_analysis\\venv\\lib\\site-packages\\segmentation_models_pytorch\\losses\\_functional.py:179\u001B[0m, in \u001B[0;36msoft_dice_score\u001B[1;34m(output, target, smooth, eps, dims)\u001B[0m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msoft_dice_score\u001B[39m(\n\u001B[0;32m    173\u001B[0m     output: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[0;32m    174\u001B[0m     target: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    177\u001B[0m     dims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    178\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m--> 179\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m output\u001B[38;5;241m.\u001B[39msize() \u001B[38;5;241m==\u001B[39m target\u001B[38;5;241m.\u001B[39msize()\n\u001B[0;32m    180\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dims \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    181\u001B[0m         intersection \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(output \u001B[38;5;241m*\u001B[39m target, dim\u001B[38;5;241m=\u001B[39mdims)\n",
      "\u001B[1;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Run Training!\n",
    "for fold in range(5):\n",
    "    print(f'Fold: {fold}')\n",
    "    train_dataloader, valid_dataloader = load_dataset(fold = fold)\n",
    "    model     = build_model()\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           lr=model_config.learning_rate,\n",
    "                           weight_decay=model_config.weight_decay) # default learning rate\n",
    "\n",
    "    if model_config.scheduler == \"CosineAnnealingLR\": # change to CosineAnnealingLR\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                   T_max = model_config.T_max,\n",
    "                                                   eta_min =  model_config.eta_min)\n",
    "\n",
    "    model, history = run_training(model, optimizer, scheduler,\n",
    "                                  device=model_config.device,\n",
    "                                  num_epochs=model_config.epochs)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
