{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-06-03T13:57:35.125559Z",
     "end_time": "2023-06-03T13:57:41.734490Z"
    }
   },
   "outputs": [],
   "source": [
    "# first import all of the packages required in this entire project:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from glob import glob\n",
    "import copy\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim import lr_scheduler\n",
    "import cv2\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "import segmentation_models_pytorch as smp\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from torchvision.transforms import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# all model configs go here so that they can be changed when we want to:\n",
    "class model_config:\n",
    "    seed = 42\n",
    "    encoder_name = \"timm-resnest200e\" #\"efficientnet-b4\" # \"tu-efficientnetv2_m\" # from https://smp.readthedocs.io/en/latest/encoders_timm.html\n",
    "    train_batch_size = 4\n",
    "    valid_batch_size = 4\n",
    "    infer_batch_size = 4\n",
    "    epochs = 5\n",
    "    learning_rate = 0.001\n",
    "    scheduler = \"CosineAnnealingLR\"\n",
    "    T_max = int(30000/train_batch_size*epochs) # for cosineannealingLR, explore different values\n",
    "    weight_decay = 1e-6 # explore different weight decay (Adam optimizer)\n",
    "    n_accumulate = 1\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    iters_to_accumulate = max(1,32//train_batch_size) # for scaling accumulated gradients\n",
    "    eta_min = 1e-5\n",
    "    model_save_directory = os.path.join(os.getcwd(),\"model\",str(encoder_name)) #assuming os.getcwd is the current training script directory"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T13:57:41.734490Z",
     "end_time": "2023-06-03T13:57:41.766027Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# sets the seed of the entire notebook so results are the same every time we run for reproducibility. no randomness, everything is controlled.\n",
    "def set_seed(seed = 42):\n",
    "    np.random.seed(seed) #numpy specific random\n",
    "    random.seed(seed) # python specific random (also for albumentation augmentations)\n",
    "    torch.manual_seed(seed) # torch specific random\n",
    "    torch.cuda.manual_seed(seed) # cuda specific random\n",
    "    # when running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False # when deterministic = true, benchmark = False, otherwise might not be deterministic\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # set a fixed value for the hash seed, for hases like dictionary\n",
    "\n",
    "set_seed(model_config.seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-03T13:57:41.766027Z",
     "end_time": "2023-06-03T13:57:41.797075Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "val_transform = A.Compose([\n",
    " # validate at 1024 x 1024, you want to use val dataset to real world application, but maybe resize to 384 if performance is bad.\n",
    "    #A.Resize(384),\n",
    "    ToTensorV2(),\n",
    "    #A.Normalize(mean=(0.8989, 0.9101, 0.9236), std=(0.0377, 0.0389, 0.0389)) #calculated above mean & std\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T11:14:45.820948Z",
     "end_time": "2023-06-02T11:14:45.843870Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "mean = torch.tensor([0.8989, 0.9101, 0.9236])\n",
    "std = torch.tensor([0.0377, 0.0389, 0.0389])\n",
    "\n",
    "# define the normalization function\n",
    "def normalize(image):\n",
    "    image = image.float() / 255.0  # convert image to float and scale to [0, 1]\n",
    "    image = (image - mean[:, None, None]) / std[:, None, None]  # normalize each channel, where mean std is torch.Size[3,1,1] and image size is [3,512,512]\n",
    "    return image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T11:14:45.841877Z",
     "end_time": "2023-06-02T11:14:45.858821Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# build test dataset\n",
    "class TestDataSet(Dataset):\n",
    "    # initialize df, label, imagepath and transforms\n",
    "    def __init__(self, df, label=True, transforms = None):\n",
    "        self.df = df\n",
    "        self.label = label\n",
    "        self.imagepaths = df[\"image_path\"].tolist()\n",
    "        self.maskpaths = df[\"mask_path\"].tolist()\n",
    "        self.transforms = transforms\n",
    "    # define length, which is simply length of all imagepaths\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    # define main function to read image and label, apply transform function and return the transformed images.\n",
    "    def __getitem__(self,idx):\n",
    "        image_path = self.imagepaths[idx]\n",
    "        image = cv2.imread(image_path,cv2.COLOR_BGR2RGB)\n",
    "        # image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = np.array(image)\n",
    "        if self.label:\n",
    "            mask_path = self.maskpaths[idx]\n",
    "            # mask = Image.open(mask_path).convert(\"L\")\n",
    "            mask = cv2.imread(mask_path,0)\n",
    "            mask = np.array(mask)\n",
    "            mask_12ch = np.zeros((1024,1024,12), dtype=np.float32)\n",
    "            for class_idx in range(1,13):\n",
    "                class_pixels = (np.array(mask) == class_idx)\n",
    "                mask_12ch[:, :, class_idx - 1] = class_pixels.astype(np.float32)\n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(image=image,mask=mask_12ch)\n",
    "            image = transformed['image']\n",
    "            image = normalize(image)\n",
    "            mask = transformed['mask']\n",
    "            mask = torch.permute(mask,(2,0,1)) # 512 x 512 x 12 -> 12 x 512 x 512 so it becomes N x C x H x W\n",
    "        image = image.float()\n",
    "        image = F.normalize(image, mean=(0.8989, 0.9101, 0.9236), std=(0.0377, 0.0389, 0.0389))\n",
    "        return image, mask, mask_path # return tensors of image arrays, image should be 1024 x 1024 x 3, mask 1024 x 1024, image_path just a list of image paths"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T11:14:45.852841Z",
     "end_time": "2023-06-02T11:14:45.869784Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "    Unnamed: 0                   id     wsi_name   \n0         9717   96662_40856xy10748  OTS_14684_6  \\\n1         9718   96662_41880xy10749  OTS_14684_6   \n2         9719   96662_42904xy10750  OTS_14684_6   \n3         9720   96662_43928xy10751  OTS_14684_6   \n4         9840   97686_61336xy10871  OTS_14684_6   \n5         9841   97686_62360xy10872  OTS_14684_6   \n6         9942   98710_60312xy10973  OTS_14684_6   \n7        10145  100758_57240xy11176  OTS_14684_6   \n8        10136  100758_48024xy11167  OTS_14684_6   \n9         7785    77206_66456xy8816  OTS_14684_6   \n10        7790    77206_71576xy8821  OTS_14684_6   \n11        7792    77206_73624xy8823  OTS_14684_6   \n\n                                           image_path   \n0   \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...  \\\n1   \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n2   \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n3   \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n4   \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n5   \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n6   \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n7   \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n8   \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n9   \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n10  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n11  \\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...   \n\n                                            mask_path   \n0   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...  \\\n1   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...   \n2   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...   \n3   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...   \n4   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...   \n5   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...   \n6   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...   \n7   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\1...   \n8   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\1...   \n9   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\7...   \n10  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\7...   \n11  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\7...   \n\n                                          composition   \n0   [0.022 0.013 0.    0.    0.    0.    0.    0. ...  \\\n1   [0.    0.002 0.    0.001 0.    0.    0.    0. ...   \n2   [0.    0.    0.    0.    0.    0.    0.    0. ...   \n3   [0.    0.    0.    0.    0.    0.    0.    0. ...   \n4   [0.028 0.249 0.    0.    0.037 0.    0.    0.1...   \n5   [0.003 0.081 0.    0.003 0.004 0.    0.    0. ...   \n6   [0.016 0.265 0.    0.001 0.051 0.001 0.    0.2...   \n7   [0.   0.   0.   0.   0.   0.   0.   0.   0.04 ...   \n8   [0.008 0.    0.009 0.028 0.016 0.288 0.    0. ...   \n9   [0.005 0.    0.    0.    0.    0.    0.256 0. ...   \n10  [0.   0.   0.   0.   0.   0.   0.   0.   0.   ...   \n11  [0.    0.    0.    0.    0.    0.    0.    0. ...   \n\n             composition_freq  \n0   [1 1 0 0 0 0 0 0 1 1 1 1]  \n1   [0 1 0 1 0 0 0 0 0 1 1 1]  \n2   [0 0 0 0 0 0 0 0 0 1 1 1]  \n3   [0 0 0 0 0 0 0 0 0 1 0 1]  \n4   [1 1 0 0 1 0 0 1 1 1 0 1]  \n5   [1 1 0 1 1 0 0 0 0 1 0 1]  \n6   [1 1 0 1 1 1 0 1 0 1 0 1]  \n7   [0 0 0 0 0 0 0 0 1 1 0 1]  \n8   [1 0 1 1 1 1 0 0 1 1 1 1]  \n9   [1 0 0 0 0 0 1 0 1 1 1 1]  \n10  [0 0 0 0 0 0 0 0 0 1 0 1]  \n11  [0 0 0 0 0 0 0 0 0 1 0 1]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>wsi_name</th>\n      <th>image_path</th>\n      <th>mask_path</th>\n      <th>composition</th>\n      <th>composition_freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9717</td>\n      <td>96662_40856xy10748</td>\n      <td>OTS_14684_6</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...</td>\n      <td>[0.022 0.013 0.    0.    0.    0.    0.    0. ...</td>\n      <td>[1 1 0 0 0 0 0 0 1 1 1 1]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9718</td>\n      <td>96662_41880xy10749</td>\n      <td>OTS_14684_6</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...</td>\n      <td>[0.    0.002 0.    0.001 0.    0.    0.    0. ...</td>\n      <td>[0 1 0 1 0 0 0 0 0 1 1 1]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9719</td>\n      <td>96662_42904xy10750</td>\n      <td>OTS_14684_6</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...</td>\n      <td>[0.    0.    0.    0.    0.    0.    0.    0. ...</td>\n      <td>[0 0 0 0 0 0 0 0 0 1 1 1]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9720</td>\n      <td>96662_43928xy10751</td>\n      <td>OTS_14684_6</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...</td>\n      <td>[0.    0.    0.    0.    0.    0.    0.    0. ...</td>\n      <td>[0 0 0 0 0 0 0 0 0 1 0 1]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9840</td>\n      <td>97686_61336xy10871</td>\n      <td>OTS_14684_6</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...</td>\n      <td>[0.028 0.249 0.    0.    0.037 0.    0.    0.1...</td>\n      <td>[1 1 0 0 1 0 0 1 1 1 0 1]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>9841</td>\n      <td>97686_62360xy10872</td>\n      <td>OTS_14684_6</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...</td>\n      <td>[0.003 0.081 0.    0.003 0.004 0.    0.    0. ...</td>\n      <td>[1 1 0 1 1 0 0 0 0 1 0 1]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>9942</td>\n      <td>98710_60312xy10973</td>\n      <td>OTS_14684_6</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...</td>\n      <td>[0.016 0.265 0.    0.001 0.051 0.001 0.    0.2...</td>\n      <td>[1 1 0 1 1 1 0 1 0 1 0 1]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>10145</td>\n      <td>100758_57240xy11176</td>\n      <td>OTS_14684_6</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\1...</td>\n      <td>[0.   0.   0.   0.   0.   0.   0.   0.   0.04 ...</td>\n      <td>[0 0 0 0 0 0 0 0 1 1 0 1]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>10136</td>\n      <td>100758_48024xy11167</td>\n      <td>OTS_14684_6</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\1...</td>\n      <td>[0.008 0.    0.009 0.028 0.016 0.288 0.    0. ...</td>\n      <td>[1 0 1 1 1 1 0 0 1 1 1 1]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>7785</td>\n      <td>77206_66456xy8816</td>\n      <td>OTS_14684_6</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\7...</td>\n      <td>[0.005 0.    0.    0.    0.    0.    0.256 0. ...</td>\n      <td>[1 0 0 0 0 0 1 0 1 1 1 1]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>7790</td>\n      <td>77206_71576xy8821</td>\n      <td>OTS_14684_6</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\7...</td>\n      <td>[0.   0.   0.   0.   0.   0.   0.   0.   0.   ...</td>\n      <td>[0 0 0 0 0 0 0 0 0 1 0 1]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>7792</td>\n      <td>77206_73624xy8823</td>\n      <td>OTS_14684_6</td>\n      <td>\\\\shelter\\Kyu\\unstain2stain\\tiles\\registered_t...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\7...</td>\n      <td>[0.    0.    0.    0.    0.    0.    0.    0. ...</td>\n      <td>[0 0 0 0 0 0 0 0 0 1 0 1]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load test_df in from directory (includes images to run inference and ground truth mask path):\n",
    "test_df_src = r\"\\\\shelter\\Kyu\\unstain2mask\\poc\\test_df_simple.xlsx\"\n",
    "test_df = pd.read_excel(test_df_src)\n",
    "test_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T11:14:45.865800Z",
     "end_time": "2023-06-02T11:14:46.049183Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# define dataloading function:\n",
    "test_dataset = TestDataSet(df = test_df, transforms = val_transform)\n",
    "test_dataloader = DataLoader(dataset = test_dataset,\n",
    "    batch_size = model_config.infer_batch_size,\n",
    "    num_workers = 0, pin_memory = True, shuffle = True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T11:14:46.050179Z",
     "end_time": "2023-06-02T11:14:46.085063Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images have a tensor size of torch.Size([4, 3, 1024, 1024]), Masks have a tensor size of torch.Size([4, 12, 1024, 1024]), and Mask Paths have a length of 4\n"
     ]
    }
   ],
   "source": [
    "image, masks, mask_path = next(iter(test_dataloader))\n",
    "print(\"Images have a tensor size of {}, Masks have a tensor size of {}, and Mask Paths have a length of {}\".\n",
    "      format(image.size(),masks.size(), len(mask_path)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T11:14:46.065130Z",
     "end_time": "2023-06-02T11:14:48.950325Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = smp.UnetPlusPlus(encoder_name=model_config.encoder_name,encoder_weights = \"imagenet\", activation = None, in_channels=3,classes=12,decoder_use_batchnorm = True)\n",
    "    model.to(model_config.device) # model to gpu\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T11:14:48.951322Z",
     "end_time": "2023-06-02T11:14:48.972329Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, thr=0.5, dim=(2,3), epsilon=0.001):\n",
    "    \"\"\"\n",
    "    Function to calculate dice coef, both y_true and y_pred needs to be of tensor size N x 12 x 1024 x 1024 (batch size x num_classes x image height x image width).\n",
    "    \"\"\"\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32) # binary tensor\n",
    "    intersection = (y_true*y_pred).sum(dim=dim) # calculate overlapping pixels b/w pred and true for height and width\n",
    "    den = y_true.sum(dim=dim) + y_pred.sum(dim=dim) # denominator, A+B along height and width\n",
    "    dice = ((2*intersection+epsilon)/(den+epsilon)).mean(dim=(1,0)) # avg over batch & channel to return scalar\n",
    "    return dice"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T11:14:48.968307Z",
     "end_time": "2023-06-02T11:14:48.984342Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run inference, predicted mask tensor should be saved as the original mask array (take argmax along axis = 0). Dice score should be calculated b/w  return list of arrays size of batch size."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def infer(model_paths, test_loader, thr=0.5):\n",
    "    model = build_model()  #initialize the model outside the loop\n",
    "    pred_labels = []\n",
    "    mask_names = []\n",
    "    pred_labels_raw = [] # 12-channel one, returned so that dice score can be calculated after inference\n",
    "    # dice_scores = []\n",
    "    for idx, (image,masks,mask_path) in enumerate(tqdm(test_loader, total=len(test_loader), desc='Inference')):\n",
    "        y_pred_list = []\n",
    "        image = image.to(model_config.device, dtype=torch.float)\n",
    "        masks = masks.to(model_config.device, dtype=torch.float)\n",
    "        mask_names.append(mask_path)\n",
    "        # y_pred = torch.zeros((model_config.infer_batch_size,12,1024,1024), device = model_config.device)# empty N x 12 x 1024 x 1024 tensor reinitialized for every batch\n",
    "        for path in model_paths: # load five best models from each fold\n",
    "            model.load_state_dict(torch.load(path))\n",
    "            model.eval() # change model to eval stage\n",
    "            output = model(image) # output of size N x 12 x 1024 x 1024, each channel in dim=1 with 12 classes has logits of label for that specific pixel\n",
    "            output = nn.Sigmoid()(output) #make the output to 0~1 probabilities, model last layer doesn't have sigmoid in it, so this becomes probabilities\n",
    "            y_pred_list.append(output) #ensemble, append the y_preds as a list\n",
    "        y_pred = torch.stack(y_pred_list,dim=0) # stack the list along a fifth dimension\n",
    "        y_pred = torch.mean(y_pred, dim = 0)  #ensemble, average the probabilities along the 5-th dimension to make it 4d again\n",
    "        # calculate dice score before making 12-channel to 1-channel\n",
    "        # dice_score = dice_coef(masks,y_pred) # dice score should be scalar, size BS x 1\n",
    "        pred_labels_raw.append(y_pred) # save the 12-channel pred labels\n",
    "        y_pred = torch.argmax(y_pred, dim=1) # argmax along channel axis, returns the highest probable channel for that pixel\n",
    "        y_pred = y_pred\n",
    "        pred_labels.append(y_pred) # list of arrays\n",
    "        # dice_scores.append(dice_score) # list of dice scores\n",
    "    return pred_labels_raw, pred_labels, mask_names #,dice_scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T11:14:48.983346Z",
     "end_time": "2023-06-02T11:14:49.003361Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model list are ['C:\\\\Users\\\\labadmin\\\\PycharmProjects\\\\wsi_analysis\\\\kevin\\\\unstain2mask\\\\model\\\\best_epoch-00.pt', 'C:\\\\Users\\\\labadmin\\\\PycharmProjects\\\\wsi_analysis\\\\kevin\\\\unstain2mask\\\\model\\\\best_epoch-01.pt', 'C:\\\\Users\\\\labadmin\\\\PycharmProjects\\\\wsi_analysis\\\\kevin\\\\unstain2mask\\\\model\\\\best_epoch-02.pt', 'C:\\\\Users\\\\labadmin\\\\PycharmProjects\\\\wsi_analysis\\\\kevin\\\\unstain2mask\\\\model\\\\best_epoch-03.pt', 'C:\\\\Users\\\\labadmin\\\\PycharmProjects\\\\wsi_analysis\\\\kevin\\\\unstain2mask\\\\model\\\\best_epoch-04.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 3/3 [00:20<00:00,  6.69s/it]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate dice score save the array of arrays as an image at an directory :\n",
    "saved_model_path = model_config.model_save_directory\n",
    "model_paths  = glob(f'{saved_model_path}/best_epoch*.pt')\n",
    "print(\"Model list are {}\".format(model_paths))\n",
    "pred_labels_raw, pred_labels, mask_names = infer(model_paths, test_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T11:14:48.997343Z",
     "end_time": "2023-06-02T11:15:09.358698Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def convert_mask_to_binary_channel(mask_path):\n",
    "    mask = cv2.imread(mask_path,0)\n",
    "    mask = np.array(mask)\n",
    "    mask_12ch = np.zeros((1024,1024,12), dtype=np.float32)\n",
    "    for class_idx in range(1,13):\n",
    "        class_pixels = (np.array(mask) == class_idx)\n",
    "        mask_12ch[:, :, class_idx - 1] = class_pixels.astype(np.float32)\n",
    "    mask_12ch = np.transpose(mask_12ch,(2,0,1))\n",
    "    mask_12ch = np.expand_dims(mask_12ch,axis=0)\n",
    "    return mask_12ch # needs to be 1 x 12 x 1024 x 1024 (1 x num_classes x H x W)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T11:15:09.361688Z",
     "end_time": "2023-06-02T11:15:09.375683Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def save_inference_results(pred_labels_raw, pred_labels, mask_names, save_dst_pth):\n",
    "    results_df = pd.DataFrame(columns=[\"dice_score\",\"inference_mask_save_path\",\"true_mask_path\"])\n",
    "    pred_labels_raw_numpy = [x.cpu().detach().numpy() for x in pred_labels_raw]\n",
    "    pred_labels_numpy = [x.cpu().detach().numpy() for x in pred_labels] # list of pred_labels\n",
    "    mask_names_numpy = [x for x in mask_names]\n",
    "    dice_scores = []\n",
    "    true_mask_names = []\n",
    "    inference_save_paths = []\n",
    "    for num_batch_idx in range(int(test_df.shape[0]/model_config.infer_batch_size)):# length of test_df must be divisible by infer_batch_size\n",
    "        batches_pred_labels_raw = pred_labels_raw_numpy[num_batch_idx]\n",
    "        batches_pred_labels = pred_labels_numpy[num_batch_idx]\n",
    "        batches_mask_names = mask_names_numpy[num_batch_idx]\n",
    "        for batch_idx in range(model_config.infer_batch_size):\n",
    "            each_pred_labels_raw = batches_pred_labels_raw[batch_idx] # 12 x 1024 x 1024\n",
    "            each_pred_labels_raw = np.expand_dims(each_pred_labels_raw,axis=0) # 1 x 12 x 1024 x 1024 for dice score\n",
    "            each_pred_label = batches_pred_labels[batch_idx]\n",
    "            each_pred_label = each_pred_label.astype('uint8')\n",
    "            each_mask_name =  batches_mask_names[batch_idx]\n",
    "            true_mask_names.append(each_mask_name)\n",
    "            each_mask_ext = os.path.basename(each_mask_name) #get only name to save!\n",
    "            y_true = convert_mask_to_binary_channel(each_mask_name)\n",
    "            y_true = torch.from_numpy(y_true)\n",
    "            each_pred_labels_raw =torch.from_numpy(each_pred_labels_raw)\n",
    "            dice_score = dice_coef(y_true,each_pred_labels_raw)\n",
    "            dice_score = dice_score.cpu().detach().numpy()\n",
    "            dice_scores.append(dice_score)\n",
    "            img_save_pth = os.path.join(save_dst_pth,each_mask_ext)\n",
    "            inference_save_paths.append(img_save_pth)\n",
    "            Image.fromarray(each_pred_label).save(img_save_pth)\n",
    "    results_df[\"dice_score\"] = dice_scores\n",
    "    results_df[\"inference_mask_save_path\"] = inference_save_paths\n",
    "    results_df[\"true_mask_path\"] = true_mask_names\n",
    "    return results_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T11:15:09.376711Z",
     "end_time": "2023-06-02T11:15:09.388728Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "results_df = save_inference_results(pred_labels_raw,pred_labels,mask_names,r\"\\\\shelter\\Kyu\\unstain2mask\\poc\\inference\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T11:15:09.388728Z",
     "end_time": "2023-06-02T11:15:12.003505Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "    dice_score                           inference_mask_save_path   \n0    0.9176604  \\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\77206...  \\\n1   0.58198065  \\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\97686...   \n2   0.39867222  \\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\96662...   \n3   0.39801082  \\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\98710...   \n4    0.8135999  \\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\10075...   \n5    0.8182497  \\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\96662...   \n6    0.9150188  \\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\96662...   \n7   0.31506363  \\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\10075...   \n8   0.40508533  \\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\97686...   \n9    0.5547165  \\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\77206...   \n10  0.62500393  \\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\96662...   \n11  0.91358167  \\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\77206...   \n\n                                       true_mask_path  \n0   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\7...  \n1   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...  \n2   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...  \n3   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...  \n4   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\1...  \n5   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...  \n6   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...  \n7   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\1...  \n8   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...  \n9   \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\7...  \n10  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...  \n11  \\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\7...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dice_score</th>\n      <th>inference_mask_save_path</th>\n      <th>true_mask_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.9176604</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\77206...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\7...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.58198065</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\97686...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.39867222</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\96662...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.39801082</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\98710...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.8135999</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\10075...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\1...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.8182497</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\96662...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.9150188</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\96662...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.31506363</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\10075...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\1...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.40508533</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\97686...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.5547165</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\77206...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\7...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.62500393</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\96662...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\9...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.91358167</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\poc\\inference\\77206...</td>\n      <td>\\\\shelter\\Kyu\\unstain2mask\\masks\\OTS_14684_6\\7...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T11:15:12.000511Z",
     "end_time": "2023-06-02T11:15:12.017430Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "save_src = r\"\\\\shelter\\Kyu\\unstain2mask\\poc\\results_df.xlsx\"\n",
    "results_df.to_excel(save_src)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-02T11:15:33.866805Z",
     "end_time": "2023-06-02T11:15:33.912652Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
