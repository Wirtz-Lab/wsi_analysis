{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load all required packages:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import openslide\n",
    "import os\n",
    "import cv2\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2,40).__str__()\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import skimage.measure\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import torchvision.transforms as transforms\n",
    "from glob import glob\n",
    "from time import time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Workflow for only ROI (no multiclass labels): Just for reference, probably won't be used (so commented out)\n",
    "# Parse XML annotation file with X,Y coordinates and instance ID into a DataFrame (only for ROI):\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# # First, input xml_filepath and output a dataframe of X,Y coordinates in general. (can be used for ROI as well)\n",
    "# def xml_to_df(xml_filepath):\n",
    "#     tree = ET.parse(xml_filepath)\n",
    "#     root = tree.getroot()\n",
    "#     append_df = []\n",
    "#     for index, Annotation in enumerate(root.iter(\"Annotation\")):\n",
    "#         for Region in Annotation.iter('Region'):\n",
    "#             x = np.array([Vertex.get('X') for Vertex in Region.iter('Vertex')])\n",
    "#             y = np.array([Vertex.get('Y') for Vertex in Region.iter('Vertex')])\n",
    "#             id = np.array([int(Region.get('Id'))])\n",
    "#             classnames = index + 1\n",
    "#             coord_dict = {\"ClassNames\": [classnames], \"X\": [x], \"Y\": [y], \"ID\": [id]}\n",
    "#             df = pd.DataFrame(data = coord_dict)\n",
    "#             df.ID = df.ID.astype(int)\n",
    "#             append_df.append(df)\n",
    "#     coord_df = pd.concat(append_df).reset_index(drop=True)\n",
    "#     return(coord_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Example:\n",
    "# coord_df = xml_to_df(r'\\\\fatherserverdw\\kyuex\\clue images\\annotations\\roi\\2022-06-07 13.18.40.xml')\n",
    "# coord_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert X,Y Coordinates to Binary Mask and Read and Resize Image (only for ROI):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# def df_to_image_mask(xml_filepath, ndpi_filepath,downsample_factor):\n",
    "#     coord_df = xml_to_df(xml_filepath)\n",
    "#     slide = openslide.open_slide(ndpi_filepath)\n",
    "#     rgb_dim = slide.dimensions\n",
    "#     print(\"Dimension of level 0 of the image is: \",rgb_dim)\n",
    "#     slide_level_dim = slide.level_dimensions\n",
    "#     num_levels = len(slide_level_dim)\n",
    "#     print(\"Number of levels in this image are:\",num_levels)\n",
    "#     factors = slide.level_downsamples\n",
    "#     print(\"Each level is downsampled by:\",factors)\n",
    "#     blank = np.zeros(rgb_dim, dtype = np.uint8) #white\n",
    "#     for idx, row in coord_df.iterrows():\n",
    "#         xx = row.X.astype('int')\n",
    "#         yy = row.Y.astype('int')\n",
    "#         xy = list(zip(xx,yy))\n",
    "#         contours = np.array(xy)\n",
    "#         mask = cv2.fillPoly(blank, pts=[contours.astype(int)], color=idx+125)\n",
    "#     target_level = slide.get_best_level_for_downsample(downsample_factor)\n",
    "#     target_dim = slide.level_dimensions[target_level]\n",
    "#     rsf = [x/y for x,y in zip(rgb_dim,target_dim)]\n",
    "#     image_resized = slide.read_region(location=(0,0),level=target_level,size=target_dim)\n",
    "#     mask_resized = cv2.resize(mask,[_//round(rsf[0]) for _ in mask.shape],interpolation=cv2.INTER_NEAREST)\n",
    "#     #cv2.imwrite(r\"\\\\fatherserverdw\\Kevin\\\\binarymask.jpg\",mask_resized) #save binary mask\n",
    "#     return image_resized,mask_resized"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cropping RGB Image with Mask (only for ROI):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Example:\n",
    "# image,mask = df_to_image_mask(r'\\\\fatherserverdw\\kyuex\\clue images\\annotations\\roi\\2022-06-07 13.18.40.xml',r'\\\\fatherserverdw\\kyuex\\clue images\\2022-06-07 13.18.40.ndpi',10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# def crop_final_mask(image,mask):\n",
    "#     imagearr = np.array(image)\n",
    "#     imagearr = imagearr[:,:,:3]\n",
    "#     maskarr = np.array(mask)\n",
    "#     maskrgb = np.repeat(maskarr[:,:,np.newaxis],3,axis=2)\n",
    "#     for tissueID in range(1,np.max(maskrgb[:])): #from first tissue id to end\n",
    "#         #masking\n",
    "#         masktmp = mask==tissueID #boolean\n",
    "#         masktmp = np.repeat(masktmp[:,:,np.newaxis],3,axis=2) #change shape to match shape of imagearr\n",
    "#         final_image = np.multiply(imagearr,masktmp)\n",
    "#         #crop\n",
    "#         [x_crop,y_crop] = np.where(final_image[:,:,0]>0)\n",
    "#         cropped_final_image = final_image[np.min(x_crop):np.max(x_crop),np.min(y_crop):np.max(y_crop)]\n",
    "#         cropped_final_image = cropped_final_image[:,:,::-1]\n",
    "#         return cropped_final_image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#Example:\n",
    "# crop_final_mask(image,mask)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Workflow for Creating Annotation & Its Respective Mask for each Annotation for a WSI Image (for multiple classes):\n",
    "1. Convert XML file path to X,Y coordinate of contours.\n",
    "2. Construct a mask with multiple annotation for the entire image, one mask with the same size of the image, with annotations # 1 to 12.\n",
    "3. Label the binary version of constructed mask from #2 with unique pixel value for each annotation circle.\n",
    "4. Iterate through the labeled binary mask to crop connected objects\n",
    "5. Use the cropped coordinates from above #4 to simulataneously crop the constructed mask and the image.\n",
    "6. Done! You now have saved all of the annotations and its respective masks of the WSI Image!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# First, input xml_filepath and output a dataframe of X,Y coordinates in general. (can be used for ROI as well)\n",
    "def xml_to_df(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    append_df = []\n",
    "    for index, Annotation in enumerate(root.iter(\"Annotation\")):\n",
    "        for Region in Annotation.iter('Region'):\n",
    "            x = np.array([Vertex.get('X') for Vertex in Region.iter('Vertex')])\n",
    "            y = np.array([Vertex.get('Y') for Vertex in Region.iter('Vertex')])\n",
    "            id = np.array([int(Region.get('Id'))])\n",
    "            classnames = index + 1\n",
    "            coord_dict = {\"ClassNames\": [classnames], \"X\": [x], \"Y\": [y], \"ID\": [id]}\n",
    "            df = pd.DataFrame(data = coord_dict)\n",
    "            df.ID = df.ID.astype(int)\n",
    "            append_df.append(df)\n",
    "    coord_df = pd.concat(append_df).reset_index(drop=True)\n",
    "    return(coord_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Then, input xml_path to use xml_to_df function to output X,Y coordinates for each annotation per class:\n",
    "def coord_to_multiclass_df(xml_path,save_pkl = False):\n",
    "    coord_df = xml_to_df(xml_path)\n",
    "    coord_df = coord_df.drop(columns = [\"ID\"])\n",
    "    dict = {\"corneum\" : 1,\"spinosum\": 2,\"hairshaft\":3,\"hairfollicle\":4,\"smoothmuscle\":5,\"oil\":6,\"sweat\":7,\"nerve\":8,\"bloodvessel\":9,\"ecm\":10,\"fat\":11,\"white\":12}\n",
    "    coord_df = coord_df.replace({\"ClassNames\": dict})\n",
    "    if save_pkl:\n",
    "        dst_pth = r'\\\\fatherserverdw\\Kevin\\coord_df.pkl'\n",
    "        coord_df.to_pickle(dst_pth) #save pkl\n",
    "    return coord_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Then input original image and the coord_df to output the mask with unique annotations (1..N, N = 12 in this case):\n",
    "def create_mask_multi_annot(xml_path, image_path, downsample_factor = 2): #choose downsample factor\n",
    "    slide = openslide.open_slide(image_path)\n",
    "    target_level = slide.get_best_level_for_downsample(downsample_factor)\n",
    "    target_dim = slide.level_dimensions[target_level]\n",
    "    rsf = [x/y for x,y in zip(slide.dimensions,target_dim)] #resize factor\n",
    "    mask = np.zeros(target_dim, dtype = np.uint8)\n",
    "    iter_order = [2,10,5,4,6,11,7,9,8,12,3,1]\n",
    "    coord_df = coord_to_multiclass_df(xml_path) #use function above\n",
    "\n",
    "    for i in iter_order:\n",
    "        coord_df_tmp = coord_df[coord_df.ClassNames == i]\n",
    "        for idx, row in coord_df_tmp.iterrows():\n",
    "            xx = row.X.astype(float).astype('int32')\n",
    "            yy = row.Y.astype(float).astype('int32')\n",
    "            contours = np.array(list(zip(xx,yy)))\n",
    "            contours = contours/rsf[0]\n",
    "            class_number = row.ClassNames\n",
    "            mask = cv2.fillPoly(mask, pts=[contours.astype(int)], color=(int(class_number)))\n",
    "    return mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# skimage method:\n",
    "# Input mask and create binary mask and then output label of connected regions:\n",
    "# def create_binary_mask_label(xml_path, image_path):\n",
    "#     mask = create_mask_multi_annot(xml_path, image_path, downsample_factor = 2)\n",
    "#     binary_mask = mask > 0\n",
    "#     binary_mask = binary_mask * 255 #255 if labeled (any class from 1 to 12), 0 if unlabeled\n",
    "#     binary_mask_label = skimage.measure.label(binary_mask,connectivity = 2) #find connected regions, marked from 0 to 128 in the original image\n",
    "#     return binary_mask_label #returns label of connected regions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# cv2 method:\n",
    "# Input mask and create binary mask and then output label of connected regions:\n",
    "def create_binary_mask_label(xml_path, image_path):\n",
    "    mask = create_mask_multi_annot(xml_path, image_path, downsample_factor = 2)\n",
    "    binary_mask = mask > 0\n",
    "    _, binary_mask_label = cv2.connectedComponents(binary_mask.astype(np.uint8))\n",
    "    return binary_mask_label #returns label of connected regions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Input label of connected regions and then output the final images and masks:\n",
    "def create_final_mask_image(xml_path, image_path, dstpath_mask, dstpath_image, downsample_factor = 2):\n",
    "    slide = openslide.open_slide(image_path)\n",
    "    target_level = slide.get_best_level_for_downsample(downsample_factor)\n",
    "    target_dim = slide.level_dimensions[target_level]\n",
    "    image = slide.read_region(location=(0,0),level=target_level,size=target_dim)\n",
    "    imagearr = np.array(image)\n",
    "    imagearr = imagearr[:,:,:3]\n",
    "    binary_mask_label = create_binary_mask_label(xml_path, image_path)\n",
    "    print(\"For image with xml path {}, total of {} connected objects\".format(xml_path,np.max(binary_mask_label)))\n",
    "    mask = create_mask_multi_annot(xml_path, image_path, downsample_factor = 2)\n",
    "    for idx,label in enumerate(range(1,np.max(binary_mask_label)+1)):\n",
    "        boo = binary_mask_label == label\n",
    "        boolabel = boo * label\n",
    "        loca = np.where(boolabel == label)\n",
    "        x = loca[0]\n",
    "        y = loca[1]\n",
    "        targetmask = mask[min(x):max(x),min(y):max(y)]\n",
    "        dstpth = dstpath_mask + str(idx)+'.png'\n",
    "        Image.fromarray(targetmask).save(dstpth)\n",
    "        targetim = imagearr[min(x):max(x),min(y):max(y),:]\n",
    "        dstpth1 = dstpath_image + str(idx)+'.png'\n",
    "        Image.fromarray(targetim).save(dstpth1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# To get the respective annotation images and masks for all xml's in the file path: \\\\fatherserverdw\\kyuex\\image\\CLUE\\3D study\\he\\c1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# first get relevant paths:\n",
    "query_src_path = r'\\\\fatherserverdw\\kyuex\\image\\CLUE\\3D study\\he\\c1'\n",
    "\n",
    "xml_complete_path = glob(os.path.join(query_src_path,'*.xml'))\n",
    "xml_files_path =  [_ for _ in os.listdir(query_src_path) if _.endswith(\".xml\")]\n",
    "xml_image_name = [x.replace('.xml','') for x in xml_files_path]\n",
    "\n",
    "# only subset wsi images that have xml files and change file path accordingly (meaning filter out images that don't have annotations):\n",
    "overlap_ndpi = [_ for _  in os.listdir(query_src_path) if (_.endswith('ndpi') and os.path.splitext(_)[0] in xml_image_name)]\n",
    "wsi_complete_path = [os.path.join(query_src_path,x) for x in overlap_ndpi]\n",
    "wsi_files_path = [os.path.basename(_) for _ in wsi_complete_path]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "['100C1.ndpi',\n '10C1.ndpi',\n '1C1.ndpi',\n '31C1.ndpi',\n '4C1.ndpi',\n '52C1.ndpi',\n '64C1.ndpi',\n '76C1.ndpi',\n '7C1.ndpi',\n '94C1.ndpi']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsi_files_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it took to create single mask/image from single annotation: 9 mins\n",
      "Time it took to create single mask/image from single annotation: 8 mins\n",
      "Time it took to create single mask/image from single annotation: 15 mins\n",
      "Time it took to create single mask/image from single annotation: 9 mins\n",
      "Time it took to create single mask/image from single annotation: 11 mins\n",
      "Time it took to create single mask/image from single annotation: 9 mins\n",
      "Time it took to create single mask/image from single annotation: 10 mins\n",
      "Time it took to create single mask/image from single annotation: 9 mins\n",
      "Time it took to create single mask/image from single annotation: 13 mins\n",
      "Time it took to create single mask/image from single annotation: 7 mins\n"
     ]
    }
   ],
   "source": [
    "# first define dstpth:\n",
    "dstpth_image = r'\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\image'\n",
    "dstpth_mask = r'\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\mask'\n",
    "\n",
    "for idx in range(len(wsi_complete_path)):\n",
    "    start = time()\n",
    "    tmp_dstpath_mask = os.path.join(dstpth_mask,xml_image_name[idx])\n",
    "    tmp_dstpath_image = os.path.join(dstpth_image,xml_image_name[idx])\n",
    "    create_final_mask_image(xml_path = xml_complete_path[idx], image_path = wsi_complete_path[idx], dstpath_mask = tmp_dstpath_mask, dstpath_image = tmp_dstpath_image, downsample_factor=2)\n",
    "    end = time()\n",
    "    print(\"Time it took to create mask/image for each wsi image: {} mins\".format(round((end-start)/60)))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Then, workflow to use the images and masks from above to create the actual masked images (make mask binary, and then multiply the image by the mask):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "image_list = r'\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\image'\n",
    "mask_list = r'\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\mask'\n",
    "complete_image_list = glob(os.path.join(image_list,'*.png'))\n",
    "complete_mask_list = glob(os.path.join(mask_list,'*.png'))\n",
    "image_names = [os.path.basename(_) for _ in complete_image_list]\n",
    "dstpth = r'\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\image_masked'\n",
    "\n",
    "for idx in range(len(complete_mask_list)):\n",
    "    tmp_img = np.array(Image.open(complete_image_list[idx]))\n",
    "    tmp_msk = np.array(Image.open(complete_mask_list[idx]))\n",
    "    tmp_binary_msk = tmp_msk > 0\n",
    "    tmp_binary_msk = np.repeat(tmp_binary_msk[:,:,np.newaxis],3,axis=2)\n",
    "    image_masked = np.multiply(tmp_img,tmp_binary_msk)\n",
    "    tmp_dstpth = os.path.join(dstpth,image_names[idx])\n",
    "    Image.fromarray(image_masked).save(tmp_dstpth)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "['100C10.png',\n '100C11.png',\n '100C110.png',\n '100C111.png',\n '100C112.png',\n '100C113.png',\n '100C12.png',\n '100C13.png',\n '100C14.png',\n '100C15.png',\n '100C16.png',\n '100C17.png',\n '100C18.png',\n '100C19.png',\n '1C10.png',\n '1C11.png',\n '1C110.png',\n '1C111.png',\n '1C112.png',\n '1C113.png',\n '1C114.png',\n '1C115.png',\n '1C116.png',\n '1C117.png',\n '1C118.png',\n '1C119.png',\n '1C12.png',\n '1C120.png',\n '1C121.png',\n '1C122.png',\n '1C123.png',\n '1C124.png',\n '1C125.png',\n '1C126.png',\n '1C127.png',\n '1C128.png',\n '1C13.png',\n '1C14.png',\n '1C15.png',\n '1C16.png',\n '1C17.png',\n '1C18.png',\n '1C19.png',\n '4C10.png',\n '4C11.png',\n '4C12.png',\n '4C13.png',\n '4C14.png',\n '52C10.png',\n '52C11.png',\n '52C12.png',\n '52C13.png',\n '52C14.png',\n '52C15.png',\n '52C16.png',\n '64C10.png',\n '64C11.png',\n '64C12.png',\n '64C13.png',\n '64C14.png',\n '64C15.png',\n '64C16.png',\n '64C17.png',\n '64C18.png',\n '76C10.png',\n '76C11.png',\n '76C12.png',\n '76C13.png',\n '76C14.png',\n '7C10.png',\n '7C11.png',\n '7C110.png',\n '7C111.png',\n '7C112.png',\n '7C113.png',\n '7C114.png',\n '7C115.png',\n '7C116.png',\n '7C117.png',\n '7C118.png',\n '7C119.png',\n '7C12.png',\n '7C120.png',\n '7C121.png',\n '7C122.png',\n '7C13.png',\n '7C14.png',\n '7C15.png',\n '7C16.png',\n '7C17.png',\n '7C18.png',\n '7C19.png',\n '94C10.png',\n '94C11.png',\n '94C12.png',\n '94C13.png',\n '94C14.png',\n '94C15.png',\n '94C16.png',\n '94C17.png']"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Then, workflow to randomly (from a gaussian distribution) place all images & masks from the output images & masks (from above workflow) on top of a 5000 x 5000 image tile to create the training/validation set for 2D skin DL model:\n",
    "It should look similar to the files in the path (example): fatherserverdw\\Q\\research\\images\\skin_aging\\deeplab_trainingset\\v11\\training\\big_tiles\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
