{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load all required packages:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import openslide\n",
    "import os\n",
    "import cv2\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2,40).__str__()\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import skimage.measure\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import torchvision.transforms as transforms\n",
    "from glob import glob\n",
    "from time import time\n",
    "from skimage.measure import label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Workflow for only ROI (no multiclass labels): Just for reference, probably won't be used (so commented out)\n",
    "# Parse XML annotation file with X,Y coordinates and instance ID into a DataFrame (only for ROI):\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# # First, input xml_filepath and output a dataframe of X,Y coordinates in general. (can be used for ROI as well)\n",
    "# def xml_to_df(xml_filepath):\n",
    "#     tree = ET.parse(xml_filepath)\n",
    "#     root = tree.getroot()\n",
    "#     append_df = []\n",
    "#     for index, Annotation in enumerate(root.iter(\"Annotation\")):\n",
    "#         for Region in Annotation.iter('Region'):\n",
    "#             x = np.array([Vertex.get('X') for Vertex in Region.iter('Vertex')])\n",
    "#             y = np.array([Vertex.get('Y') for Vertex in Region.iter('Vertex')])\n",
    "#             id = np.array([int(Region.get('Id'))])\n",
    "#             classnames = index + 1\n",
    "#             coord_dict = {\"ClassNames\": [classnames], \"X\": [x], \"Y\": [y], \"ID\": [id]}\n",
    "#             df = pd.DataFrame(data = coord_dict)\n",
    "#             df.ID = df.ID.astype(int)\n",
    "#             append_df.append(df)\n",
    "#     coord_df = pd.concat(append_df).reset_index(drop=True)\n",
    "#     return(coord_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Example:\n",
    "# coord_df = xml_to_df(r'\\\\fatherserverdw\\kyuex\\clue images\\annotations\\roi\\2022-06-07 13.18.40.xml')\n",
    "# coord_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert X,Y Coordinates to Binary Mask and Read and Resize Image (only for ROI):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# def df_to_image_mask(xml_filepath, ndpi_filepath,downsample_factor):\n",
    "#     coord_df = xml_to_df(xml_filepath)\n",
    "#     slide = openslide.open_slide(ndpi_filepath)\n",
    "#     rgb_dim = slide.dimensions\n",
    "#     print(\"Dimension of level 0 of the image is: \",rgb_dim)\n",
    "#     slide_level_dim = slide.level_dimensions\n",
    "#     num_levels = len(slide_level_dim)\n",
    "#     print(\"Number of levels in this image are:\",num_levels)\n",
    "#     factors = slide.level_downsamples\n",
    "#     print(\"Each level is downsampled by:\",factors)\n",
    "#     blank = np.zeros(rgb_dim, dtype = np.uint8) #white\n",
    "#     for idx, row in coord_df.iterrows():\n",
    "#         xx = row.X.astype('int')\n",
    "#         yy = row.Y.astype('int')\n",
    "#         xy = list(zip(xx,yy))\n",
    "#         contours = np.array(xy)\n",
    "#         mask = cv2.fillPoly(blank, pts=[contours.astype(int)], color=idx+125)\n",
    "#     target_level = slide.get_best_level_for_downsample(downsample_factor)\n",
    "#     target_dim = slide.level_dimensions[target_level]\n",
    "#     rsf = [x/y for x,y in zip(rgb_dim,target_dim)]\n",
    "#     image_resized = slide.read_region(location=(0,0),level=target_level,size=target_dim)\n",
    "#     mask_resized = cv2.resize(mask,[_//round(rsf[0]) for _ in mask.shape],interpolation=cv2.INTER_NEAREST)\n",
    "#     #cv2.imwrite(r\"\\\\fatherserverdw\\Kevin\\\\binarymask.jpg\",mask_resized) #save binary mask\n",
    "#     return image_resized,mask_resized"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cropping RGB Image with Mask (only for ROI):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Example:\n",
    "# image,mask = df_to_image_mask(r'\\\\fatherserverdw\\kyuex\\clue images\\annotations\\roi\\2022-06-07 13.18.40.xml',r'\\\\fatherserverdw\\kyuex\\clue images\\2022-06-07 13.18.40.ndpi',10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# def crop_final_mask(image,mask):\n",
    "#     imagearr = np.array(image)\n",
    "#     imagearr = imagearr[:,:,:3]\n",
    "#     maskarr = np.array(mask)\n",
    "#     maskrgb = np.repeat(maskarr[:,:,np.newaxis],3,axis=2)\n",
    "#     for tissueID in range(1,np.max(maskrgb[:])): #from first tissue id to end\n",
    "#         #masking\n",
    "#         masktmp = mask==tissueID #boolean\n",
    "#         masktmp = np.repeat(masktmp[:,:,np.newaxis],3,axis=2) #change shape to match shape of imagearr\n",
    "#         final_image = np.multiply(imagearr,masktmp)\n",
    "#         #crop\n",
    "#         [x_crop,y_crop] = np.where(final_image[:,:,0]>0)\n",
    "#         cropped_final_image = final_image[np.min(x_crop):np.max(x_crop),np.min(y_crop):np.max(y_crop)]\n",
    "#         cropped_final_image = cropped_final_image[:,:,::-1]\n",
    "#         return cropped_final_image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#Example:\n",
    "# crop_final_mask(image,mask)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Workflow for Creating Annotation & Its Respective Mask for each Annotation for a WSI Image (for multiple classes):\n",
    "1. Convert XML file path to X,Y coordinate of contours.\n",
    "2. Construct a mask with multiple annotation for the entire image, one mask with the same size of the image, with annotations # 1 to 12.\n",
    "3. Label the binary version of constructed mask from #2 with unique pixel value for each annotation circle.\n",
    "4. Iterate through the labeled binary mask to crop connected objects\n",
    "5. Use the cropped coordinates from above #4 to simulataneously crop the constructed mask and the image.\n",
    "6. Done! You now have saved all of the annotations and its respective masks of the WSI Image!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# First, input xml_filepath and output a dataframe of X,Y coordinates in general. (can be used for ROI as well)\n",
    "def xml_to_df(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    append_df = []\n",
    "    for index, Annotation in enumerate(root.iter(\"Annotation\")):\n",
    "        for Region in Annotation.iter('Region'):\n",
    "            x = np.array([Vertex.get('X') for Vertex in Region.iter('Vertex')])\n",
    "            y = np.array([Vertex.get('Y') for Vertex in Region.iter('Vertex')])\n",
    "            id = np.array([int(Region.get('Id'))])\n",
    "            classnames = index + 1\n",
    "            coord_dict = {\"ClassNames\": [classnames], \"X\": [x], \"Y\": [y], \"ID\": [id]}\n",
    "            df = pd.DataFrame(data = coord_dict)\n",
    "            df.ID = df.ID.astype(int)\n",
    "            append_df.append(df)\n",
    "    coord_df = pd.concat(append_df).reset_index(drop=True)\n",
    "    return(coord_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Then, input xml_path to use xml_to_df function to output X,Y coordinates for each annotation per class:\n",
    "def coord_to_multiclass_df(xml_path,save_pkl = False):\n",
    "    coord_df = xml_to_df(xml_path)\n",
    "    coord_df = coord_df.drop(columns = [\"ID\"])\n",
    "    dict = {\"corneum\" : 1,\"spinosum\": 2,\"hairshaft\":3,\"hairfollicle\":4,\"smoothmuscle\":5,\"oil\":6,\"sweat\":7,\"nerve\":8,\"bloodvessel\":9,\"ecm\":10,\"fat\":11,\"white\":12}\n",
    "    coord_df = coord_df.replace({\"ClassNames\": dict})\n",
    "    if save_pkl:\n",
    "        dst_pth = r'\\\\fatherserverdw\\Kevin\\coord_df.pkl'\n",
    "        coord_df.to_pickle(dst_pth) #save pkl\n",
    "    return coord_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Then input original image and the coord_df to output the mask with unique annotations (1..N, N = 12 in this case):\n",
    "def create_mask_multi_annot(xml_path, image_path, downsample_factor = 2): #choose downsample factor\n",
    "    slide = openslide.open_slide(image_path)\n",
    "    target_level = slide.get_best_level_for_downsample(downsample_factor)\n",
    "    target_dim = slide.level_dimensions[target_level]\n",
    "    rsf = [x/y for x,y in zip(slide.dimensions,target_dim)] #resize factor\n",
    "    mask = np.zeros(target_dim, dtype = np.uint8)\n",
    "    iter_order = [2,10,5,4,6,11,7,9,8,12,3,1]\n",
    "    coord_df = coord_to_multiclass_df(xml_path) #use function above\n",
    "\n",
    "    for i in iter_order:\n",
    "        coord_df_tmp = coord_df[coord_df.ClassNames == i]\n",
    "        for idx, row in coord_df_tmp.iterrows():\n",
    "            xx = row.X.astype(float).astype('int32')\n",
    "            yy = row.Y.astype(float).astype('int32')\n",
    "            contours = np.array(list(zip(xx,yy)))\n",
    "            contours = contours/rsf[0]\n",
    "            class_number = row.ClassNames\n",
    "            mask = cv2.fillPoly(mask, pts=[contours.astype(int)], color=(int(class_number)))\n",
    "    return mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# skimage method:\n",
    "# Input mask and create binary mask and then output label of connected regions:\n",
    "# def create_binary_mask_label(xml_path, image_path):\n",
    "#     mask = create_mask_multi_annot(xml_path, image_path, downsample_factor = 2)\n",
    "#     binary_mask = mask > 0\n",
    "#     binary_mask = binary_mask * 255 #255 if labeled (any class from 1 to 12), 0 if unlabeled\n",
    "#     binary_mask_label = skimage.measure.label(binary_mask,connectivity = 2) #find connected regions, marked from 0 to 128 in the original image\n",
    "#     return binary_mask_label #returns label of connected regions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# cv2 method:\n",
    "# Input mask and create binary mask and then output label of connected regions:\n",
    "def create_binary_mask_label(xml_path, image_path):\n",
    "    mask = create_mask_multi_annot(xml_path, image_path, downsample_factor = 2)\n",
    "    binary_mask = mask > 0\n",
    "    _, binary_mask_label = cv2.connectedComponents(binary_mask.astype(np.uint8))\n",
    "    return binary_mask_label #returns label of connected regions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Input label of connected regions and then output the final images and masks:\n",
    "def create_final_mask_image(xml_path, image_path, dstpath_mask, dstpath_image, downsample_factor = 2):\n",
    "    slide = openslide.open_slide(image_path)\n",
    "    target_level = slide.get_best_level_for_downsample(downsample_factor)\n",
    "    target_dim = slide.level_dimensions[target_level]\n",
    "    image = slide.read_region(location=(0,0),level=target_level,size=target_dim)\n",
    "    imagearr = np.array(image)\n",
    "    imagearr = imagearr[:,:,:3]\n",
    "    binary_mask_label = create_binary_mask_label(xml_path, image_path)\n",
    "    print(\"For image with xml path {}, total of {} connected objects\".format(xml_path,np.max(binary_mask_label)))\n",
    "    mask = create_mask_multi_annot(xml_path, image_path, downsample_factor = 2)\n",
    "    for idx,label in enumerate(range(1,np.max(binary_mask_label)+1)):\n",
    "        boo = binary_mask_label == label\n",
    "        boolabel = boo * label\n",
    "        loca = np.where(boolabel == label)\n",
    "        x = loca[0]\n",
    "        y = loca[1]\n",
    "        targetmask = mask[min(x):max(x),min(y):max(y)]\n",
    "        dstpth = dstpath_mask + str(idx)+'.png'\n",
    "        Image.fromarray(targetmask).save(dstpth)\n",
    "        targetim = imagearr[min(x):max(x),min(y):max(y),:]\n",
    "        dstpth1 = dstpath_image + str(idx)+'.png'\n",
    "        Image.fromarray(targetim).save(dstpth1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# To get the respective annotation images and masks for all xml's in the file path: \\\\fatherserverdw\\kyuex\\image\\CLUE\\3D study\\he\\c1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# # first get relevant paths:\n",
    "# query_src_path = r'\\\\fatherserverdw\\kyuex\\image\\CLUE\\3D study\\he\\c1'\n",
    "#\n",
    "# xml_complete_path = glob(os.path.join(query_src_path,'*.xml'))\n",
    "# xml_files_path =  [_ for _ in os.listdir(query_src_path) if _.endswith(\".xml\")]\n",
    "# xml_image_name = [x.replace('.xml','') for x in xml_files_path]\n",
    "#\n",
    "# # only subset wsi images that have xml files and change file path accordingly (meaning filter out images that don't have annotations):\n",
    "# overlap_ndpi = [_ for _  in os.listdir(query_src_path) if (_.endswith('ndpi') and os.path.splitext(_)[0] in xml_image_name)]\n",
    "# wsi_complete_path = [os.path.join(query_src_path,x) for x in overlap_ndpi]\n",
    "# wsi_files_path = [os.path.basename(_) for _ in wsi_complete_path]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# # first define dstpth:\n",
    "# dstpth_image = r'\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\image'\n",
    "# dstpth_mask = r'\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\mask'\n",
    "#\n",
    "# for idx in range(len(wsi_complete_path)):\n",
    "#     start = time()\n",
    "#     tmp_dstpath_mask = os.path.join(dstpth_mask,xml_image_name[idx])\n",
    "#     tmp_dstpath_image = os.path.join(dstpth_image,xml_image_name[idx])\n",
    "#     create_final_mask_image(xml_path = xml_complete_path[idx], image_path = wsi_complete_path[idx], dstpath_mask = tmp_dstpath_mask, dstpath_image = tmp_dstpath_image, downsample_factor=2)\n",
    "#     end = time()\n",
    "#     print(\"Time it took to create mask/image for each wsi image: {} mins\".format(round((end-start)/60)))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Then, workflow to use the images and masks from above to create the actual masked images (make mask binary, and then multiply the image by the mask):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def create_masked_images_masks(image_list,mask_list,dstpth):\n",
    "    complete_image_list = glob(os.path.join(image_list,'*.png'))\n",
    "    complete_mask_list = glob(os.path.join(mask_list,'*.png'))\n",
    "    image_names = [os.path.basename(_) for _ in complete_image_list]\n",
    "    for idx in range(len(complete_mask_list)):\n",
    "        tmp_img = np.array(Image.open(complete_image_list[idx]))\n",
    "        tmp_msk = np.array(Image.open(complete_mask_list[idx]))\n",
    "        tmp_binary_msk = tmp_msk > 0\n",
    "        tmp_binary_msk = np.repeat(tmp_binary_msk[:,:,np.newaxis],3,axis=2)\n",
    "        image_masked = np.multiply(tmp_img,tmp_binary_msk)\n",
    "        tmp_dstpth = os.path.join(dstpth,image_names[idx])\n",
    "        Image.fromarray(image_masked).save(tmp_dstpth)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# create_masked_images_masks(image_list = r'\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\image', mask_list = r'\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\mask', dstpth = r'\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\image_masked' )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# image_list = r'\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\image'\n",
    "# mask_list = r'\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\mask'\n",
    "# complete_image_list = glob(os.path.join(image_list,'*.png'))\n",
    "# complete_mask_list = glob(os.path.join(mask_list,'*.png'))\n",
    "# image_names = [os.path.basename(_) for _ in complete_image_list]\n",
    "# dstpth = r'\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\image_masked'\n",
    "#\n",
    "# for idx in range(len(complete_mask_list)):\n",
    "#     tmp_img = np.array(Image.open(complete_image_list[idx]))\n",
    "#     tmp_msk = np.array(Image.open(complete_mask_list[idx]))\n",
    "#     tmp_binary_msk = tmp_msk > 0\n",
    "#     tmp_binary_msk = np.repeat(tmp_binary_msk[:,:,np.newaxis],3,axis=2)\n",
    "#     image_masked = np.multiply(tmp_img,tmp_binary_msk)\n",
    "#     tmp_dstpth = os.path.join(dstpth,image_names[idx])\n",
    "#     Image.fromarray(image_masked).save(tmp_dstpth)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Then, workflow to randomly (from a gaussian distribution) place all images & masks from the output images & masks (from above workflow) on top of a 5000 x 5000 image tile to create the training/validation set for 2D skin DL model:\n",
    "It should look similar to the files in the path (example): fatherserverdw\\Q\\research\\images\\skin_aging\\deeplab_trainingset\\v11\\training\\big_tiles\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def rotate_image_cv2(mat, angle):\n",
    "    \"\"\"\n",
    "    Rotates an image (angle in degrees) and expands image to avoid cropping\n",
    "    Image has to be uint8\n",
    "    \"\"\"\n",
    "\n",
    "    height, width = mat.shape[:2] # image shape has 3 dimensions\\n\",\n",
    "    image_center = (width/2, height/2) # getRotationMatrix2D needs coordinates in reverse order (width, height) compared to shape\\n\",\n",
    "    rotation_mat = cv2.getRotationMatrix2D(image_center, angle, 1.)\n",
    "    # rotation calculates the cos and sin, taking absolutes of those.\n",
    "    abs_cos = abs(rotation_mat[0,0])\n",
    "    abs_sin = abs(rotation_mat[0,1])\n",
    "\n",
    "     # find the new width and height bounds\n",
    "    bound_w = int(height * abs_sin + width * abs_cos)\n",
    "    bound_h = int(height * abs_cos + width * abs_sin)\n",
    "\n",
    "    # subtract old image center (bringing image back to origo) and adding the new image center coordinates\n",
    "    rotation_mat[0, 2] += bound_w/2 - image_center[0]\n",
    "    rotation_mat[1, 2] += bound_h/2 - image_center[1]\n",
    "\n",
    "    # rotate image with the new bounds and translated rotation matrix\n",
    "    rotated_mat = cv2.warpAffine(mat, rotation_mat, (bound_w, bound_h),flags = cv2.INTER_NEAREST)\n",
    "    return rotated_mat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def create_mask_image_tile(query_image_path, query_mask_path, show_tile):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    query_image_path: the same path as the output of the create_masked_images_masks function, which has the final images with annotations properly cropped.\n",
    "    query_mask_path: the path for the masks of the image for query_image_path\n",
    "\n",
    "    Outputs:\n",
    "    returns image_tile and msk_tile, which are a 5000*5000 image/mask with random annotations pasted on top of another.\n",
    "\n",
    "    This function is used by the generate_train_val_data function below, this function is never used independently.\n",
    "    \"\"\"\n",
    "    image_tile = np.zeros((20480,20480))\n",
    "    image_tile = np.repeat(image_tile[:,:,np.newaxis],3,axis=2)\n",
    "    image_tile = Image.fromarray((image_tile*255).astype(np.uint8))\n",
    "\n",
    "    msk_tile = np.zeros((20480,20480)) #black msk tile\n",
    "    msk_tile = np.repeat(msk_tile[:,:,np.newaxis],3,axis=2)\n",
    "    msk_tile = Image.fromarray((msk_tile*255).astype(np.uint8))\n",
    "\n",
    "    # pick one file to work with first:\n",
    "    number_of_files = len(os.listdir(query_image_path))\n",
    "    rand_file_num = np.random.randint(1,number_of_files-1,size = number_of_files)\n",
    "    lower = 0\n",
    "    upper = 20480\n",
    "    mu = 10240\n",
    "    sigma = 5120\n",
    "    rand_coord = stats.truncnorm((lower - mu) / sigma, (upper - mu) / sigma, loc = mu, scale = sigma)\n",
    "    # plt.hist(rand_coord_pair.rvs(10000))\n",
    "    # plt.show()\n",
    "\n",
    "    rand_coord_num = number_of_files+1\n",
    "    count = 0\n",
    "\n",
    "    query_image_list = glob(os.path.join(query_image_path, '*.png'))\n",
    "    query_mask_list = glob(os.path.join(query_mask_path, '*.png'))\n",
    "\n",
    "    while count < 5000:\n",
    "        for idx in np.nditer(rand_file_num):\n",
    "            image = Image.open(query_image_list[rand_file_num[idx]])\n",
    "            msk = Image.open(query_mask_list[rand_file_num[idx]])\n",
    "            rand_coord_x = np.round(rand_coord.rvs(rand_coord_num))\n",
    "            rand_coord_x = [int(x) for x in rand_coord_x]\n",
    "            rand_coord_y = np.round(rand_coord.rvs(rand_coord_num))\n",
    "            rand_coord_y = [int(y) for y in rand_coord_y]\n",
    "            x = rand_coord_x[idx]\n",
    "            y = rand_coord_y[idx]\n",
    "            rotationangle = np.random.randint(0,360)\n",
    "            image1 = np.array(image)\n",
    "            imagerot = rotate_image_cv2(image1,rotationangle)\n",
    "            msk2 = np.array(msk)\n",
    "            maskrot = rotate_image_cv2(msk2,rotationangle)\n",
    "\n",
    "            contrast_range = np.random.uniform(low=0,high=0.1)\n",
    "            brightness_range = np.random.uniform(low = 0, high = 0.1)\n",
    "            hue_range = np.random.uniform(low = 0, high = 0.01)\n",
    "            saturation_range = np.random.uniform(low=0,high=0.1)\n",
    "            color_transform = transforms.ColorJitter(brightness=brightness_range, contrast=contrast_range, saturation=saturation_range, hue=hue_range)\n",
    "            imagerot2 = color_transform(Image.fromarray(imagerot))\n",
    "\n",
    "            # create a mask for the mask and apply it to paste:\n",
    "            maskrot3 = maskrot\n",
    "            maskrot2 = Image.fromarray(maskrot)\n",
    "            maskrot = Image.fromarray(maskrot > 0)\n",
    "            msk_tile.paste(maskrot2,(x,y), mask = maskrot)\n",
    "\n",
    "            maskrot3[maskrot3>0] = 255\n",
    "            maskrot3 = maskrot3.astype(np.uint8)\n",
    "            maskrot3 = Image.fromarray(maskrot3)\n",
    "            image_tile.paste(imagerot2,(x,y), mask=maskrot3)\n",
    "            count += 1\n",
    "    if show_tile:\n",
    "        image_tile.show()\n",
    "        msk_tile.show()\n",
    "    return image_tile, msk_tile"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def generate_train_val_data(query_image_path, query_mask_path, dst_image_path, dst_label_path, n_repeat):\n",
    "    \"\"\"\n",
    "    Same inputs as create_mask_image_tile function, with additional arguments being the correct file paths to save the masks and labels.\n",
    "    n_repeat: n_repeat = 1 creates 25 training/validation image/masks. if n_repeat = 9, you create 250 training/validation data. This is true if M and N are divided by 5.\n",
    "    \"\"\"\n",
    "    start = time()\n",
    "    for repeat_count in range(n_repeat+1):\n",
    "        image_tile, msk_tile = create_mask_image_tile(query_image_path, query_mask_path, show_tile = False)\n",
    "        image_tile = np.array(image_tile)\n",
    "        M = image_tile.shape[0]//1\n",
    "        N = image_tile.shape[1]//1\n",
    "        image_tiles_split = [image_tile[x:x+M,y:y+N] for x in range(0,image_tile.shape[0],M) for y in range(0,image_tile.shape[1],N)]\n",
    "        msk_tile = np.array(msk_tile)\n",
    "        M = msk_tile.shape[0]//1\n",
    "        N = msk_tile.shape[1]//1\n",
    "        msk_tiles_split = [msk_tile[x:x+M,y:y+N] for x in range(0,msk_tile.shape[0],M) for y in range(0,msk_tile.shape[1],N)]\n",
    "        for idx in range(len(msk_tiles_split)):\n",
    "            imgsave = image_tiles_split[idx]\n",
    "            tmp_img_pth = os.path.join(dst_image_path, str(idx+(25 * repeat_count)))\n",
    "            tmp_img_pth = tmp_img_pth + \".png\"\n",
    "            cv2.imwrite(tmp_img_pth, imgsave)\n",
    "            msksave = msk_tiles_split[idx]\n",
    "            tmp_msk_pth = os.path.join(dst_label_path, str(idx+(25 * repeat_count)))\n",
    "            tmp_msk_pth = tmp_msk_pth + \".png\"\n",
    "            cv2.imwrite(tmp_msk_pth,msksave[:,:,0])\n",
    "    end = time()\n",
    "    print(\"Total time it took to generate training/validation data is {} minutes\".format(round((end-start)/60)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time it took to generate training/validation data is 5 minutes\n",
      "Total time it took to generate training/validation data is 6 minutes\n"
     ]
    }
   ],
   "source": [
    "# generate training data:\n",
    "generate_train_val_data(query_image_path = r'\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\image_masked', query_mask_path = r'\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\mask', dst_image_path = r\"\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\training\\im\", dst_label_path = r\"\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\training\\label\", n_repeat = 1)\n",
    "\n",
    "# generate validation data:\n",
    "generate_train_val_data(query_image_path = r'\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\image_masked', query_mask_path = r'\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\mask', dst_image_path = r\"\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\validation\\im\", dst_label_path = r\"\\\\fatherserverdw\\Kevin\\kevin_train\\dataset 221122\\validation\\label\", n_repeat = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Balance the class area -> bigger pics like fat/whitespace will be pasted less than smaller pics like oil\n",
    "### Edit the functions above so that for every 10 iterations or so, check the tissue composition, and pick top 3/4 class with the lowest tissue composition and paste those images."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def return_class_composition(mask_tile):\n",
    "    mask_ra = np.array(mask_tile)\n",
    "    bool = (0<mask_ra) &  (mask_ra<12)\n",
    "    composition = mask_ra[bool]\n",
    "    hist = np.bincount(composition,)\n",
    "    hist = hist/np.sum(hist)*100\n",
    "    count_list = list(hist)\n",
    "    del(count_list[0])\n",
    "    count_list = [np.round(x,3) for x in count_list]\n",
    "    count_array = np.array(count_list)\n",
    "    return count_array"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_mask_image_tile_v2(query_image_path, query_mask_path, show_tile):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    query_image_path: the same path as the output of the create_masked_images_masks function, which has the final images with annotations properly cropped.\n",
    "    query_mask_path: the path for the masks of the image for query_image_path\n",
    "\n",
    "    Outputs:\n",
    "    returns image_tile and msk_tile, which are a 5000*5000 image/mask with random annotations pasted on top of another.\n",
    "\n",
    "    This function is used by the generate_train_val_data function below, this function is never used independently.\n",
    "    \"\"\"\n",
    "    image_tile = np.zeros((20480,20480))\n",
    "    image_tile = np.repeat(image_tile[:,:,np.newaxis],3,axis=2)\n",
    "    image_tile = Image.fromarray((image_tile*255).astype(np.uint8))\n",
    "\n",
    "    msk_tile = np.zeros((20480,20480)) #black msk tile\n",
    "    msk_tile = np.repeat(msk_tile[:,:,np.newaxis],3,axis=2)\n",
    "    msk_tile = Image.fromarray((msk_tile*255).astype(np.uint8))\n",
    "\n",
    "    # pick one file to work with first:\n",
    "    number_of_files = len(os.listdir(query_image_path))\n",
    "    rand_file_num = np.random.randint(1,number_of_files-1,size = number_of_files)\n",
    "    lower = 0\n",
    "    upper = 20480\n",
    "    mu = 10240\n",
    "    sigma = 5120\n",
    "    rand_coord = stats.truncnorm((lower - mu) / sigma, (upper - mu) / sigma, loc = mu, scale = sigma) # continuous normal distribution\n",
    "    # plt.hist(rand_coord_pair.rvs(10000))\n",
    "    # plt.show()\n",
    "\n",
    "    rand_coord_num = number_of_files+1\n",
    "    count = 0\n",
    "\n",
    "    query_image_list = glob(os.path.join(query_image_path, '*.png'))\n",
    "    query_mask_list = glob(os.path.join(query_mask_path, '*.png'))\n",
    "\n",
    "    while count < 5000:\n",
    "        for idx in np.nditer(rand_file_num): # iterate over array of rand_file_num\n",
    "            if count <= 99 :\n",
    "                image = Image.open(query_image_list[rand_file_num[idx]])\n",
    "                msk = Image.open(query_mask_list[rand_file_num[idx]])\n",
    "                rand_coord_x = np.round(rand_coord.rvs(rand_coord_num)) # sample from normal distribution\n",
    "                rand_coord_x = [int(x) for x in rand_coord_x]\n",
    "                rand_coord_y = np.round(rand_coord.rvs(rand_coord_num)) # sample from normal distribution\n",
    "                rand_coord_y = [int(y) for y in rand_coord_y]\n",
    "                x = rand_coord_x[idx]\n",
    "                y = rand_coord_y[idx]\n",
    "                rotationangle = np.random.randint(0,360)\n",
    "                image1 = np.array(image)\n",
    "                imagerot = rotate_image_cv2(image1,rotationangle)\n",
    "                msk2 = np.array(msk)\n",
    "                maskrot = rotate_image_cv2(msk2,rotationangle)\n",
    "\n",
    "                contrast_range = np.random.uniform(low=0,high=0.1)\n",
    "                brightness_range = np.random.uniform(low = 0, high = 0.1)\n",
    "                hue_range = np.random.uniform(low = 0, high = 0.01)\n",
    "                saturation_range = np.random.uniform(low=0,high=0.1)\n",
    "                color_transform = transforms.ColorJitter(brightness=brightness_range, contrast=contrast_range, saturation=saturation_range, hue=hue_range)\n",
    "                imagerot2 = color_transform(Image.fromarray(imagerot))\n",
    "\n",
    "                # create a mask for the mask and apply it to paste:\n",
    "                maskrot3 = maskrot\n",
    "                maskrot2 = Image.fromarray(maskrot)\n",
    "                maskrot = Image.fromarray(maskrot > 0)\n",
    "                msk_tile.paste(maskrot2,(x,y), mask = maskrot)\n",
    "\n",
    "                maskrot3[maskrot3>0] = 255\n",
    "                maskrot3 = maskrot3.astype(np.uint8)\n",
    "                maskrot3 = Image.fromarray(maskrot3)\n",
    "                image_tile.paste(imagerot2,(x,y), mask=maskrot3)\n",
    "                count += 1\n",
    "\n",
    "            if (count % 10 == 0) and (count > 99):\n",
    "                count_array = return_class_composition(msk_tile)\n",
    "                min_class = np.argmin(count_array)\n",
    "\n",
    "    if show_tile:\n",
    "        image_tile.show()\n",
    "        msk_tile.show()\n",
    "    return image_tile, msk_tile"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
