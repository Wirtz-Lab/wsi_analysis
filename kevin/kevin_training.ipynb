{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Parse XML annotation file with X,Y coordinates and instance ID into a DataFrame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def xml_to_df(xml_filepath):\n",
    "    append_df = []\n",
    "    tree = ET.parse(xml_filepath)\n",
    "    root = tree.getroot()\n",
    "    for Annotation in root.iter(\"Annotation\"):\n",
    "        for Region in Annotation.iter('Region'): #iterate over the Region so we can iterate over id 1 and 2 (two circles):\n",
    "            x = np.array([Vertex.get('X') for Vertex in Region.iter('Vertex')])\n",
    "            y = np.array([Vertex.get('Y') for Vertex in Region.iter('Vertex')])\n",
    "            id = np.array([Region.get('Id')])\n",
    "            coord_dict = {\"X\": [x], \"Y\": [y], \"ID\": [id]}\n",
    "            df = pd.DataFrame(data = coord_dict)\n",
    "            df.ID = df.ID.astype(int)\n",
    "            append_df.append(df)\n",
    "    coord_df = pd.concat(append_df)\n",
    "    return(coord_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   X  \\\n0  [5615, 5725, 5810, 5865, 5900, 5915, 5930, 594...   \n0  [24299, 24364, 24483, 24537, 24613, 24624, 246...   \n\n                                                   Y  ID  \n0  [10850, 10890, 10930, 10950, 10960, 10970, 109...   1  \n0  [20025, 20068, 20133, 20176, 20209, 20231, 202...   2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X</th>\n      <th>Y</th>\n      <th>ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[5615, 5725, 5810, 5865, 5900, 5915, 5930, 594...</td>\n      <td>[10850, 10890, 10930, 10950, 10960, 10970, 109...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>[24299, 24364, 24483, 24537, 24613, 24624, 246...</td>\n      <td>[20025, 20068, 20133, 20176, 20209, 20231, 202...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # for pc:\n",
    "# # src = r'\\\\fatherserverdw\\kyuex\\clue images'\n",
    "# # for mac:\n",
    "# src = r'//Volumes/kyuex/clue images'\n",
    "# xml = [_ for _ in os.listdir(src) if _.endswith('xml')]\n",
    "# xml\n",
    "\n",
    "coord_df = xml_to_df('//Volumes/kyuex/clue images/2022-06-07 13.18.40.xml')\n",
    "coord_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert X,Y Coordinates to Binary Mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[255, 255, 255, ..., 255, 255, 255],\n       [255, 255, 255, ..., 255, 255, 255],\n       [255, 255, 255, ..., 255, 255, 255],\n       ...,\n       [255, 255, 255, ..., 255, 255, 255],\n       [255, 255, 255, ..., 255, 255, 255],\n       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2,40).__str__()\n",
    "import cv2\n",
    "\n",
    "def df_to_mask(coord_df):\n",
    "    for i in np.arange(len(coord_df)):\n",
    "        xx = coord_df.iloc[i].X\n",
    "        yy = coord_df.iloc[i].Y\n",
    "        xy = list(zip(xx,yy))\n",
    "        contours = np.array(xy)\n",
    "        image = np.full((40000, 40000), 255, dtype = np.uint8) #white\n",
    "        mask = cv2.drawContours(image,[contours.astype(int)],-1,(0,255,0),10) #contourIdx = -1, draw all contours\n",
    "        #cv2.imwrite('//Volumes/Kevin/' + 'mask' + str(i) + '.jpg',mask) # save image on drive\n",
    "        return mask\n",
    "df_to_mask(coord_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cropping RGB Image with Mask:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of level 0 of the image is:  (48000, 47872)\n",
      "Number of levels in this image are: 8\n",
      "Each level is downsampled by: (1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0)\n"
     ]
    }
   ],
   "source": [
    "import openslide\n",
    "# Get basic information of the slide we have:\n",
    "slide = openslide.open_slide('//Volumes/kyuex/clue images/2022-06-07 13.18.40.ndpi')\n",
    "rgb_dim = slide.dimensions\n",
    "print(\"Dimension of level 0 of the image is: \",rgb_dim)\n",
    "slide_level_dim = slide.level_dimensions\n",
    "num_levels = len(slide_level_dim)\n",
    "print(\"Number of levels in this image are:\",num_levels)\n",
    "factors = slide.level_downsamples\n",
    "print(\"Each level is downsampled by:\",factors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of levels in this tiles object are: 17\n",
      "Dimensions of data in each level are: ((1, 1), (2, 2), (3, 3), (6, 6), (12, 12), (24, 24), (47, 47), (94, 94), (188, 187), (375, 374), (750, 748), (1500, 1496), (3000, 2992), (6000, 5984), (12000, 11968), (24000, 23936), (48000, 47872))\n",
      "Total number of tiles are: 46979\n"
     ]
    }
   ],
   "source": [
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "# get tiles now:\n",
    "tiles = DeepZoomGenerator(slide, tile_size = 256, overlap = 0, limit_bounds = False)\n",
    "# each tile has size 256 x 256 image\n",
    "print(\"Number of levels in this tiles object are:\",tiles.level_count)\n",
    "print(\"Dimensions of data in each level are:\",tiles.level_dimensions)\n",
    "print(\"Total number of tiles are:\",tiles.tile_count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tiles are: 46979\n",
      "Total number of tiles in the large image are: (2, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of tiles are:\", tiles.tile_count)\n",
    "max_tile_count_in_selected_image = tiles.level_tiles[9]\n",
    "print(\"Total number of tiles in the large image are:\", max_tile_count_in_selected_image)\n",
    "single_tile = tiles.get_tile(9,(0,0))\n",
    "single_tile_RGB = single_tile.convert('RGB')\n",
    "single_tile_RGB.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of mask is: (40000, 40000)\n",
      "Dimensions of tile is: (256, 256)\n"
     ]
    }
   ],
   "source": [
    "mask = df_to_mask(coord_df)\n",
    "print(\"Dimensions of mask is:\",mask.shape)\n",
    "single_tile_dim = tiles.get_tile_dimensions(9,(0,0))\n",
    "print(\"Dimensions of tile is:\",single_tile_dim)\n",
    "mask_x, mask_y = mask.shape\n",
    "tile_x, tile_y = single_tile_dim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(13975, 14235)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.unique(mask, return_counts = True)\n",
    "line = np.where(mask == 0)\n",
    "x1 = max(line[0])\n",
    "y1 = max(line[1])\n",
    "x1,y1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) :-1: error: (-5:Bad argument) in function 'bitwise_and'\n> Overload resolution failed:\n>  - src1 is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src1'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Input \u001B[0;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m mask_cropped \u001B[38;5;241m=\u001B[39m mask[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m14236\u001B[39m,\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m14236\u001B[39m]\n\u001B[1;32m      2\u001B[0m mask_cropped \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mresize(mask_cropped,(\u001B[38;5;241m256\u001B[39m,\u001B[38;5;241m256\u001B[39m))\n\u001B[0;32m----> 3\u001B[0m cropped_image \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbitwise_and\u001B[49m\u001B[43m(\u001B[49m\u001B[43msingle_tile_RGB\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask_cropped\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31merror\u001B[0m: OpenCV(4.5.5) :-1: error: (-5:Bad argument) in function 'bitwise_and'\n> Overload resolution failed:\n>  - src1 is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src1'\n"
     ]
    }
   ],
   "source": [
    "mask_cropped = mask[0:14236,0:14236]\n",
    "mask_cropped = cv2.resize(mask_cropped,(256,256))\n",
    "cropped_image = cv2.bitwise_and(single_tile_RGB, mask_cropped)\n",
    "# error because single_tile_RGB array is three tuples while mask is just one number"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}