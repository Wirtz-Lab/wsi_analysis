{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## The aim is to register each tissue images in the stained and unstained WSIs. To do this, we first need to crop and save each individual tissue in each WSI and save them as a png file. Then we can pad the two images together and register them by editing the registration code from image_registration.ipynb.\n",
    "## The path of the images are in: \\\\shelter\\Kyu\\unstain2stain\\biomax_images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.morphology import remove_small_objects, remove_small_holes\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import warp\n",
    "from skimage.registration import optical_flow_tvl1, optical_flow_ilk\n",
    "import openslide\n",
    "import os\n",
    "import cv2\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2,40).__str__()\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.measure\n",
    "import scipy.stats as stats\n",
    "import torchvision.transforms as transforms\n",
    "from glob import glob\n",
    "from time import time\n",
    "from skimage.measure import label, regionprops_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def _time(f):\n",
    "    \"\"\"\n",
    "    Helper function: Measures time taken for a certain function that we suspect that takes long. Simply run _time(function_name)\n",
    "    \"\"\"\n",
    "    def wrapper(*args,**kwargs):\n",
    "        start=time()\n",
    "        r=f(*args,**kwargs)\n",
    "        end=time()\n",
    "        print(\"%s timed %f\" %(f.__name__,end-start))\n",
    "        return r\n",
    "    return wrapper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def xml_to_df(xml_filepath):\n",
    "    \"\"\"\n",
    "    Helper function from xml2trainingdata.ipynb\n",
    "    input: annotation xml file\n",
    "    output: dataframe of X,Y coordinates of the contours\n",
    "    Can be used for multiclass and just simple ROI as well.\n",
    "    \"\"\"\n",
    "    tree = ET.parse(xml_filepath)\n",
    "    root = tree.getroot()\n",
    "    append_df = []\n",
    "    for index, Annotation in enumerate(root.iter(\"Annotation\")):\n",
    "        for Region in Annotation.iter('Region'):\n",
    "            x = np.array([Vertex.get('X') for Vertex in Region.iter('Vertex')])\n",
    "            y = np.array([Vertex.get('Y') for Vertex in Region.iter('Vertex')])\n",
    "            id = np.array([int(Region.get('Id'))])\n",
    "            classnames = index + 1\n",
    "            coord_dict = {\"ClassNames\": [classnames], \"X\": [x], \"Y\": [y], \"ID\": [id]}\n",
    "            df = pd.DataFrame(data = coord_dict)\n",
    "            df.ID = df.ID.astype(int)\n",
    "            append_df.append(df)\n",
    "    coord_df = pd.concat(append_df).reset_index(drop=True)\n",
    "    return(coord_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def df_to_image_mask(xml_filepath, ndpi_filepath,downsample_factor, general_save_path):\n",
    "    \"\"\"\n",
    "    Helper function from xml2trainingdata.ipynb\n",
    "    input: xml file path and ndpi file path of the wsi image, and the desired downsample factor\n",
    "    output: binary mask of the wsi image\n",
    "    \"\"\"\n",
    "    coord_df = xml_to_df(xml_filepath)\n",
    "    slide = openslide.open_slide(ndpi_filepath)\n",
    "    rgb_dim = slide.dimensions\n",
    "    print(\"Dimension of level 0 of the image is: \",rgb_dim)\n",
    "    slide_level_dim = slide.level_dimensions\n",
    "    num_levels = len(slide_level_dim)\n",
    "    print(\"Number of levels in this image are:\",num_levels)\n",
    "    factors = slide.level_downsamples\n",
    "    print(\"Each level is downsampled by:\",factors)\n",
    "    target_level = slide.get_best_level_for_downsample(downsample_factor)\n",
    "    target_dim = slide.level_dimensions[target_level]\n",
    "    rsf = [x/y for x,y in zip(rgb_dim,target_dim)]\n",
    "    blank = np.zeros((target_dim[1],target_dim[0]), dtype = np.uint8) #white\n",
    "    for idx, row in coord_df.iterrows():\n",
    "        xx = row.X.astype('int')\n",
    "        yy = row.Y.astype('int')\n",
    "        xx = [round(x/rsf[0]) for x in xx]\n",
    "        yy = [round(x/rsf[0]) for x in yy]\n",
    "        xy = list(zip(xx,yy))\n",
    "        contours = np.array(xy)\n",
    "        mask = cv2.fillPoly(blank, pts=[contours.astype(int)], color=255)\n",
    "    # image_resized = slide.read_region(location=(0,0),level=target_level,size=target_dim)\n",
    "    # mask_resized = cv2.resize(mask,[_//round(rsf[0]) for _ in mask.shape],interpolation=cv2.INTER_NEAREST)\n",
    "    # mask = np.rot90(mask, k = 1, axes= (1,0))\n",
    "    tmp = os.path.basename(ndpi_filepath)\n",
    "    ndpi_name = os.path.splitext(tmp)[0]\n",
    "    save_path = os.path.join(general_save_path,ndpi_name + \".png\")\n",
    "    cv2.imwrite(save_path,mask) #save binary mask\n",
    "    return (\"Image saved successfully!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### for stained: downsample by 8x to find the bounding box for each tissue image in WSI, and then get those bounding box coordinates multiplied by 8x again, and use those coordinates to read region with no downsample, but only that region of interest and then crop. (modify read_region function to read at full resolution, but only the bounding box by changing location and size). But use binary mask of the unstained to find the order, so we can save the images from top left to bottom right.\n",
    "\n",
    "### for unstained: use xml coordinates and just find the bounding box from there and then read region with no downsample and crop. But use binary mask of the unstained to find the order, so we can save the images from top left to bottom right.\n",
    "\n",
    "### To find order: get both binary images/masks of the raw ndpi, and because their relative positions are so different, we crop both images so that only the tissues are shown, meaning that there is no \"white space\" in the image. And then if we normalize the centroids with respect to the size of the cropped image, the centroids should be the same"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of level 0 of the image is:  (199680, 98560)\n",
      "Number of levels in this image are: 8\n",
      "Each level is downsampled by: (1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0)\n",
      "Dimension of level 0 of the image is:  (184320, 98560)\n",
      "Number of levels in this image are: 8\n",
      "Each level is downsampled by: (1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0)\n",
      "Dimension of level 0 of the image is:  (192000, 98560)\n",
      "Number of levels in this image are: 8\n",
      "Each level is downsampled by: (1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Image saved successfully!'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use df_to_image_mask to create binarymask of unstained with downsample 16x:\n",
    "df_to_image_mask(r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\sk244a.xml', r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\sk244a.ndpi',16,r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\entire_binary_masks')\n",
    "df_to_image_mask(r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\sk481.xml', r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\sk481.ndpi',16,r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\entire_binary_masks')\n",
    "df_to_image_mask(r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\skn1001.xml', r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\skn1001.ndpi',16,r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\entire_binary_masks')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# for stained:\n",
    "def stained_crop(stain_ndpi_filepath, general_save_path, binary_mask_path, save = True):\n",
    "    slide = openslide.open_slide(stain_ndpi_filepath)\n",
    "    tmp = os.path.basename(stain_ndpi_filepath)\n",
    "    ndpi_name = os.path.splitext(tmp)[0]\n",
    "\n",
    "# since image_resized is read with downsample, now find the coordinates of the bounding box for each image\n",
    "# to do that, first create a binary mask (which is already found in binary_image_path and then use label to find bbox of each label (image).\n",
    "\n",
    "    binary_img = Image.open(binary_mask_path)\n",
    "    labeledbw = label(np.array(binary_img))\n",
    "    props = regionprops_table(labeledbw, properties = ('bbox','label'))\n",
    "    # find bbox to crop\n",
    "    b0 = props.get('bbox-0') #xmin\n",
    "    b1 = props.get('bbox-1') #ymin\n",
    "    b2 = props.get('bbox-2') #xmax\n",
    "    b3 = props.get('bbox-3') #ymax\n",
    "    xmin = np.min(b0)\n",
    "    ymin = np.min(b1)\n",
    "    xmax = np.max(b2)\n",
    "    ymax = np.max(b3)\n",
    "    newlabeledbw = labeledbw[xmin:xmax,ymin:ymax] #crop image so no white space\n",
    "    size = newlabeledbw.shape\n",
    "    plt.imshow(newlabeledbw.astype(np.int32))\n",
    "    newprops = regionprops_table(newlabeledbw, properties = ('centroid','label'))\n",
    "    c0 = newprops.get('centroid-0')\n",
    "    c1 = newprops.get('centroid-1')\n",
    "    c0 = [round(x / size[0],4) for x in c0]\n",
    "    c1 = [round(x / size[1],4) for x in c1]\n",
    "    stained_centroid_tuple = list(zip(c0,c1)) #return centroid_tuple so that this can be used for unstain\n",
    "    id_list = np.arange(0,np.max(labeledbw))\n",
    "    stained_centroid_tuple_list = list(zip(stained_centroid_tuple,id_list))\n",
    "    if save:\n",
    "        for id in range(1,np.max(labeledbw)):\n",
    "            bwtarget = labeledbw == id\n",
    "            ind = np.argwhere(bwtarget)\n",
    "            xx_min = np.min(ind[:,1])\n",
    "            xx_max = np.max(ind[:,1])\n",
    "            yy_min = np.min(ind[:,0])\n",
    "            yy_max = np.max(ind[:,0])\n",
    "            x_min = round(xx_min*16) #downsample factor used to create binary_masks in both stained and unstained was 16.\n",
    "            x_max = round(xx_max*16)\n",
    "            y_min = round(yy_min*16)\n",
    "            y_max = round(yy_max*16)\n",
    "            location = (x_min,y_min)\n",
    "            dim = (x_max-x_min,y_max-y_min)\n",
    "            fin_image = slide.read_region(location= location,level=0,size=dim)\n",
    "            fin_image = np.array(fin_image)\n",
    "            save_path = os.path.join(general_save_path,ndpi_name)\n",
    "            save_path = os.path.join(save_path, ndpi_name + str(id - 1) + \".png\")\n",
    "            Image.fromarray(fin_image).save(save_path)\n",
    "        print(\"Image saved successfully!\")\n",
    "    else:\n",
    "        return stained_centroid_tuple_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved successfully!\n"
     ]
    }
   ],
   "source": [
    "stained_crop(r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\stained\\sk244ahe.ndpi', r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\stained\\images', r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\stained\\entire_binary_masks\\sk244a.png', save = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stained_crop(r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\stained\\sk481he.ndpi', r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\stained\\images', r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\stained\\entire_binary_masks\\sk481.png', save = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stained_crop(r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\stained\\skn1001he.ndpi', r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\stained\\images', r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\stained\\entire_binary_masks\\skn1001.png', save = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#compare the two centroids:\n",
    "def find_id (list1, list2):\n",
    "    if len(list1) != len(list2):\n",
    "        print(\"Two lists must have the same length, please fix!\")\n",
    "        return\n",
    "    else:\n",
    "        difference_ra = []\n",
    "        order_ra = []\n",
    "        for idx in range(0,len(list1)):\n",
    "            for idx1 in range(0,len(list1)):\n",
    "                difference_tup = np.subtract(list1[idx][0],list2[idx1][0]) #list1 is reference.\n",
    "                abs_difference = abs(difference_tup[0]) + abs(difference_tup[1])\n",
    "                difference_ra.append(abs_difference)\n",
    "            matched_id = np.argmin(difference_ra)\n",
    "            difference_ra = []\n",
    "            order_ra.append(matched_id)\n",
    "    return list(order_ra)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def unstained_crop(xml_filepath, unstain_ndpi_filepath, stain_ndpi_filepath, unstained_binary_mask_filepath, stained_binary_mask_filepath, general_save_path):\n",
    "    \"\"\"\n",
    "    Function to crop the unstained ndpi to individual tissue png files in order from top left to bottom right.\n",
    "    input: xml file path, ndpi file path of the unstained version. Also need binary mask of the same ndpi file path, which can simply be generated by downsampling the raw file (done elsewhere, make sure to know downsample factor of the binary mask)\n",
    "    output: the cropped images\n",
    "    \"\"\"\n",
    "    coord_df = xml_to_df(xml_filepath)\n",
    "    slide = openslide.open_slide(unstain_ndpi_filepath)\n",
    "    rgb_dim = slide.dimensions\n",
    "    print(\"Dimension of level 0 of the unstained image is: \",rgb_dim)\n",
    "    slide_level_dim = slide.level_dimensions\n",
    "    num_levels = len(slide_level_dim)\n",
    "    print(\"Number of levels in this unstained image are:\",num_levels)\n",
    "    factors = slide.level_downsamples\n",
    "    print(\"For unstained image, each level is downsampled by:\",factors)\n",
    "    tmp = os.path.basename(xml_filepath)\n",
    "    ndpi_name = os.path.splitext(tmp)[0]\n",
    "    stained_centroid_tuple_list = stained_crop(stain_ndpi_filepath, general_save_path, stained_binary_mask_filepath, save = False) #get centroid tuples for stained\n",
    "    unstained_binary_mask = Image.open(unstained_binary_mask_filepath)\n",
    "    unstained_binary_mask = np.array(unstained_binary_mask)\n",
    "    dim = unstained_binary_mask.shape\n",
    "    binary_img = unstained_binary_mask > 0\n",
    "    labeledbw = label(np.array(binary_img))\n",
    "    props = regionprops_table(labeledbw, properties = ('bbox','label'))\n",
    "    # find bbox to crop\n",
    "    b0 = props.get('bbox-0') #xmin\n",
    "    b1 = props.get('bbox-1') #ymin\n",
    "    b2 = props.get('bbox-2') #xmax\n",
    "    b3 = props.get('bbox-3') #ymax\n",
    "    xmin = np.min(b0)\n",
    "    ymin = np.min(b1)\n",
    "    xmax = np.max(b2)\n",
    "    ymax = np.max(b3)\n",
    "    cX_ra = []\n",
    "    cY_ra = []\n",
    "    for idx, row in coord_df.iterrows(): # now get centroid tuple for unstained first\n",
    "        # to get centroid tuple:\n",
    "        xx = row.X.astype('int')\n",
    "        yy = row.Y.astype('int')\n",
    "        x_ratio = ymin * 16\n",
    "        xxx = [n - x_ratio for n in xx]\n",
    "        y_ratio = xmin * 16\n",
    "        yyy = [n - y_ratio for n in yy]\n",
    "        xy = list(zip(xxx,yyy))\n",
    "        xy = np.array(xy)\n",
    "        moments = cv2.moments(xy)\n",
    "        cX = int(moments[\"m10\"] / moments[\"m00\"])\n",
    "        cY = int(moments[\"m01\"] / moments[\"m00\"])\n",
    "        cX_ra.append(cX)\n",
    "        cY_ra.append(cY)\n",
    "    x_ratio1 = (dim[1]-(ymax-ymin)) * 16\n",
    "    y_ratio1 = (dim[0]-(xmax-xmin)) * 16\n",
    "    cX_ra1 = [round(p / (rgb_dim[0] - x_ratio1),4) for p in cX_ra]\n",
    "    cY_ra1 = [round(p / (rgb_dim[1]- y_ratio1),4) for p in cY_ra]\n",
    "    unstained_centroid_tuple = list(zip(cY_ra1,cX_ra1))\n",
    "    id_list = np.arange(0,coord_df.shape[0])\n",
    "    unstained_centroid_tuple_list = list(zip(unstained_centroid_tuple,id_list))\n",
    "    # print(unstained_centroid_tuple_list)\n",
    "    order = find_id(stained_centroid_tuple_list,unstained_centroid_tuple_list)\n",
    "    print(\"order that is getting saved is {}\".format(order))\n",
    "\n",
    "    # to crop with same order as stained:\n",
    "    for idx, _ in coord_df.iterrows():\n",
    "        xx = coord_df.X[order[idx]].astype('int')\n",
    "        yy = coord_df.Y[order[idx]].astype('int')\n",
    "        x_min = np.min(xx)\n",
    "        x_max = np.max(xx)\n",
    "        y_min = np.min(yy)\n",
    "        y_max = np.max(yy)\n",
    "        location = (x_min,y_min)\n",
    "        dim = (x_max-x_min,y_max-y_min)\n",
    "        image_resized = slide.read_region(location= location,level=0,size=dim)\n",
    "        image_resized = np.array(image_resized)\n",
    "        final_img = Image.fromarray(image_resized)\n",
    "        save_path = os.path.join(general_save_path,ndpi_name)\n",
    "        save_path = os.path.join(save_path, ndpi_name + str(idx) + \".png\")\n",
    "        final_img.save(save_path)\n",
    "    print(\"Images saved successfully!\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of level 0 of the unstained image is:  (199680, 98560)\n",
      "Number of levels in this unstained image are: 8\n",
      "For unstained image, each level is downsampled by: (1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0)\n",
      "order that is getting saved is [2, 0, 18, 24, 17, 22, 5, 3, 11, 20, 10, 19, 4, 9, 6, 12, 21, 14, 1, 7, 13, 15, 16, 8, 23]\n"
     ]
    }
   ],
   "source": [
    "unstained_crop(r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\sk244a.xml', r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\sk244a.ndpi',r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\stained\\sk244ahe.ndpi',r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\entire_binary_masks\\sk244a.png',r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\stained\\entire_binary_masks\\sk244a.png',r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\images')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unstained_crop(r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\sk481.xml', r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\sk481.ndpi',r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\stained\\sk481he.ndpi',r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\entire_binary_masks\\sk481.png',r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\stained\\entire_binary_masks\\sk481.png',r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\images')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unstained_crop(r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\sk244a.xml', r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\sk244a.ndpi',r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\stained\\sk244ahe.ndpi',r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\entire_binary_masks\\sk244a.png',r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\stained\\entire_binary_masks\\sk244a.png',r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\images')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# function to pad images to same size:\n",
    "def pad_images_to_same_size(images):\n",
    "    \"\"\"\n",
    "    :param images: sequence of images\n",
    "    :return: list of images padded so that all images have same width and height (max width and height are used)\n",
    "    \"\"\"\n",
    "    width_max = 0\n",
    "    height_max = 0\n",
    "    for img in images:\n",
    "        h, w = img.shape[:2]\n",
    "        width_max = max(width_max, w)\n",
    "        height_max = max(height_max, h)\n",
    "\n",
    "    images_padded = []\n",
    "    for img in images:\n",
    "        h, w = img.shape[:2]\n",
    "        diff_vert = height_max - h\n",
    "        pad_top = diff_vert//2\n",
    "        pad_bottom = diff_vert - pad_top\n",
    "        diff_hori = width_max - w\n",
    "        pad_left = diff_hori//2\n",
    "        pad_right = diff_hori - pad_left\n",
    "        img_padded = cv2.copyMakeBorder(img, pad_top, pad_bottom, pad_left, pad_right, cv2.BORDER_CONSTANT, value=(255,255,255))\n",
    "        assert img_padded.shape[:2] == (height_max, width_max)\n",
    "        images_padded.append(img_padded)\n",
    "\n",
    "    return images_padded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "pad_images_to_same_size = _time(pad_images_to_same_size)\n",
    "optical_flow_tvl1 = _time(optical_flow_tvl1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pad the two images:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now register the two padded images:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def registrate_two_images(reference_image_path, moving_image_path, save_path):\n",
    "    \"\"\"\n",
    "    Note: The order of the files saved in the ref_img_path and mov_img_path must be the same so that you are registering the same images!\n",
    "    \"\"\"\n",
    "    ref_img_path = [_ for _ in os.listdir(reference_image_path) if _.endswith(\".png\")]\n",
    "    ref_img_path_complete = [os.path.join(ref_img_path, x) for x in ref_img_path]\n",
    "    ref_img_path_1 = [x.replace('.png','') for x in ref_img_path]\n",
    "\n",
    "    mov_img_path = [_ for _ in os.listdir(moving_image_path) if _.endswith(\".png\")]\n",
    "    # mov_img_path_complete = [os.path.join(mov_img_path, x) for x in mov_img_path]\n",
    "    # mov_img_path_1 = [x.replace('.png','') for x in mov_img_path]\n",
    "\n",
    "    if int(len(ref_img_path)) != int(len(mov_img_path)):\n",
    "        print(\"Number of images in reference and moving file paths are not equal, please fix and try again!\")\n",
    "        return\n",
    "\n",
    "    num = int(len(ref_img_path))\n",
    "    start = time()\n",
    "    for idx in range(num,len(ref_img_path_complete)):\n",
    "        if idx == len(ref_img_path_complete) - 1:\n",
    "            break\n",
    "        ref_img = np.array(Image.open(ref_img_path))\n",
    "        mov_img = np.array(Image.open(mov_img_path))\n",
    "        ref_img_g = rgb2gray(ref_img)\n",
    "        mov_img_g = rgb2gray(mov_img)\n",
    "        v, u = optical_flow_tvl1(ref_img_g, mov_img_g)\n",
    "        nr, nc = ref_img_g.shape\n",
    "        row_coords, col_coords = np.meshgrid(np.arange(nr), np.arange(nc),\n",
    "                                             indexing='ij')\n",
    "        mov_img_warp_ra =[]\n",
    "        for i in range(3):\n",
    "            mov_img_warp = warp(mov_img[:,:,i], np.array([row_coords + v, col_coords + u]),mode='edge')\n",
    "            mov_img_warp_ra.append(mov_img_warp)\n",
    "        r = np.array(mov_img_warp_ra[0]*255).astype('uint8')\n",
    "        g = np.array(mov_img_warp_ra[1]*255).astype('uint8')\n",
    "        b = np.array(mov_img_warp_ra[2]*255).astype('uint8')\n",
    "        rgb = np.stack([r,g,b],axis=2)\n",
    "        reg_img = Image.fromarray(rgb)\n",
    "        reg_img.save(save_path + str(ref_img_path_1[idx]) + '.png')\n",
    "\n",
    "    end = time()\n",
    "    print(\"time it took to register: \"+  str((end-start)/60) + \" minutes\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
