{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import warp\n",
    "from skimage.registration import optical_flow_tvl1, optical_flow_ilk\n",
    "import openslide\n",
    "import os\n",
    "import cv2\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2,40).__str__()\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.measure\n",
    "import scipy.stats as stats\n",
    "import torchvision.transforms as transforms\n",
    "from glob import glob\n",
    "from time import time\n",
    "from skimage.measure import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def _time(f):\n",
    "    def wrapper(*args,**kwargs):\n",
    "        start=time()\n",
    "        r=f(*args,**kwargs)\n",
    "        end=time()\n",
    "        print(\"%s timed %f\" %(f.__name__,end-start))\n",
    "        return r\n",
    "    return wrapper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# First, input xml_filepath and output a dataframe of X,Y coordinates in general. (can be used for ROI as well)\n",
    "def xml_to_df(xml_filepath):\n",
    "    tree = ET.parse(xml_filepath)\n",
    "    root = tree.getroot()\n",
    "    append_df = []\n",
    "    for index, Annotation in enumerate(root.iter(\"Annotation\")):\n",
    "        for Region in Annotation.iter('Region'):\n",
    "            x = np.array([Vertex.get('X') for Vertex in Region.iter('Vertex')])\n",
    "            y = np.array([Vertex.get('Y') for Vertex in Region.iter('Vertex')])\n",
    "            id = np.array([int(Region.get('Id'))])\n",
    "            classnames = index + 1\n",
    "            coord_dict = {\"ClassNames\": [classnames], \"X\": [x], \"Y\": [y], \"ID\": [id]}\n",
    "            df = pd.DataFrame(data = coord_dict)\n",
    "            df.ID = df.ID.astype(int)\n",
    "            append_df.append(df)\n",
    "    coord_df = pd.concat(append_df).reset_index(drop=True)\n",
    "    return(coord_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "    ClassNames                                                  X  \\\n0            1  [66855, 66848, 66848, 66848, 66848, 66848, 668...   \n1            1  [64319, 64382, 64395, 64421, 64446, 64472, 644...   \n2            1  [78061, 78048, 78048, 78048, 78048, 78048, 780...   \n3            1  [66800, 66791, 66781, 66763, 66754, 66735, 667...   \n4            1  [66050, 66060, 66078, 66106, 66143, 66180, 661...   \n5            1  [78649, 78649, 78649, 78649, 78649, 78649, 786...   \n6            1  [77691, 77678, 77665, 77639, 77627, 77601, 775...   \n7            1  [78163, 78291, 78432, 78559, 78738, 78879, 790...   \n8            1  [89727, 89727, 89713, 89699, 89693, 89679, 896...   \n9            1  [88630, 88593, 88574, 88537, 88519, 88500, 884...   \n10           1  [92605, 92591, 92584, 92577, 92570, 92556, 925...   \n11           1  [100955, 100853, 100788, 100751, 100723, 10071...   \n12           1  [100259, 100246, 100233, 100233, 100208, 10019...   \n13           1  [99964, 99939, 99888, 99849, 99811, 99773, 997...   \n14           1  [108841, 108854, 108880, 108905, 108931, 10895...   \n15           1  [109952, 109978, 110004, 110055, 110106, 11015...   \n16           2  [131119, 131119, 131119, 131119, 131119, 13111...   \n17           2  [121747, 121747, 121747, 121747, 121747, 12174...   \n18           2  [111810, 111782, 111782, 111775, 111768, 11176...   \n19           2  [122991, 122977, 122963, 122956, 122942, 12292...   \n20           2  [111917, 111898, 111880, 111843, 111843, 11181...   \n21           2  [122925, 122916, 122907, 122888, 122870, 12287...   \n22           2  [99842, 99842, 99842, 99847, 99858, 99864, 998...   \n23           3  [122175, 122221, 122249, 122305, 122333, 12237...   \n24           3  [89504, 89504, 89504, 89466, 89440, 89415, 893...   \n\n                                                    Y  ID  \n0   [29667, 29667, 29674, 29681, 29688, 29695, 297...   1  \n1   [63336, 63399, 63412, 63438, 63451, 63476, 635...   2  \n2   [28813, 28813, 28851, 28915, 29005, 29068, 291...   3  \n3   [38608, 38608, 38617, 38636, 38654, 38682, 387...   4  \n4   [49432, 49422, 49404, 49395, 49367, 49330, 493...   5  \n5   [38239, 38252, 38264, 38290, 38328, 38354, 383...   6  \n6   [48635, 48635, 48635, 48648, 48661, 48686, 487...   7  \n7   [67984, 67984, 67997, 67997, 67997, 67997, 679...   8  \n8   [66995, 66954, 66905, 66863, 66821, 66793, 667...   9  \n9   [55128, 55054, 54999, 54906, 54851, 54795, 547...  10  \n10  [44612, 44598, 44598, 44591, 44584, 44556, 445...  11  \n11  [39098, 39126, 39145, 39154, 39172, 39191, 391...  12  \n12  [49159, 49159, 49172, 49197, 49223, 49248, 492...  13  \n13  [68329, 68303, 68278, 68227, 68214, 68163, 681...  14  \n14  [53552, 53603, 53629, 53667, 53705, 53744, 537...  15  \n15  [68521, 68521, 68521, 68534, 68547, 68559, 685...  16  \n16  [64939, 64948, 64957, 64976, 65004, 65022, 650...   1  \n17  [31587, 31594, 31615, 31643, 31685, 31727, 317...   2  \n18  [28829, 28899, 28913, 28934, 28955, 28976, 289...   3  \n19  [45757, 45737, 45723, 45702, 45688, 45660, 456...   4  \n20  [44960, 44904, 44867, 44811, 44774, 44719, 446...   5  \n21  [56986, 56967, 56949, 56930, 56912, 56893, 568...   6  \n22  [30706, 30712, 30728, 30766, 30810, 30859, 309...   7  \n23  [61023, 61023, 61023, 61023, 61014, 61014, 610...   1  \n24  [27766, 27779, 27792, 27830, 27894, 27958, 280...   2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ClassNames</th>\n      <th>X</th>\n      <th>Y</th>\n      <th>ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[66855, 66848, 66848, 66848, 66848, 66848, 668...</td>\n      <td>[29667, 29667, 29674, 29681, 29688, 29695, 297...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[64319, 64382, 64395, 64421, 64446, 64472, 644...</td>\n      <td>[63336, 63399, 63412, 63438, 63451, 63476, 635...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>[78061, 78048, 78048, 78048, 78048, 78048, 780...</td>\n      <td>[28813, 28813, 28851, 28915, 29005, 29068, 291...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>[66800, 66791, 66781, 66763, 66754, 66735, 667...</td>\n      <td>[38608, 38608, 38617, 38636, 38654, 38682, 387...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>[66050, 66060, 66078, 66106, 66143, 66180, 661...</td>\n      <td>[49432, 49422, 49404, 49395, 49367, 49330, 493...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>[78649, 78649, 78649, 78649, 78649, 78649, 786...</td>\n      <td>[38239, 38252, 38264, 38290, 38328, 38354, 383...</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>[77691, 77678, 77665, 77639, 77627, 77601, 775...</td>\n      <td>[48635, 48635, 48635, 48648, 48661, 48686, 487...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>[78163, 78291, 78432, 78559, 78738, 78879, 790...</td>\n      <td>[67984, 67984, 67997, 67997, 67997, 67997, 679...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>[89727, 89727, 89713, 89699, 89693, 89679, 896...</td>\n      <td>[66995, 66954, 66905, 66863, 66821, 66793, 667...</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>[88630, 88593, 88574, 88537, 88519, 88500, 884...</td>\n      <td>[55128, 55054, 54999, 54906, 54851, 54795, 547...</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>[92605, 92591, 92584, 92577, 92570, 92556, 925...</td>\n      <td>[44612, 44598, 44598, 44591, 44584, 44556, 445...</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n      <td>[100955, 100853, 100788, 100751, 100723, 10071...</td>\n      <td>[39098, 39126, 39145, 39154, 39172, 39191, 391...</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1</td>\n      <td>[100259, 100246, 100233, 100233, 100208, 10019...</td>\n      <td>[49159, 49159, 49172, 49197, 49223, 49248, 492...</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1</td>\n      <td>[99964, 99939, 99888, 99849, 99811, 99773, 997...</td>\n      <td>[68329, 68303, 68278, 68227, 68214, 68163, 681...</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1</td>\n      <td>[108841, 108854, 108880, 108905, 108931, 10895...</td>\n      <td>[53552, 53603, 53629, 53667, 53705, 53744, 537...</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1</td>\n      <td>[109952, 109978, 110004, 110055, 110106, 11015...</td>\n      <td>[68521, 68521, 68521, 68534, 68547, 68559, 685...</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2</td>\n      <td>[131119, 131119, 131119, 131119, 131119, 13111...</td>\n      <td>[64939, 64948, 64957, 64976, 65004, 65022, 650...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2</td>\n      <td>[121747, 121747, 121747, 121747, 121747, 12174...</td>\n      <td>[31587, 31594, 31615, 31643, 31685, 31727, 317...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2</td>\n      <td>[111810, 111782, 111782, 111775, 111768, 11176...</td>\n      <td>[28829, 28899, 28913, 28934, 28955, 28976, 289...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2</td>\n      <td>[122991, 122977, 122963, 122956, 122942, 12292...</td>\n      <td>[45757, 45737, 45723, 45702, 45688, 45660, 456...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2</td>\n      <td>[111917, 111898, 111880, 111843, 111843, 11181...</td>\n      <td>[44960, 44904, 44867, 44811, 44774, 44719, 446...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2</td>\n      <td>[122925, 122916, 122907, 122888, 122870, 12287...</td>\n      <td>[56986, 56967, 56949, 56930, 56912, 56893, 568...</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2</td>\n      <td>[99842, 99842, 99842, 99847, 99858, 99864, 998...</td>\n      <td>[30706, 30712, 30728, 30766, 30810, 30859, 309...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>3</td>\n      <td>[122175, 122221, 122249, 122305, 122333, 12237...</td>\n      <td>[61023, 61023, 61023, 61023, 61014, 61014, 610...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>3</td>\n      <td>[89504, 89504, 89504, 89466, 89440, 89415, 893...</td>\n      <td>[27766, 27779, 27792, 27830, 27894, 27958, 280...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord_df = xml_to_df(r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\sk244a.xml')\n",
    "coord_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### for stained: downsample by 8x to find the bounding box for each tissue image in WSI, and then get those boundingbox coordsinates multipled by 8x again, and use those coordinates to read region with no downsample, but only that region of interest and then crop. (modify read_region function to read at full resolution, but only the bounding box by changing location and size).\n",
    "\n",
    "### for unstained: use xml coordinates and just find the boudnign box from there and then read region with no downsample and crop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "# for unstained:\n",
    "def unstained_crop(xml_filepath, unstain_ndpi_filepath):\n",
    "    coord_df = xml_to_df(xml_filepath)\n",
    "    slide = openslide.open_slide(unstain_ndpi_filepath)\n",
    "    rgb_dim = slide.dimensions\n",
    "    print(\"Dimension of level 0 of the unstained image is: \",rgb_dim)\n",
    "    slide_level_dim = slide.level_dimensions\n",
    "    num_levels = len(slide_level_dim)\n",
    "    print(\"Number of levels in this unstained image are:\",num_levels)\n",
    "    factors = slide.level_downsamples\n",
    "    print(\"For unstained image, each level is downsampled by:\",factors)\n",
    "    tmp = os.path.basename(xml_filepath)\n",
    "    ndpi_name = os.path.splitext(tmp)[0]\n",
    "\n",
    "    for idx, row in coord_df.iterrows():\n",
    "        xx = row.X.astype('int')\n",
    "        yy = row.Y.astype('int')\n",
    "        x_min = np.min(xx)\n",
    "        x_max = np.max(xx)\n",
    "        y_min = np.min(yy)\n",
    "        y_max = np.max(yy)\n",
    "        location = (x_min,y_min)\n",
    "        dim = (x_max-x_min,y_max-y_min)\n",
    "        image_resized = slide.read_region(location= location,level=0,size=dim)\n",
    "        image_resized = np.array(image_resized)\n",
    "        final_img = Image.fromarray(image_resized)\n",
    "        save_path = os.path.join(r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\images',ndpi_name)\n",
    "        save_path = os.path.join(save_path, ndpi_name + str(idx) + \".png\")\n",
    "        final_img.save(save_path)\n",
    "\n",
    "    print(\"Images saved successfully!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of level 0 of the unstained image is:  (199680, 98560)\n",
      "Number of levels in this unstained image are: 8\n",
      "For unstained image, each level is downsampled by: (1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0)\n"
     ]
    }
   ],
   "source": [
    "unstained_crop(r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\sk244a.xml', r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\sk244a.ndpi')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for stained:\n",
    "\n",
    "# coord_df = xml_to_df(xml_filepath)\n",
    "# slide = openslide.open_slide(unstain_ndpi_filepath)\n",
    "# rgb_dim = slide.dimensions\n",
    "# print(\"Dimension of level 0 of the unstained image is: \",rgb_dim)\n",
    "# slide_level_dim = slide.level_dimensions\n",
    "# num_levels = len(slide_level_dim)\n",
    "# print(\"Number of levels in this unstained image are:\",num_levels)\n",
    "# factors = slide.level_downsamples\n",
    "# print(\"For unstained image, each level is downsampled by:\",factors)\n",
    "# target_level = slide.get_best_level_for_downsample(downsample_factor)\n",
    "# target_dim = slide.level_dimensions[target_level]\n",
    "# rsf = [x/y for x,y in zip(rgb_dim,target_dim)]\n",
    "# image_resized = slide.read_region(location=(0,0),level=target_level,size=target_dim)\n",
    "# image_resized = np.array(image_resized)\n",
    "# print(\"unstained image size after downsample is: {}\".format(image_resized.shape))\n",
    "# tmp = os.path.basename(xml_filepath)\n",
    "# ndpi_name = os.path.splitext(tmp)[0]\n",
    "# for idx, row in coord_df.iterrows():\n",
    "#     xx = row.X.astype('int')\n",
    "#     yy = row.Y.astype('int')\n",
    "#     x_min = round(np.min(xx)/rsf[0])\n",
    "#     x_max = round(np.max(xx)/rsf[0])\n",
    "#     y_min = round(np.min(yy)/rsf[0])\n",
    "#     y_max = round(np.max(yy)/rsf[0])\n",
    "#     final_img = image_resized[y_min:y_max,x_min:x_max]\n",
    "#     final_img = Image.fromarray(final_img)\n",
    "#     save_path = os.path.join(r'\\\\shelter\\Kyu\\unstain2stain\\biomax_images\\unstained\\images',ndpi_name)\n",
    "#     save_path = os.path.join(save_path, ndpi_name + str(idx) + \".png\")\n",
    "#     final_img.save(save_path)\n",
    "#     print(\"Images saved successfully!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# function to pad images to same size:\n",
    "def pad_images_to_same_size(images):\n",
    "    \"\"\"\n",
    "    :param images: sequence of images\n",
    "    :return: list of images padded so that all images have same width and height (max width and height are used)\n",
    "    \"\"\"\n",
    "    width_max = 0\n",
    "    height_max = 0\n",
    "    for img in images:\n",
    "        h, w = img.shape[:2]\n",
    "        width_max = max(width_max, w)\n",
    "        height_max = max(height_max, h)\n",
    "\n",
    "    images_padded = []\n",
    "    for img in images:\n",
    "        h, w = img.shape[:2]\n",
    "        diff_vert = height_max - h\n",
    "        pad_top = diff_vert//2\n",
    "        pad_bottom = diff_vert - pad_top\n",
    "        diff_hori = width_max - w\n",
    "        pad_left = diff_hori//2\n",
    "        pad_right = diff_hori - pad_left\n",
    "        img_padded = cv2.copyMakeBorder(img, pad_top, pad_bottom, pad_left, pad_right, cv2.BORDER_CONSTANT, value=(255,255,255))\n",
    "        assert img_padded.shape[:2] == (height_max, width_max)\n",
    "        images_padded.append(img_padded)\n",
    "\n",
    "    return images_padded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "pad_images_to_same_size = _time(pad_images_to_same_size)\n",
    "optical_flow_tvl1 = _time(optical_flow_tvl1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First create separate images from each wsi image, with annotations in the unstained folder. crop the images (total of 24 annotation, so 24 images per whole slide) and save them first in a different folder in same path. Then pad the images and then save them. Then using those padded images, register them to one another (doesn't matter which way since there are only two images)\n",
    "## the path is in: \\\\shelter\\Kyu\\unstain2stain\\biomax_images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def registrate_two_images(reference_image_path, moving_image_path, save_path):\n",
    "    ref_img_path = [_ for _ in os.listdir(reference_image_path) if _.endswith(\".jpg\")]\n",
    "    ref_img_path_complete = [os.path.join(ref_img_path, x) for x in ref_img_path]\n",
    "    ref_img_path_1 = [x.replace('.jpg','') for x in ref_img_path]\n",
    "\n",
    "    mov_img_path = [_ for _ in os.listdir(moving_image_path) if _.endswith(\".jpg\")]\n",
    "    mov_img_path_complete = [os.path.join(mov_img_path, x) for x in mov_img_path]\n",
    "    mov_img_path_1 = [x.replace('.jpg','') for x in mov_img_path]\n",
    "\n",
    "    if int(len(ref_img_path)) != int(len(mov_img_path)):\n",
    "        raise\n",
    "\n",
    "    num = int(len(ref_img_path)/2) - 1 #idx = 16, or 17th image\n",
    "    num_plus1 = num + 1 #idx = 17, or 18th image\n",
    "    num_minus1 = num - 1 #idx = 15, or 16th image\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    ref_img_path = img_files_path_complete[num]\n",
    "    mov_img_path = img_files_path_complete[num_plus1]\n",
    "    ref_img = np.array(Image.open(ref_img_path))\n",
    "    mov_img = np.array(Image.open(mov_img_path))\n",
    "\n",
    "    ref_img_g = rgb2gray(ref_img)\n",
    "    mov_img_g = rgb2gray(mov_img)\n",
    "    v, u = optical_flow_tvl1(ref_img_g, mov_img_g)\n",
    "    nr, nc = ref_img_g.shape\n",
    "    row_coords, col_coords = np.meshgrid(np.arange(nr), np.arange(nc),\n",
    "                                         indexing='ij')\n",
    "    end = time()\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    mov_img_warp_ra =[]\n",
    "    for i in range(3):\n",
    "        mov_img_warp = warp(mov_img[:,:,i], np.array([row_coords + v, col_coords + u]),mode='edge')\n",
    "        mov_img_warp_ra.append(mov_img_warp)\n",
    "\n",
    "    r = np.array(mov_img_warp_ra[0]*255).astype('uint8')\n",
    "    g = np.array(mov_img_warp_ra[1]*255).astype('uint8')\n",
    "    b = np.array(mov_img_warp_ra[2]*255).astype('uint8')\n",
    "    rgb = np.stack([r,g,b],axis=2)\n",
    "    reg_img = Image.fromarray(rgb)\n",
    "    reg_img.save(r'\\\\fatherserverdw\\kyuex\\image\\CLUE\\3D study\\he\\CoarseRegIM\\run4_16xr_jpg_rszfc1_padsz1000\\opticalflow_registered_image\\\\' + str(img_files_path_1[num_plus1]) + '.jpg')\n",
    "\n",
    "    end = time()\n",
    "    print(\"time it took to register: \"+  str(end-start) + \" seconds\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#two for loops to recursively create registered images:\n",
    "\n",
    "# from middle to end (higher index), idx of 17 to 33, or 18th image to 34th image:\n",
    "start = time()\n",
    "\n",
    "for idx in range(num_plus1,len(img_files_path_complete)): #idx = 17 to 34 (not including 34)\n",
    "    if idx == len(img_files_path_complete) - 1:\n",
    "        break\n",
    "    ref_img_path = os.path.join(r'\\\\fatherserverdw\\kyuex\\image\\CLUE\\3D study\\he\\CoarseRegIM\\run4_16xr_jpg_rszfc1_padsz1000\\opticalflow_registered_image', img_files_path[idx])\n",
    "    mov_img_path = img_files_path_complete[idx+1]\n",
    "    ref_img = np.array(Image.open(ref_img_path))\n",
    "    mov_img = np.array(Image.open(mov_img_path))\n",
    "\n",
    "    ref_img_g = rgb2gray(ref_img)\n",
    "    mov_img_g = rgb2gray(mov_img)\n",
    "    v, u = optical_flow_tvl1(ref_img_g, mov_img_g)\n",
    "    nr, nc = ref_img_g.shape\n",
    "    row_coords, col_coords = np.meshgrid(np.arange(nr), np.arange(nc),\n",
    "                                         indexing='ij')\n",
    "    mov_img_warp_ra =[]\n",
    "    for i in range(3):\n",
    "        mov_img_warp = warp(mov_img[:,:,i], np.array([row_coords + v, col_coords + u]),mode='edge')\n",
    "        mov_img_warp_ra.append(mov_img_warp)\n",
    "    r = np.array(mov_img_warp_ra[0]*255).astype('uint8')\n",
    "    g = np.array(mov_img_warp_ra[1]*255).astype('uint8')\n",
    "    b = np.array(mov_img_warp_ra[2]*255).astype('uint8')\n",
    "    rgb = np.stack([r,g,b],axis=2)\n",
    "    reg_img = Image.fromarray(rgb)\n",
    "    reg_img.save(r'\\\\fatherserverdw\\kyuex\\image\\CLUE\\3D study\\he\\CoarseRegIM\\run4_16xr_jpg_rszfc1_padsz1000\\opticalflow_registered_image\\\\' + str(img_files_path_1[idx+1]) + '.jpg')\n",
    "\n",
    "end = time()\n",
    "print(\"time it took to register: \"+  str((end-start)/60) + \" minutes\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
