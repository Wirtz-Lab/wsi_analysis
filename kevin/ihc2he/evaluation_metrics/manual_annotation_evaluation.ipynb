{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Workflow to find F1 score between manual annotation evaluation of IHC image and segmentation result of inferred H&E image from CODA segmentation model:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Part 0: Code to save the test images that were chosen for manual annotation evaluation in a separate folder, the segmentation map of these inferred images will also be in those respective folders:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 20%|██        | 4/20 [00:00<00:00, 33.67it/s]\u001B[A\n",
      " 40%|████      | 8/20 [00:00<00:00, 32.34it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 29.77it/s]\u001B[A\n",
      " 80%|████████  | 16/20 [00:00<00:00, 31.57it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 31.82it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:00<00:03,  1.53it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 28.61it/s]\u001B[A\n",
      " 35%|███▌      | 7/20 [00:00<00:00, 31.49it/s]\u001B[A\n",
      " 55%|█████▌    | 11/20 [00:00<00:00, 31.74it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 31.43it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 32.24it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:01<00:02,  1.56it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 20%|██        | 4/20 [00:00<00:00, 37.55it/s]\u001B[A\n",
      " 40%|████      | 8/20 [00:00<00:00, 35.26it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 34.98it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 37.73it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:01<00:01,  1.68it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 42.79it/s]\u001B[A\n",
      " 50%|█████     | 10/20 [00:00<00:00, 40.29it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 39.44it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 39.75it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.77it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.42it/s]\u001B[A\n",
      " 50%|█████     | 10/20 [00:00<00:00, 38.97it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 41.61it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 40.61it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:02<00:00,  1.84it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 41.26it/s]\u001B[A\n",
      " 50%|█████     | 10/20 [00:00<00:00, 36.40it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 38.71it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 38.51it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.77it/s]\n"
     ]
    }
   ],
   "source": [
    "src_path = r\"\\\\10.99.68.178\\ashleyex\\Type_1_diabetes\\IHC to HE model\\annotation_jpg\"\n",
    "files_src = [os.path.join(src_path,x) for x in os.listdir(src_path)]\n",
    "files_src = [x for x in files_src if x.split(\"_\")[-1][:3] == \"IHC\"] # all six folders\n",
    "dst_path = r\"\\\\10.99.68.51\\Kyu\\IHC2HE\\Balanced_Aligned\\dataset_v1_256x256\\test\\manual_annotation_eval\"\n",
    "img_src_path = r\"\\\\10.99.68.51\\Kyu\\IHC2HE\\Balanced_Aligned\\dataset_v1_256x256\\test\"\n",
    "for folder in tqdm(files_src):\n",
    "    dst_folder = os.path.join(dst_path,os.path.basename(folder))\n",
    "    if not os.path.exists(dst_folder):\n",
    "        os.makedirs(dst_folder)\n",
    "    img_list = [os.path.join(folder,x) for x in os.listdir(folder) if x.endswith(\".jpg\")]\n",
    "    for img in tqdm(img_list):\n",
    "        shutil.copy(img,dst_folder)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For conditional I2SB inference only, need HE_segmentation map so move the corresponding seg maps as well:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "seg_map_dir = r\"\\\\10.99.68.51\\Kyu\\IHC2HE\\Balanced_Aligned\\dataset_v1_256x256\\test\\HE\\classification_12082023\\color\"\n",
    "src = r\"\\\\10.99.68.178\\ashleyex\\Type_1_diabetes\\IHC to HE model\\annotation_jpg\"\n",
    "file_src = [os.path.join(src,x) for x in os.listdir(src)]\n",
    "file_src = [x for x in file_src if x.split(\"_\")[-1][:3] == \"IHC\"] # all six folders\n",
    "save_dir = r\"\\\\10.99.68.51\\Kyu\\IHC2HE\\Balanced_Aligned\\dataset_v1_256x256\\test\\manual_annotation_eval\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 28.69it/s]\u001B[A\n",
      " 35%|███▌      | 7/20 [00:00<00:00, 29.90it/s]\u001B[A\n",
      " 55%|█████▌    | 11/20 [00:00<00:00, 30.53it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 30.25it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 28.52it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:00<00:03,  1.40it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 26.19it/s]\u001B[A\n",
      " 35%|███▌      | 7/20 [00:00<00:00, 30.04it/s]\u001B[A\n",
      " 50%|█████     | 10/20 [00:00<00:00, 12.02it/s]\u001B[A\n",
      " 65%|██████▌   | 13/20 [00:00<00:00, 14.59it/s]\u001B[A\n",
      " 80%|████████  | 16/20 [00:00<00:00, 16.39it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:01<00:00, 18.24it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:01<00:03,  1.06it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      "  5%|▌         | 1/20 [00:00<00:18,  1.00it/s]\u001B[A\n",
      " 25%|██▌       | 5/20 [00:01<00:02,  5.74it/s]\u001B[A\n",
      " 45%|████▌     | 9/20 [00:01<00:01, 10.41it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:01<00:00, 13.26it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:01<00:00, 15.98it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:01<00:00, 11.92it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:03<00:03,  1.29s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 25.33it/s]\u001B[A\n",
      " 30%|███       | 6/20 [00:00<00:00, 26.24it/s]\u001B[A\n",
      " 50%|█████     | 10/20 [00:00<00:00, 28.97it/s]\u001B[A\n",
      " 65%|██████▌   | 13/20 [00:00<00:00, 28.80it/s]\u001B[A\n",
      " 80%|████████  | 16/20 [00:00<00:00, 27.59it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 27.27it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:04<00:02,  1.07s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 25.26it/s]\u001B[A\n",
      " 30%|███       | 6/20 [00:00<00:00, 25.38it/s]\u001B[A\n",
      " 45%|████▌     | 9/20 [00:00<00:00, 24.59it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 25.77it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 25.47it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 26.38it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:05<00:00,  1.04it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 28.46it/s]\u001B[A\n",
      " 35%|███▌      | 7/20 [00:00<00:00, 30.25it/s]\u001B[A\n",
      " 55%|█████▌    | 11/20 [00:00<00:00, 30.07it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 29.63it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 28.48it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(file_src):\n",
    "    folder_name = os.path.basename(file)\n",
    "    save_dir_folder = os.path.join(save_dir,folder_name)\n",
    "    save_dir_folder = os.path.join(save_dir_folder,\"HE_segmentation_map\")\n",
    "    if not os.path.exists(save_dir_folder):\n",
    "        os.makedirs(save_dir_folder)\n",
    "    all_image_list = [os.path.join(file,x) for x in os.listdir(file) if x.endswith(\".jpg\")]\n",
    "    for images in tqdm(all_image_list):\n",
    "        image_name = os.path.basename(images)\n",
    "        if \"IHCA\" in file:\n",
    "            image_name = image_name.replace(\"ISLET\",\"HE\")\n",
    "            image_name = image_name.replace(\".jpg\",\".png\")\n",
    "        elif \"IHCB\" in file:\n",
    "            image_name = image_name.replace(\"VESSEL\",\"HE\")\n",
    "            image_name = image_name.replace(\".jpg\",\".png\")\n",
    "        elif \"IHCC\" in file:\n",
    "            image_name = image_name.replace(\"IMMUNE\",\"HE\")\n",
    "            image_name = image_name.replace(\".jpg\",\".png\")\n",
    "        seg_map_img = os.path.join(seg_map_dir,image_name)\n",
    "        shutil.copy(seg_map_img,save_dir_folder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Part 1: Code to turn manual IHC annotations saved in .xml file to a binary mask and a tissue map (Need to run only once):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = r\"\\\\10.99.68.178\\ashleyex\\Type_1_diabetes\\IHC to HE model\\annotation_jpg\"\n",
    "file_src = [os.path.join(src,x) for x in os.listdir(src)]\n",
    "file_src = [x for x in file_src if x.split(\"_\")[-1][:3] == \"IHC\"] # all six folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# First, input xml_filepath and output a dataframe of X,Y coordinates in general. (can be used for ROI as well)\n",
    "def xml_to_df(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    append_df = []\n",
    "    for index, Annotation in enumerate(root.iter(\"Annotation\")):\n",
    "        for Region in Annotation.iter('Region'):\n",
    "            x = np.array([Vertex.get('X') for Vertex in Region.iter('Vertex')])\n",
    "            y = np.array([Vertex.get('Y') for Vertex in Region.iter('Vertex')])\n",
    "            id = np.array([int(Region.get('Id'))])\n",
    "            classnames = index + 1\n",
    "            coord_dict = {\"ClassNames\": [classnames], \"X\": [x], \"Y\": [y], \"ID\": [id]}\n",
    "            df = pd.DataFrame(data=coord_dict)\n",
    "            df.ID = df.ID.astype(int)\n",
    "            append_df.append(df)\n",
    "    coord_df = pd.concat(append_df).reset_index(drop=True)\n",
    "    return (coord_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Then, input xml_path to use xml_to_df function to output X,Y coordinates for each annotation per class:\n",
    "def coord_to_multiclass_df(xml_path):\n",
    "    coord_df = xml_to_df(xml_path)\n",
    "    coord_df = coord_df.drop(columns=[\"ID\"])\n",
    "    dict = {\"islet\": 1, \"duct\": 2, \"vessels\": 3, \"fat\": 4, \"acini\": 5, \"ecm\": 6, \"whitespace\": 7,\n",
    "            \"nerves\": 8}\n",
    "    coord_df = coord_df.replace({\"ClassNames\": dict})\n",
    "    return coord_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Then input original image and the coord_df to output the mask with unique annotations (1..N, N = 8 in this case):\n",
    "def create_mask_multi_annot(xml_path, image_size = (256,256)):\n",
    "    mask = np.zeros(image_size, dtype=np.uint8)\n",
    "    iter_order = [6, 5, 4, 1, 2, 3, 8, 7] #[ecm acini fat islet duct vessels nerves whitespace/noise]\n",
    "    coord_df = coord_to_multiclass_df(xml_path)  #use function above\n",
    "    for i in iter_order:\n",
    "        coord_df_tmp = coord_df[coord_df.ClassNames == i]\n",
    "        for idx, row in coord_df_tmp.iterrows():\n",
    "            xx = row.X.astype(float).astype('int32')\n",
    "            yy = row.Y.astype(float).astype('int32')\n",
    "            contours = np.array(list(zip(xx, yy)))\n",
    "            class_number = row.ClassNames\n",
    "            mask = cv2.fillPoly(mask, pts=[contours.astype(int)], color=(int(class_number)))\n",
    "            binary_mask = mask > 0\n",
    "            binary_mask = binary_mask.astype(np.uint8)\n",
    "    return mask, binary_mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      "  5%|▌         | 1/20 [00:00<00:05,  3.60it/s]\u001B[A\n",
      " 20%|██        | 4/20 [00:00<00:01, 11.64it/s]\u001B[A\n",
      " 30%|███       | 6/20 [00:00<00:01, 13.62it/s]\u001B[A\n",
      " 45%|████▌     | 9/20 [00:00<00:00, 16.53it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 18.69it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 20.09it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:01<00:00, 16.43it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:01<00:06,  1.23s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 24.92it/s]\u001B[A\n",
      " 30%|███       | 6/20 [00:00<00:00, 24.19it/s]\u001B[A\n",
      " 45%|████▌     | 9/20 [00:00<00:00, 24.37it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 24.25it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 22.52it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 23.15it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:02<00:04,  1.01s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 25.01it/s]\u001B[A\n",
      " 30%|███       | 6/20 [00:00<00:00, 27.72it/s]\u001B[A\n",
      " 45%|████▌     | 9/20 [00:00<00:00, 26.39it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 25.83it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 26.33it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 25.97it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:02<00:02,  1.10it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 27.29it/s]\u001B[A\n",
      " 30%|███       | 6/20 [00:00<00:00, 27.86it/s]\u001B[A\n",
      " 45%|████▌     | 9/20 [00:00<00:00, 27.58it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 24.78it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 22.21it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 22.86it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:03<00:01,  1.11it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 10%|█         | 2/20 [00:00<00:01, 11.11it/s]\u001B[A\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 17.13it/s]\u001B[A\n",
      " 40%|████      | 8/20 [00:00<00:00, 19.03it/s]\u001B[A\n",
      " 55%|█████▌    | 11/20 [00:00<00:00, 19.80it/s]\u001B[A\n",
      " 70%|███████   | 14/20 [00:00<00:00, 21.62it/s]\u001B[A\n",
      " 85%|████████▌ | 17/20 [00:00<00:00, 22.68it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 21.26it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:04<00:00,  1.09it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 24.56it/s]\u001B[A\n",
      " 30%|███       | 6/20 [00:00<00:00, 23.88it/s]\u001B[A\n",
      " 45%|████▌     | 9/20 [00:00<00:00, 24.38it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 23.43it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 22.64it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 22.57it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# for loop of using create_binary_mask_label to save binary and image_mask in the annotation folder:\n",
    "for file in tqdm(file_src):\n",
    "    xml_path = [os.path.join(file,x) for x in os.listdir(file) if x.endswith(\".xml\")]\n",
    "    img_path = [os.path.join(file,x) for x in os.listdir(file) if x.endswith(\".jpg\")]\n",
    "    if len(xml_path) != len(img_path):\n",
    "        assert(\"xml and .jpg files mismatch\")\n",
    "    mask_save_path = os.path.join(file,\"mask\")\n",
    "    bin_mask_save_path = os.path.join(file,\"bin_mask\")\n",
    "    if not os.path.exists(mask_save_path):\n",
    "        os.makedirs(mask_save_path)\n",
    "    if not os.path.exists(bin_mask_save_path):\n",
    "        os.makedirs(bin_mask_save_path)\n",
    "    for xml_file in tqdm(xml_path):\n",
    "        image_name = os.path.basename(xml_file).replace(\"xml\",\"png\")\n",
    "        mask_test, bin_mask_test = create_mask_multi_annot(xml_file)\n",
    "        Image.fromarray(mask_test).save(os.path.join(mask_save_path,image_name))\n",
    "        Image.fromarray(bin_mask_test).save(os.path.join(bin_mask_save_path,image_name))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Part 2: Code to use the above saved binary mask and apply it to the pix2pix, pyramid-pix2pix, and I2SB and I2SB-cond segmentation map:\n",
    "### Note: First need to run segmentation on MATLAB to get the tissue map of the inferred pix2pix/i2sb:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For pix2pix:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def rename_images(image_path):\n",
    "    file_list = [os.path.join(image_path, x) for x in os.listdir(image_path) if x.endswith(\".png\")]\n",
    "    for filename in tqdm(file_list):\n",
    "        if \"IMMUNE\" in filename:\n",
    "            os.rename(filename, filename.replace(\"IMMUNE\",\"HE\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:00<00:00, 201.98it/s]\n"
     ]
    }
   ],
   "source": [
    "rename_images(r\"\\\\10.99.68.178\\ashleyex\\Type_1_diabetes\\IHC to HE model\\annotation_jpg\\inferred\\pix2pix\\classification_01032024\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 30.00it/s]\u001B[A\n",
      " 30%|███       | 6/20 [00:00<00:00, 28.29it/s]\u001B[A\n",
      " 50%|█████     | 10/20 [00:00<00:00, 30.42it/s]\u001B[A\n",
      " 70%|███████   | 14/20 [00:00<00:00, 28.91it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 29.39it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:00<00:03,  1.43it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 30.00it/s]\u001B[A\n",
      " 35%|███▌      | 7/20 [00:00<00:00, 32.21it/s]\u001B[A\n",
      " 55%|█████▌    | 11/20 [00:00<00:00, 28.27it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 29.22it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 29.47it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:01<00:02,  1.43it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 20%|██        | 4/20 [00:00<00:00, 28.52it/s]\u001B[A\n",
      " 35%|███▌      | 7/20 [00:00<00:00, 26.58it/s]\u001B[A\n",
      " 50%|█████     | 10/20 [00:00<00:00, 26.87it/s]\u001B[A\n",
      " 70%|███████   | 14/20 [00:00<00:00, 29.21it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 29.82it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:02<00:02,  1.44it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 20%|██        | 4/20 [00:00<00:00, 30.77it/s]\u001B[A\n",
      " 40%|████      | 8/20 [00:00<00:00, 29.44it/s]\u001B[A\n",
      " 55%|█████▌    | 11/20 [00:00<00:00, 26.09it/s]\u001B[A\n",
      " 70%|███████   | 14/20 [00:00<00:00, 27.29it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 29.45it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.44it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 23.64it/s]\u001B[A\n",
      " 30%|███       | 6/20 [00:00<00:00, 25.70it/s]\u001B[A\n",
      " 50%|█████     | 10/20 [00:00<00:00, 30.41it/s]\u001B[A\n",
      " 70%|███████   | 14/20 [00:00<00:00, 30.56it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 29.13it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.43it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 22.02it/s]\u001B[A\n",
      " 30%|███       | 6/20 [00:00<00:00, 24.83it/s]\u001B[A\n",
      " 45%|████▌     | 9/20 [00:00<00:00, 24.91it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 24.61it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 25.05it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 26.10it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# for the file name, for IHCA, replace islet with HE, for B, replace vessel with HE, for C, replace immune with HE for file base name:\n",
    "p2p_mask_dir = r\"\\\\10.99.68.178\\ashleyex\\Type_1_diabetes\\IHC to HE model\\annotation_jpg\\inferred\\pix2pix\\classification_01032024\" # path directory to tissue map of the pix2pix generated images\n",
    "for file in tqdm(file_src):\n",
    "    bin_mask_file = os.path.join(file,\"bin_mask\")\n",
    "    bin_mask_path_src = [os.path.join(bin_mask_file,x) for x in os.listdir(bin_mask_file) if x.endswith(\".png\")]\n",
    "    infer_mask_save_path = os.path.join(file,\"pix2pix_mask\")\n",
    "    if not os.path.exists(infer_mask_save_path):\n",
    "        os.makedirs(infer_mask_save_path)\n",
    "    for bin_mask_path in tqdm(bin_mask_path_src):\n",
    "        mask_name = os.path.basename(bin_mask_path)\n",
    "        if \"IHCA\" in file:\n",
    "            file_name = mask_name.replace(\"ISLET\",\"HE\")\n",
    "            # file_name = file_name.replace(\".png\",\"_output.png\")\n",
    "        elif \"IHCB\" in file:\n",
    "            file_name = mask_name.replace(\"VESSEL\",\"HE\")\n",
    "            # file_name = file_name.replace(\".png\",\"_output.png\")\n",
    "        elif \"IHCC\" in file:\n",
    "            file_name = mask_name.replace(\"IMMUNE\",\"HE\")\n",
    "            # file_name = file_name.replace(\".png\",\"_output.png\")\n",
    "        infer_mask_path = os.path.join(p2p_mask_dir,file_name)\n",
    "        infer_mask = np.array(cv2.imread(infer_mask_path,0))\n",
    "        bin_mask = np.array(cv2.imread(bin_mask_path,0))\n",
    "        infer_mask_edit = infer_mask * bin_mask\n",
    "        Image.fromarray(infer_mask_edit).save(os.path.join(infer_mask_save_path,file_name))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For pyramid-pix2pix:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Since it was trained on 1024 x 1024, need to first get the 256x256 portion of the image and then its respective mask saved elsewhere to do the same for p-pix2pix. Below is the code to extract the respective mask:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 29.68it/s]\u001B[A\n",
      " 35%|███▌      | 7/20 [00:00<00:00, 34.03it/s]\u001B[A\n",
      " 55%|█████▌    | 11/20 [00:00<00:00, 35.36it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 34.95it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 33.95it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:00<00:03,  1.66it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 20%|██        | 4/20 [00:00<00:00, 31.45it/s]\u001B[A\n",
      " 40%|████      | 8/20 [00:00<00:00, 35.78it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 31.57it/s]\u001B[A\n",
      " 80%|████████  | 16/20 [00:00<00:00, 33.14it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 32.52it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:01<00:02,  1.62it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 20%|██        | 4/20 [00:00<00:00, 30.49it/s]\u001B[A\n",
      " 40%|████      | 8/20 [00:00<00:00, 33.06it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 35.40it/s]\u001B[A\n",
      " 80%|████████  | 16/20 [00:00<00:00, 33.83it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 31.56it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:01<00:01,  1.59it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 20%|██        | 4/20 [00:00<00:00, 32.21it/s]\u001B[A\n",
      " 40%|████      | 8/20 [00:00<00:00, 33.11it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 32.28it/s]\u001B[A\n",
      " 80%|████████  | 16/20 [00:00<00:00, 32.23it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 31.05it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.56it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 29.22it/s]\u001B[A\n",
      " 35%|███▌      | 7/20 [00:00<00:00, 30.02it/s]\u001B[A\n",
      " 55%|█████▌    | 11/20 [00:00<00:00, 30.63it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 30.31it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 30.26it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.53it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 20%|██        | 4/20 [00:00<00:00, 35.31it/s]\u001B[A\n",
      " 40%|████      | 8/20 [00:00<00:00, 35.21it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 36.01it/s]\u001B[A\n",
      " 80%|████████  | 16/20 [00:00<00:00, 32.90it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 33.76it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# for the file name, for IHCA, replace islet with HE, for B, replace vessel with HE, for C, replace immune with HE for file base name:\n",
    "p_p2p_mask_dir = r\"\\\\10.99.68.178\\ashleyex\\Type_1_diabetes\\IHC to HE model\\annotation_jpg\\p-pix2pix-inferred\\classification_01042024\"# path directory to tissue map of the pyramid-pix2pix generated images (note these are 1024 x 1024 unlike all others)\n",
    "for file in tqdm(file_src):\n",
    "    bin_mask_file = os.path.join(file,\"bin_mask\")\n",
    "    bin_mask_path_src = [os.path.join(bin_mask_file,x) for x in os.listdir(bin_mask_file) if x.endswith(\".png\")]\n",
    "    infer_mask_save_path = os.path.join(file,\"pyramid_pix2pix_mask\")\n",
    "    if not os.path.exists(infer_mask_save_path):\n",
    "        os.makedirs(infer_mask_save_path)\n",
    "    for bin_mask_path in tqdm(bin_mask_path_src):\n",
    "        mask_name = os.path.basename(bin_mask_path)\n",
    "        if \"IHCA\" in file:\n",
    "            file_name = mask_name.replace(\"ISLET_\",\"\")\n",
    "        elif \"IHCB\" in file:\n",
    "            file_name = mask_name.replace(\"VESSEL_\",\"\")\n",
    "        elif \"IHCC\" in file:\n",
    "            file_name = mask_name.replace(\"IMMUNE_\",\"\")\n",
    "        infer_mask_path = os.path.join(p_p2p_mask_dir,file_name)\n",
    "        real_infer_mask_path = infer_mask_path[:-7]+\".png\"\n",
    "        x = int(infer_mask_path[-6:-5])\n",
    "        y = int(infer_mask_path[-5:-4])\n",
    "        infer_mask = np.array(cv2.imread(real_infer_mask_path,0))\n",
    "        infer_mask = infer_mask[(y-1)*256:y*256,(x-1)*256:x*256]\n",
    "        bin_mask = np.array(cv2.imread(bin_mask_path,0))\n",
    "        infer_mask_edit = infer_mask * bin_mask\n",
    "        Image.fromarray(infer_mask_edit).save(os.path.join(infer_mask_save_path,file_name))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For I2SB:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['\\\\\\\\10.99.68.178\\\\ashleyex\\\\Type_1_diabetes\\\\IHC to HE model\\\\annotation_jpg\\\\S1_IHCA',\n '\\\\\\\\10.99.68.178\\\\ashleyex\\\\Type_1_diabetes\\\\IHC to HE model\\\\annotation_jpg\\\\S1_IHCB',\n '\\\\\\\\10.99.68.178\\\\ashleyex\\\\Type_1_diabetes\\\\IHC to HE model\\\\annotation_jpg\\\\S1_IHCC',\n '\\\\\\\\10.99.68.178\\\\ashleyex\\\\Type_1_diabetes\\\\IHC to HE model\\\\annotation_jpg\\\\S2_IHCA',\n '\\\\\\\\10.99.68.178\\\\ashleyex\\\\Type_1_diabetes\\\\IHC to HE model\\\\annotation_jpg\\\\S2_IHCB',\n '\\\\\\\\10.99.68.178\\\\ashleyex\\\\Type_1_diabetes\\\\IHC to HE model\\\\annotation_jpg\\\\S2_IHCC']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_src"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 25.40it/s]\u001B[A\n",
      " 30%|███       | 6/20 [00:00<00:01, 14.00it/s]\u001B[A\n",
      " 50%|█████     | 10/20 [00:00<00:00, 20.19it/s]\u001B[A\n",
      " 65%|██████▌   | 13/20 [00:00<00:00, 12.37it/s]\u001B[A\n",
      " 80%|████████  | 16/20 [00:01<00:00, 15.47it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:01<00:00, 14.47it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:01<00:06,  1.40s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 20%|██        | 4/20 [00:00<00:00, 31.97it/s]\u001B[A\n",
      " 40%|████      | 8/20 [00:00<00:00, 31.98it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 16.10it/s]\u001B[A\n",
      " 80%|████████  | 16/20 [00:01<00:00, 13.10it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:01<00:00, 17.11it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:02<00:05,  1.27s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 27.42it/s]\u001B[A\n",
      " 35%|███▌      | 7/20 [00:00<00:00, 31.22it/s]\u001B[A\n",
      " 55%|█████▌    | 11/20 [00:00<00:00, 31.60it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 30.23it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 30.77it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:03<00:02,  1.00it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 27.98it/s]\u001B[A\n",
      " 35%|███▌      | 7/20 [00:00<00:00, 29.84it/s]\u001B[A\n",
      " 55%|█████▌    | 11/20 [00:00<00:00, 30.84it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 31.31it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 29.84it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:03<00:01,  1.13it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 20%|██        | 4/20 [00:00<00:00, 32.00it/s]\u001B[A\n",
      " 40%|████      | 8/20 [00:00<00:00, 31.99it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 29.92it/s]\u001B[A\n",
      " 80%|████████  | 16/20 [00:00<00:00, 30.38it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 30.88it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:04<00:00,  1.24it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 23.99it/s]\u001B[A\n",
      " 30%|███       | 6/20 [00:00<00:00, 23.19it/s]\u001B[A\n",
      " 45%|████▌     | 9/20 [00:00<00:00, 25.16it/s]\u001B[A\n",
      " 65%|██████▌   | 13/20 [00:00<00:00, 27.94it/s]\u001B[A\n",
      " 85%|████████▌ | 17/20 [00:00<00:00, 28.14it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 27.29it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# for the file name, for IHCA, replace islet with HE, for B, replace vessel with HE, for C, replace immune with HE for file base name:\n",
    "i2sb_mask_dir = r\"\\\\10.99.68.178\\ashleyex\\Type_1_diabetes\\IHC to HE model\\annotation_jpg\\inferred\\I2SB\\test-run-4\\iter_24388\\classification_01022024\"\n",
    "for file in tqdm(file_src):\n",
    "    bin_mask_file = os.path.join(file,\"bin_mask\")\n",
    "    bin_mask_path_src = [os.path.join(bin_mask_file,x) for x in os.listdir(bin_mask_file) if x.endswith(\".png\")]\n",
    "    infer_mask_save_path = os.path.join(file,\"i2sb_infer_seg_map\")\n",
    "    if not os.path.exists(infer_mask_save_path):\n",
    "        os.makedirs(infer_mask_save_path)\n",
    "    for bin_mask_path in tqdm(bin_mask_path_src):\n",
    "        mask_name = os.path.basename(bin_mask_path)\n",
    "        if \"IHCA\" in file:\n",
    "            file_name = mask_name.replace(\"ISLET\",\"HE\")\n",
    "            file_name = file_name.replace(\".png\",\"_inferred.png\")\n",
    "        elif \"IHCB\" in file:\n",
    "            file_name = mask_name.replace(\"VESSEL\",\"HE\")\n",
    "            file_name = file_name.replace(\".png\",\"_inferred.png\")\n",
    "        elif \"IHCC\" in file:\n",
    "            file_name = mask_name.replace(\"IMMUNE\",\"HE\")\n",
    "            file_name = file_name.replace(\".png\",\"_inferred.png\")\n",
    "        infer_mask_path = os.path.join(i2sb_mask_dir,file_name)\n",
    "        infer_mask = np.array(cv2.imread(infer_mask_path,0))\n",
    "        bin_mask = np.array(cv2.imread(bin_mask_path,0))\n",
    "        infer_mask_edit = infer_mask * bin_mask\n",
    "        Image.fromarray(infer_mask_edit).save(os.path.join(infer_mask_save_path,file_name))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For I2SB-cond:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 10%|█         | 2/20 [00:00<00:00, 18.29it/s]\u001B[A\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 23.67it/s]\u001B[A\n",
      " 45%|████▌     | 9/20 [00:00<00:00, 29.24it/s]\u001B[A\n",
      " 65%|██████▌   | 13/20 [00:00<00:00, 29.53it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 29.27it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:00<00:03,  1.43it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 28.56it/s]\u001B[A\n",
      " 35%|███▌      | 7/20 [00:00<00:00, 33.36it/s]\u001B[A\n",
      " 55%|█████▌    | 11/20 [00:00<00:00, 29.09it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 31.75it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 30.00it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:01<00:02,  1.45it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 20%|██        | 4/20 [00:00<00:00, 35.12it/s]\u001B[A\n",
      " 40%|████      | 8/20 [00:00<00:00, 34.70it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 35.53it/s]\u001B[A\n",
      " 80%|████████  | 16/20 [00:00<00:00, 33.95it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 34.10it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:01<00:01,  1.54it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 20%|██        | 4/20 [00:00<00:00, 33.25it/s]\u001B[A\n",
      " 40%|████      | 8/20 [00:00<00:00, 32.48it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 34.23it/s]\u001B[A\n",
      " 80%|████████  | 16/20 [00:00<00:00, 30.11it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 31.39it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.51it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 20%|██        | 4/20 [00:00<00:00, 31.65it/s]\u001B[A\n",
      " 40%|████      | 8/20 [00:00<00:00, 32.81it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 34.25it/s]\u001B[A\n",
      " 80%|████████  | 16/20 [00:00<00:00, 32.18it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 32.32it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.53it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 20%|██        | 4/20 [00:00<00:00, 31.51it/s]\u001B[A\n",
      " 40%|████      | 8/20 [00:00<00:00, 32.64it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 32.35it/s]\u001B[A\n",
      " 80%|████████  | 16/20 [00:00<00:00, 32.21it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 32.38it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# for the file name, for IHCA, replace islet with HE, for B, replace vessel with HE, for C, replace immune with HE for file base name:\n",
    "i2sb_mask_dir = r\"\\\\10.99.68.178\\ashleyex\\Type_1_diabetes\\IHC to HE model\\annotation_jpg\\inferred\\I2SB-cond\\test-run-seg-map-cond\\iter_19656\\classification_01022024\"\n",
    "for file in tqdm(file_src):\n",
    "    bin_mask_file = os.path.join(file,\"bin_mask\")\n",
    "    bin_mask_path_src = [os.path.join(bin_mask_file,x) for x in os.listdir(bin_mask_file) if x.endswith(\".png\")]\n",
    "    infer_mask_save_path = os.path.join(file,\"i2sb_cond_infer_seg_map\")\n",
    "    if not os.path.exists(infer_mask_save_path):\n",
    "        os.makedirs(infer_mask_save_path)\n",
    "    for bin_mask_path in tqdm(bin_mask_path_src):\n",
    "        mask_name = os.path.basename(bin_mask_path)\n",
    "        if \"IHCA\" in file:\n",
    "            file_name = mask_name.replace(\"ISLET\",\"HE\")\n",
    "            file_name = file_name.replace(\".png\",\"_inferred.png\")\n",
    "        elif \"IHCB\" in file:\n",
    "            file_name = mask_name.replace(\"VESSEL\",\"HE\")\n",
    "            file_name = file_name.replace(\".png\",\"_inferred.png\")\n",
    "        elif \"IHCC\" in file:\n",
    "            file_name = mask_name.replace(\"IMMUNE\",\"HE\")\n",
    "            file_name = file_name.replace(\".png\",\"_inferred.png\")\n",
    "        infer_mask_path = os.path.join(i2sb_mask_dir,file_name)\n",
    "        infer_mask = np.array(cv2.imread(infer_mask_path,0))\n",
    "        bin_mask = np.array(cv2.imread(bin_mask_path,0))\n",
    "        infer_mask_edit = infer_mask * bin_mask\n",
    "        Image.fromarray(infer_mask_edit).save(os.path.join(infer_mask_save_path,file_name))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
