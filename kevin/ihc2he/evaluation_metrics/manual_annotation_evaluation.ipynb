{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Workflow to find F1 score between manual annotation evaluation of IHC image and segmentation result of inferred H&E image from CODA segmentation model:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Part 1: Code to turn manual IHC annotations saved in .xml file to a binary mask and a tissue map:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = r\"\\\\10.99.68.178\\ashleyex\\Type_1_diabetes\\IHC to HE model\\annotation_jpg\"\n",
    "file_src = [os.path.join(src,x) for x in os.listdir(src)]\n",
    "file_src = [x for x in file_src if x.split(\"_\")[-1][:3] == \"IHC\"] # all six folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# First, input xml_filepath and output a dataframe of X,Y coordinates in general. (can be used for ROI as well)\n",
    "def xml_to_df(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    append_df = []\n",
    "    for index, Annotation in enumerate(root.iter(\"Annotation\")):\n",
    "        for Region in Annotation.iter('Region'):\n",
    "            x = np.array([Vertex.get('X') for Vertex in Region.iter('Vertex')])\n",
    "            y = np.array([Vertex.get('Y') for Vertex in Region.iter('Vertex')])\n",
    "            id = np.array([int(Region.get('Id'))])\n",
    "            classnames = index + 1\n",
    "            coord_dict = {\"ClassNames\": [classnames], \"X\": [x], \"Y\": [y], \"ID\": [id]}\n",
    "            df = pd.DataFrame(data=coord_dict)\n",
    "            df.ID = df.ID.astype(int)\n",
    "            append_df.append(df)\n",
    "    coord_df = pd.concat(append_df).reset_index(drop=True)\n",
    "    return (coord_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Then, input xml_path to use xml_to_df function to output X,Y coordinates for each annotation per class:\n",
    "def coord_to_multiclass_df(xml_path):\n",
    "    coord_df = xml_to_df(xml_path)\n",
    "    coord_df = coord_df.drop(columns=[\"ID\"])\n",
    "    dict = {\"islet\": 1, \"duct\": 2, \"vessels\": 3, \"fat\": 4, \"acini\": 5, \"ecm\": 6, \"whitespace\": 7,\n",
    "            \"nerves\": 8}\n",
    "    coord_df = coord_df.replace({\"ClassNames\": dict})\n",
    "    return coord_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Then input original image and the coord_df to output the mask with unique annotations (1..N, N = 8 in this case):\n",
    "def create_mask_multi_annot(xml_path, image_size = (256,256)):\n",
    "    mask = np.zeros(image_size, dtype=np.uint8)\n",
    "    iter_order = [6, 5, 4, 1, 2, 3, 8, 7] #[ecm acini fat islet duct vessels nerves whitespace/noise]\n",
    "    coord_df = coord_to_multiclass_df(xml_path)  #use function above\n",
    "    for i in iter_order:\n",
    "        coord_df_tmp = coord_df[coord_df.ClassNames == i]\n",
    "        for idx, row in coord_df_tmp.iterrows():\n",
    "            xx = row.X.astype(float).astype('int32')\n",
    "            yy = row.Y.astype(float).astype('int32')\n",
    "            contours = np.array(list(zip(xx, yy)))\n",
    "            class_number = row.ClassNames\n",
    "            mask = cv2.fillPoly(mask, pts=[contours.astype(int)], color=(int(class_number)))\n",
    "            binary_mask = mask > 0\n",
    "            binary_mask = binary_mask.astype(np.uint8)\n",
    "    return mask, binary_mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      "  5%|▌         | 1/20 [00:00<00:05,  3.60it/s]\u001B[A\n",
      " 20%|██        | 4/20 [00:00<00:01, 11.64it/s]\u001B[A\n",
      " 30%|███       | 6/20 [00:00<00:01, 13.62it/s]\u001B[A\n",
      " 45%|████▌     | 9/20 [00:00<00:00, 16.53it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 18.69it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 20.09it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:01<00:00, 16.43it/s]\u001B[A\n",
      " 17%|█▋        | 1/6 [00:01<00:06,  1.23s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 24.92it/s]\u001B[A\n",
      " 30%|███       | 6/20 [00:00<00:00, 24.19it/s]\u001B[A\n",
      " 45%|████▌     | 9/20 [00:00<00:00, 24.37it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 24.25it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 22.52it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 23.15it/s]\u001B[A\n",
      " 33%|███▎      | 2/6 [00:02<00:04,  1.01s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 25.01it/s]\u001B[A\n",
      " 30%|███       | 6/20 [00:00<00:00, 27.72it/s]\u001B[A\n",
      " 45%|████▌     | 9/20 [00:00<00:00, 26.39it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 25.83it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 26.33it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 25.97it/s]\u001B[A\n",
      " 50%|█████     | 3/6 [00:02<00:02,  1.10it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 27.29it/s]\u001B[A\n",
      " 30%|███       | 6/20 [00:00<00:00, 27.86it/s]\u001B[A\n",
      " 45%|████▌     | 9/20 [00:00<00:00, 27.58it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 24.78it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 22.21it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 22.86it/s]\u001B[A\n",
      " 67%|██████▋   | 4/6 [00:03<00:01,  1.11it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 10%|█         | 2/20 [00:00<00:01, 11.11it/s]\u001B[A\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 17.13it/s]\u001B[A\n",
      " 40%|████      | 8/20 [00:00<00:00, 19.03it/s]\u001B[A\n",
      " 55%|█████▌    | 11/20 [00:00<00:00, 19.80it/s]\u001B[A\n",
      " 70%|███████   | 14/20 [00:00<00:00, 21.62it/s]\u001B[A\n",
      " 85%|████████▌ | 17/20 [00:00<00:00, 22.68it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 21.26it/s]\u001B[A\n",
      " 83%|████████▎ | 5/6 [00:04<00:00,  1.09it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 24.56it/s]\u001B[A\n",
      " 30%|███       | 6/20 [00:00<00:00, 23.88it/s]\u001B[A\n",
      " 45%|████▌     | 9/20 [00:00<00:00, 24.38it/s]\u001B[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 23.43it/s]\u001B[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 22.64it/s]\u001B[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 22.57it/s]\u001B[A\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# for loop of using create_binary_mask_label to save binary and image_mask in the annotation folder:\n",
    "for file in tqdm(file_src):\n",
    "    xml_path = [os.path.join(file,x) for x in os.listdir(file) if x.endswith(\".xml\")]\n",
    "    img_path = [os.path.join(file,x) for x in os.listdir(file) if x.endswith(\".jpg\")]\n",
    "    if len(xml_path) != len(img_path):\n",
    "        assert(\"xml and .jpg files mismatch\")\n",
    "    mask_save_path = os.path.join(file,\"mask\")\n",
    "    bin_mask_save_path = os.path.join(file,\"bin_mask\")\n",
    "    if not os.path.exists(mask_save_path):\n",
    "        os.makedirs(mask_save_path)\n",
    "    if not os.path.exists(bin_mask_save_path):\n",
    "        os.makedirs(bin_mask_save_path)\n",
    "    for xml_file in tqdm(xml_path):\n",
    "        image_name = os.path.basename(xml_file).replace(\"xml\",\"png\")\n",
    "        mask_test, bin_mask_test = create_mask_multi_annot(xml_file)\n",
    "        Image.fromarray(mask_test).save(os.path.join(mask_save_path,image_name))\n",
    "        Image.fromarray(bin_mask_test).save(os.path.join(bin_mask_save_path,image_name))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code to use the above saved binary mask and apply it to the pix2pix, pyramid-pix2pix, and I2SB segmentation map:\n",
    "### For pix2pix:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[75], line 23\u001B[0m\n\u001B[0;32m     21\u001B[0m infer_mask \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(cv2\u001B[38;5;241m.\u001B[39mimread(infer_mask_path,\u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m     22\u001B[0m bin_mask \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(cv2\u001B[38;5;241m.\u001B[39mimread(bin_mask_path,\u001B[38;5;241m0\u001B[39m))\n\u001B[1;32m---> 23\u001B[0m GT_mask_edit \u001B[38;5;241m=\u001B[39m \u001B[43minfer_mask\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbin_mask\u001B[49m\n\u001B[0;32m     24\u001B[0m Image\u001B[38;5;241m.\u001B[39mfromarray(GT_mask_edit)\u001B[38;5;241m.\u001B[39msave(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(infer_mask_save_path,file_name))\n",
      "\u001B[1;31mTypeError\u001B[0m: unsupported operand type(s) for *: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "# for the file name, for IHCA, replace islet with HE, for B, replace vessel with HE, for C, replace immune with HE for file base name:\n",
    "p2p_mask_dir = r\"\\\\10.99.68.51\\Kyu\\IHC2HE\\Balanced_Aligned\\dataset_v1_256x256\\infer\\test\\pix2pix\\classification_10162023\"\n",
    "for file in tqdm(file_src):\n",
    "    bin_mask_file = os.path.join(file,\"bin_mask\")\n",
    "    bin_mask_path_src = [os.path.join(bin_mask_file,x) for x in os.listdir(bin_mask_file) if x.endswith(\".png\")]\n",
    "    infer_mask_save_path = os.path.join(file,\"pix2pix_mask\")\n",
    "    if not os.path.exists(infer_mask_save_path):\n",
    "        os.makedirs(infer_mask_save_path)\n",
    "    for bin_mask_path in tqdm(bin_mask_path_src):\n",
    "        mask_name = os.path.basename(bin_mask_path)\n",
    "        if \"IHCA\" in file:\n",
    "            file_name = mask_name.replace(\"ISLET\",\"HE\")\n",
    "            file_name = file_name.replace(\".png\",\"_output.png\")\n",
    "        elif \"IHCB\" in file:\n",
    "            file_name = mask_name.replace(\"VESSEL\",\"HE\")\n",
    "            file_name = file_name.replace(\".png\",\"_output.png\")\n",
    "        elif \"IHCC\" in file:\n",
    "            file_name = mask_name.replace(\"IMMUNE\",\"HE\")\n",
    "            file_name = file_name.replace(\".png\",\"_output.png\")\n",
    "        infer_mask_path = os.path.join(p2p_mask_dir,file_name)\n",
    "        infer_mask = np.array(cv2.imread(infer_mask_path,0))\n",
    "        bin_mask = np.array(cv2.imread(bin_mask_path,0))\n",
    "        infer_mask_edit = infer_mask * bin_mask\n",
    "        Image.fromarray(infer_mask_edit).save(os.path.join(infer_mask_save_path,file_name))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\\\\\\\10.99.68.51\\\\Kyu\\\\IHC2HE\\\\Balanced_Aligned\\\\dataset_v1_256x256\\\\infer\\\\pix2pix\\\\classification_10162023\\\\sample 1_IHCA 08_23_2023_HE_image_tile_00074_12_output.png'"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_mask_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For pyramid-pix2pix:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# p_p2p_mask_dir =\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For I2SB-uncond:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# i2sb_mask_dir ="
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For I2SB-cond:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# i2sb_mask_dir ="
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
