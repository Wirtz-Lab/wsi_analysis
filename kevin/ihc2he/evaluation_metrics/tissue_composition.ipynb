{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Code to calculate tissue composition in GT tissue map, vs pix2pix, pyramid pix2pix, and I2SB:\n",
    "### Since this is to calculate bulk tissue composition so that it is invariant to the slight pixel offsets vs GT, all you have to do is just sum up the masks and then represent the tissue composition as % by dividing by the total pixel area."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# for i2sb, it is tmp, when finish sampling I2SB, do evaluation on all data:\n",
    "gt_pth = r\"\\\\10.99.68.51\\Kyu\\IHC2HE\\Balanced_Aligned\\dataset_v1_256x256\\val\\HE\\classification_10172023\"\n",
    "p2p_pth = r\"\\\\10.99.68.51\\Kyu\\IHC2HE\\Balanced_Aligned\\dataset_v1_256x256\\infer\\pix2pix_sample1_only\\classification_10162023\"\n",
    "# p_p2p_pth = # tbd\n",
    "# i2sb_pth = # tbd\n",
    "\n",
    "gt_images = [os.path.join(gt_pth,x) for x in os.listdir(gt_pth) if x.endswith(\".png\")]\n",
    "p2p_images = [os.path.join(p2p_pth,x) for x in os.listdir(p2p_pth) if x.endswith(\".png\")]\n",
    "# p_p2p_images = [os.path.join(p_p2p_pth,x) for x in os.listdir(p_p2p_pth) if x.endswith(\".png\")]\n",
    "# i2sb_images = [os.path.join(i2sb_pth,x) for x in os.listdir(i2sb_pth) if x.endswith(\".png\")]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "def return_tissue_composition(image_directory):\n",
    "    pixel_value_counts = np.zeros(9, dtype=int)\n",
    "    for filename in tqdm(image_directory,colour=\"red\"):\n",
    "        image = cv2.imread(filename, 0)\n",
    "        unique, counts = np.unique(image, return_counts=True)\n",
    "        pixel_value_counts[unique] += counts\n",
    "    tissue_comp = [x/pixel_value_counts.sum() for x in pixel_value_counts]\n",
    "    tissue_comp = [x*100 for x in tissue_comp]\n",
    "    tissue_comp = tissue_comp[1:]\n",
    "    return tissue_comp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001B[31m██████████\u001B[0m| 9952/9952 [01:38<00:00, 101.32it/s]\n",
      "100%|\u001B[31m██████████\u001B[0m| 9952/9952 [01:43<00:00, 95.81it/s] \n"
     ]
    }
   ],
   "source": [
    "gt_pixel_value_counts = return_tissue_composition(gt_images)\n",
    "p2p_pixel_value_counts = return_tissue_composition(p2p_images)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "def find_MAE(list1,list2):\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Lists must be of equal length\")\n",
    "    absolute_differences = [abs(a - b) for a, b in zip(list1, list2)]\n",
    "    mae = sum(absolute_differences) / len(absolute_differences)\n",
    "    return mae"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0859945196047474"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_MAE(gt_pixel_value_counts,p2p_pixel_value_counts)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Note: 1~8 in order: islet duct vessels fat acini collagen whitespace nerves"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.2802698558549789,\n 0.3572813567624598,\n 1.2948856476418842,\n 8.554825982096878,\n 55.89510497556238,\n 16.26526489135153,\n 17.233209211343354,\n 0.11915807938652408]"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2p_pixel_value_counts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "[1.145437676040306,\n 0.7418683104193096,\n 1.7018703019120685,\n 6.052104913153449,\n 56.5369057118701,\n 14.424007881875973,\n 19.155930092863716,\n 0.2418751118650774]"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_pixel_value_counts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
