{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Code to calculate tissue composition in GT tissue map, vs pix2pix, pyramid pix2pix, and I2SB:\n",
    "### Since this is to calculate bulk tissue composition so that it is invariant to the slight pixel offsets vs GT, all you have to do is just sum up the masks and then represent the tissue composition as % by dividing by the total pixel area."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# for i2sb, it is tmp, when finish sampling I2SB, do evaluation on all data:\n",
    "gt_pth = r\"\\\\10.99.68.51\\Kyu\\IHC2HE\\Balanced_Aligned\\dataset_v1_256x256\\val\\HE\\classification_10172023\"\n",
    "# p2p_pth = r\"\\\\10.99.68.51\\Kyu\\IHC2HE\\Balanced_Aligned\\dataset_v1_256x256\\infer\\pix2pix_sample1_only\\classification_10162023\"\n",
    "gt_large_pth = r\"\\\\10.99.68.51\\Kyu\\IHC2HE\\Balanced_Aligned\\dataset_v1\\val\\HE\\classification_11242023\"\n",
    "\n",
    "p_p2p_pth = r\"\\\\10.99.68.51\\Kyu\\IHC2HE\\Balanced_Aligned\\dataset_v1\\infer\\pyramid-pix2pix\\classification_12262023\"\n",
    "i2sb_pth = r\"\\\\10.99.68.51\\Kyu\\IHC2HE\\Balanced_Aligned\\dataset_v1_256x256\\infer\\i2sb\\unconditional\\test-run-4\\iter_24388\\classification_12262023\"\n",
    "i2sb_cond_pth = r\"\\\\10.99.68.51\\Kyu\\IHC2HE\\Balanced_Aligned\\dataset_v1_256x256\\infer\\i2sb\\conditional\\test-run-seg-map-cond\\iter_19656\\classification_12302023\"\n",
    "\n",
    "gt_images = [os.path.join(gt_pth,x) for x in os.listdir(gt_pth) if x.endswith(\".png\")]\n",
    "gt_large_images = [os.path.join(gt_large_pth,x) for x in os.listdir(gt_large_pth) if x.endswith(\".png\")]\n",
    "# p2p_images = [os.path.join(p2p_pth,x) for x in os.listdir(p2p_pth) if x.endswith(\".png\")]\n",
    "p_p2p_images = [os.path.join(p_p2p_pth,x) for x in os.listdir(p_p2p_pth) if x.endswith(\".png\")]\n",
    "i2sb_images = [os.path.join(i2sb_pth,x) for x in os.listdir(i2sb_pth) if x.endswith(\".png\")]\n",
    "i2sb_cond_images = [os.path.join(i2sb_cond_pth,x) for x in os.listdir(i2sb_cond_pth) if x.endswith(\".png\")]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def return_tissue_composition(image_directory):\n",
    "    pixel_value_counts = np.zeros(9, dtype=int)\n",
    "    for filename in tqdm(image_directory,colour=\"red\"):\n",
    "        image = cv2.imread(filename, 0)\n",
    "        unique, counts = np.unique(image, return_counts=True)\n",
    "        pixel_value_counts[unique] += counts\n",
    "    tissue_comp = [x/pixel_value_counts.sum() for x in pixel_value_counts]\n",
    "    tissue_comp = [x*100 for x in tissue_comp]\n",
    "    tissue_comp = tissue_comp[1:]\n",
    "    return tissue_comp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001B[31m██████████\u001B[0m| 9952/9952 [01:33<00:00, 106.29it/s]\n",
      "100%|\u001B[31m██████████\u001B[0m| 622/622 [00:11<00:00, 54.96it/s]\n",
      "100%|\u001B[31m██████████\u001B[0m| 622/622 [00:11<00:00, 54.25it/s]\n",
      "100%|\u001B[31m██████████\u001B[0m| 9951/9951 [01:40<00:00, 98.73it/s] \n"
     ]
    }
   ],
   "source": [
    "gt_pixel_value_counts = return_tissue_composition(gt_images)\n",
    "gt_large_pixel_value_counts = return_tissue_composition(gt_large_images)\n",
    "p_p2p_pixel_value_counts = return_tissue_composition(p_p2p_images)\n",
    "i2sb_pixel_value_counts = return_tissue_composition(i2sb_images)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001B[31m██████████\u001B[0m| 9952/9952 [01:51<00:00, 89.34it/s] \n"
     ]
    }
   ],
   "source": [
    "i2sb_cond_pixel_value_counts = return_tissue_composition(i2sb_cond_images)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def find_MAE(list1,list2):\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Lists must be of equal length\")\n",
    "    absolute_differences = [abs(a - b) for a, b in zip(list1, list2)]\n",
    "    mae = sum(absolute_differences) / len(absolute_differences)\n",
    "    return mae"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "0.29613308584575077"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_MAE(gt_large_pixel_value_counts,p_p2p_pixel_value_counts)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "0.1764743117848524"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_MAE(gt_pixel_value_counts,i2sb_pixel_value_counts)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "0.07830149107807303"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_MAE(gt_pixel_value_counts,i2sb_cond_pixel_value_counts)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Note: 1~8 in order: islet duct vessels fat acini collagen whitespace nerves"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0.2778468791311577"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_large_pixel_value_counts[0] - p_p2p_pixel_value_counts[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "0.2679591678246587"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_pixel_value_counts[0] - i2sb_pixel_value_counts[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "0.12833742466770182"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_pixel_value_counts[0] - i2sb_cond_pixel_value_counts[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "[1.145437676040306,\n 0.7418683104193096,\n 1.7018703019120685,\n 6.052104913153449,\n 56.5369057118701,\n 14.424007881875973,\n 19.155930092863716,\n 0.2418751118650774]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_pixel_value_counts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "[1.288278923157327,\n 0.8155905548782594,\n 1.9711781161391082,\n 6.332270048822237,\n 56.27300992272674,\n 14.037663376982955,\n 18.98074962701828,\n 0.30125943027508606]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_large_pixel_value_counts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "[1.0104320440261694,\n 0.5238963860024209,\n 1.7843640502242797,\n 6.012669100255445,\n 56.97376490405901,\n 14.52144073903369,\n 18.927915303270147,\n 0.2455174731288309]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_p2p_pixel_value_counts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.8774785082156473,\n 0.6823543088182877,\n 1.632509029351243,\n 5.783905099832931,\n 56.67458121087273,\n 14.869671234017387,\n 19.27848848885908,\n 0.20101212003269145]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2sb_pixel_value_counts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "[1.0171002513726042,\n 0.7440728006638898,\n 1.8084572059165243,\n 5.923803212941651,\n 56.526892898167056,\n 14.41092031178367,\n 19.36034466292697,\n 0.208408656227627]"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2sb_cond_pixel_value_counts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
