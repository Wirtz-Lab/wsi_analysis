{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Code to generate inference data tiles to test pytorch deeplab model. Most funtions from xml2trainingdata.ipynb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OPENSLIDE_PATH = r'C:\\Users\\Kevin\\Downloads\\openslide-win64-20230414\\bin'\n",
    "\n",
    "import os\n",
    "if hasattr(os, 'add_dll_directory'):\n",
    "    # Python >= 3.8 on Windows\n",
    "    with os.add_dll_directory(OPENSLIDE_PATH):\n",
    "        import openslide\n",
    "else:\n",
    "    import openslide\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "from matplotlib import pyplot as plt\n",
    "import skimage.measure\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import torchvision.transforms as transforms\n",
    "from glob import glob\n",
    "from time import time\n",
    "from skimage.measure import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# First, input xml_filepath and output a dataframe of X,Y coordinates in general. (can be used for ROI as well)\n",
    "def xml_to_df(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    append_df = []\n",
    "    for index, Annotation in enumerate(root.iter(\"Annotation\")):\n",
    "        for Region in Annotation.iter('Region'):\n",
    "            x = np.array([Vertex.get('X') for Vertex in Region.iter('Vertex')])\n",
    "            y = np.array([Vertex.get('Y') for Vertex in Region.iter('Vertex')])\n",
    "            id = np.array([int(Region.get('Id'))])\n",
    "            classnames = index + 1\n",
    "            coord_dict = {\"ClassNames\": [classnames], \"X\": [x], \"Y\": [y], \"ID\": [id]}\n",
    "            df = pd.DataFrame(data = coord_dict)\n",
    "            df.ID = df.ID.astype(int)\n",
    "            append_df.append(df)\n",
    "    coord_df = pd.concat(append_df).reset_index(drop=True)\n",
    "    return(coord_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Then, input xml_path to use xml_to_df function to output X,Y coordinates for each annotation per class:\n",
    "def coord_to_multiclass_df(xml_path):\n",
    "    coord_df = xml_to_df(xml_path)\n",
    "    coord_df = coord_df.drop(columns = [\"ID\"])\n",
    "    dict = {\"corneum\" : 1,\"spinosum\": 2,\"hairshaft\":3,\"hairfollicle\":4,\"smoothmuscle\":5,\"oil\":6,\"sweat\":7,\"nerve\":8,\"bloodvessel\":9,\"ecm\":10,\"fat\":11,\"white\":12}\n",
    "    coord_df = coord_df.replace({\"ClassNames\": dict})\n",
    "    return coord_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "    ClassNames                                                  X  \\\n0            1  [37653, 37655, 37657, 37659, 37664, 37668, 376...   \n1            1  [43239, 43239, 43238, 43237, 43237, 43237, 432...   \n2            1  [46442, 46442, 46442, 46444, 46446, 46446, 464...   \n3            1  [40550, 40548, 40548, 40547, 40547, 40545, 405...   \n4            2  [37619, 37618, 37618, 37617, 37616, 37614, 376...   \n..         ...                                                ...   \n71          12  [43404, 43405, 43405, 43405, 43406, 43407, 434...   \n72          12  [39544, 39542, 39541, 39540, 39540, 39540, 395...   \n73          12  [36964, 36964, 36965, 36966, 36968, 36970, 369...   \n74          12  [46791, 46794, 46801, 46804, 46808, 46820, 468...   \n75          12  [40548, 40550, 40552, 40556, 40557, 40558, 405...   \n\n                                                    Y  \n0   [26262, 26264, 26264, 26264, 26264, 26266, 262...  \n1   [29633, 29634, 29634, 29636, 29637, 29638, 296...  \n2   [31652, 31654, 31656, 31659, 31661, 31663, 316...  \n3   [27686, 27686, 27684, 27684, 27682, 27682, 276...  \n4   [26556, 26556, 26555, 26555, 26555, 26555, 265...  \n..                                                ...  \n71  [29588, 29584, 29583, 29582, 29581, 29579, 295...  \n72  [36137, 36137, 36137, 36137, 36138, 36139, 361...  \n73  [30517, 30516, 30513, 30511, 30508, 30506, 305...  \n74  [31307, 31310, 31314, 31318, 31321, 31330, 313...  \n75  [27695, 27692, 27689, 27685, 27684, 27682, 276...  \n\n[76 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ClassNames</th>\n      <th>X</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[37653, 37655, 37657, 37659, 37664, 37668, 376...</td>\n      <td>[26262, 26264, 26264, 26264, 26264, 26266, 262...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[43239, 43239, 43238, 43237, 43237, 43237, 432...</td>\n      <td>[29633, 29634, 29634, 29636, 29637, 29638, 296...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>[46442, 46442, 46442, 46444, 46446, 46446, 464...</td>\n      <td>[31652, 31654, 31656, 31659, 31661, 31663, 316...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>[40550, 40548, 40548, 40547, 40547, 40545, 405...</td>\n      <td>[27686, 27686, 27684, 27684, 27682, 27682, 276...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>[37619, 37618, 37618, 37617, 37616, 37614, 376...</td>\n      <td>[26556, 26556, 26555, 26555, 26555, 26555, 265...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>12</td>\n      <td>[43404, 43405, 43405, 43405, 43406, 43407, 434...</td>\n      <td>[29588, 29584, 29583, 29582, 29581, 29579, 295...</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>12</td>\n      <td>[39544, 39542, 39541, 39540, 39540, 39540, 395...</td>\n      <td>[36137, 36137, 36137, 36137, 36138, 36139, 361...</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>12</td>\n      <td>[36964, 36964, 36965, 36966, 36968, 36970, 369...</td>\n      <td>[30517, 30516, 30513, 30511, 30508, 30506, 305...</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>12</td>\n      <td>[46791, 46794, 46801, 46804, 46808, 46820, 468...</td>\n      <td>[31307, 31310, 31314, 31318, 31321, 31330, 313...</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>12</td>\n      <td>[40548, 40550, 40552, 40556, 40557, 40558, 405...</td>\n      <td>[27695, 27692, 27689, 27685, 27684, 27682, 276...</td>\n    </tr>\n  </tbody>\n</table>\n<p>76 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_src = r\"\\\\shelter\\Kyu\\skin_aging\\clue_cohort\\annotations\\12class\\2022-06-14 15.39.21.xml\"\n",
    "img_src = r\"\\\\shelter\\Kyu\\skin_aging\\clue_cohort\\wsi\\2022-06-14 15.39.21.ndpi\"\n",
    "multi_coord_df = coord_to_multiclass_df(xml_src)\n",
    "multi_coord_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make 1024 x 1024 tiles for the xmin:xmax and ymin:ymax to get the parts of WSI with annotations. Save the corresponding 1024 x 1024 masks of the tiles. Then for each tile you put them in for inference, and then use cv2.findContours to filter out the results so that you only evaluate on the annotated part of the image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Then input original image and the coord_df to output the mask with unique annotations (1..N, N = 12 in this case):\n",
    "def create_mask_multi_annot(xml_path, image_path, downsample_factor = 1): #choose downsample factor\n",
    "    slide = openslide.open_slide(image_path)\n",
    "    target_level = slide.get_best_level_for_downsample(downsample_factor)\n",
    "    target_dim = slide.level_dimensions[target_level]\n",
    "    rsf = [x/y for x,y in zip(slide.dimensions,target_dim)] #resize factor\n",
    "    print(\"rsf is {}\".format(rsf))\n",
    "    mask = np.zeros(target_dim, dtype = np.uint8)\n",
    "    iter_order = [2,10,5,4,6,11,7,9,8,12,3,1]\n",
    "    coord_df = coord_to_multiclass_df(xml_path) #use function above\n",
    "\n",
    "    for i in iter_order:\n",
    "        coord_df_tmp = coord_df[coord_df.ClassNames == i]\n",
    "        for idx, row in coord_df_tmp.iterrows():\n",
    "            xx = row.X.astype(float).astype('int32')\n",
    "            yy = row.Y.astype(float).astype('int32')\n",
    "            contours = np.array(list(zip(xx,yy)))\n",
    "            contours = contours/rsf[0]\n",
    "            class_number = row.ClassNames\n",
    "            mask = cv2.fillPoly(mask, pts=[contours.astype(int)], color=(int(class_number)))\n",
    "    return mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "create_mask_multi_annot(xml_src,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# cv2 method:\n",
    "# Input mask and create binary mask and then output label of connected regions:\n",
    "def create_binary_mask_label(xml_path, image_path):\n",
    "    mask = create_mask_multi_annot(xml_path, image_path, downsample_factor = 1)\n",
    "    binary_mask = mask > 0\n",
    "    _, binary_mask_label = cv2.connectedComponents(binary_mask.astype(np.uint8))\n",
    "    return binary_mask_label #returns label of connected regions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Input label of connected regions and then output the final images and masks:\n",
    "def create_final_mask_image(xml_path, image_path, dstpath_mask, dstpath_image, downsample_factor = 1):\n",
    "    slide = openslide.open_slide(image_path)\n",
    "    target_level = slide.get_best_level_for_downsample(downsample_factor)\n",
    "    target_dim = slide.level_dimensions[target_level]\n",
    "    image = slide.read_region(location=(0,0),level=target_level,size=target_dim)\n",
    "    imagearr = np.array(image)\n",
    "    imagearr = imagearr[:,:,:3]\n",
    "    binary_mask_label = create_binary_mask_label(xml_path, image_path)\n",
    "    print(\"For image with xml path {}, total of {} connected objects\".format(xml_path,np.max(binary_mask_label)))\n",
    "    mask = create_mask_multi_annot(xml_path, image_path, downsample_factor = 1)\n",
    "    for idx,label in enumerate(range(1,np.max(binary_mask_label)+1)):\n",
    "        boo = binary_mask_label == label\n",
    "        boolabel = boo * label\n",
    "        loca = np.where(boolabel == label)\n",
    "        x = loca[0]\n",
    "        y = loca[1]\n",
    "        targetmask = mask[min(x):max(x),min(y):max(y)]\n",
    "        dstpth = dstpath_mask + str(idx)+'.png'\n",
    "        Image.fromarray(targetmask).save(dstpth)\n",
    "        targetim = imagearr[min(x):max(x),min(y):max(y),:]\n",
    "        dstpth1 = dstpath_image + str(idx)+'.png'\n",
    "        Image.fromarray(targetim).save(dstpth1)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
