{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Code to use all best models for 5 folds and print confusion matrix and some inferred images and save!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim import lr_scheduler\n",
    "import cv2\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "import segmentation_models_pytorch as smp\n",
    "from torchvision.models.resnet import Bottleneck, ResNet\n",
    "import pickle\n",
    "from natsort import natsorted\n",
    "from sklearn.metrics import f1_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class model_config:\n",
    "    start_fold = 1  # start CV fold to train\n",
    "    total_fold = 5  # total # of folds\n",
    "    key = \"BT\"  # key of resnet model to train if pretrained_resnet = True\n",
    "    pretrained_resnet = False  # whether to train using a pretrained resnet model\n",
    "    seed = 42  # random seed\n",
    "    train_batch_size = 4\n",
    "    valid_batch_size = 8\n",
    "    epochs = 300\n",
    "    patience = int(epochs / 10)\n",
    "    learning_rate = 0.002  # 0.001 for bs=16\n",
    "    scheduler = \"CosineAnnealingLR\"  # explore different lr schedulers, with cosineannealingLR, at T_max, the learning rate will be about half of initial lr above.\n",
    "    num_training_samples = 160\n",
    "    T_max = max(10, int(\n",
    "        num_training_samples / train_batch_size * epochs))  # number of iterations for a full cycle, need to change for different # of iterations (iteration = batch size). low BS and num_train sample -> low T_max.\n",
    "    weight_decay = 1e-6  # explore different weight decay (for Adam optimizer)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    iters_to_accumulate = max(1, 32 // train_batch_size)  # for scaling accumulated gradients, should never be <1\n",
    "    eta_min = 1e-5\n",
    "    model_save_directory = os.path.join(os.getcwd(), \"model\",\n",
    "                                        \"DeepLabV3+_baseline\")  # assuming os.getcwd is the current training script directory\n",
    "\n",
    "\n",
    "# %%\n",
    "# sets the seed of the entire notebook so results are the same every time we run for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)  # numpy specific random\n",
    "    random.seed(seed)  # python specific random (also for albumentation augmentations)\n",
    "    torch.manual_seed(seed)  # torch specific random\n",
    "    torch.cuda.manual_seed(seed)  # cuda specific random\n",
    "    # when running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False  # when deterministic = true, benchmark = False, otherwise might not be deterministic\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # set a fixed value for the hash seed, for hashes like dictionary\n",
    "\n",
    "\n",
    "set_seed(model_config.seed)  # set seed first"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_transforms = A.Compose([ToTensorV2()])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TrainDataSet(Dataset):\n",
    "    # initialize df, label, imagepath, transforms:\n",
    "    def __init__(self, image_paths: list, mask_paths: list, transforms=None, label=True):\n",
    "        self.label = label\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    # define main function to read image and label, apply transform function and return the transformed images.\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = cv2.imread(image_path, cv2.COLOR_BGR2RGB)\n",
    "        image = np.array(image)\n",
    "        if self.label:\n",
    "            mask_path = self.mask_paths[idx]\n",
    "            mask = cv2.imread(mask_path, 0)\n",
    "            mask = np.array(mask)\n",
    "            mask[mask == 13] = 0\n",
    "        if self.transforms is not None:  # albumentations\n",
    "            transformed = self.transforms(image=image, mask=mask)\n",
    "            image = transformed['image']\n",
    "            mask = transformed['mask']\n",
    "            mask = mask.unsqueeze(0)  # dtypes: image = torch.uin8, mask = torch.uint8\n",
    "        return image, mask  # return tensors of equal dtype and size\n",
    "        # image is size 3x1024x1024 and mask is size 1x1024x1024 (need dummy dimension to match dimension)\n",
    "\n",
    "\n",
    "# %%\n",
    "# define dataloading function to use above dataset to return train and val dataloaders:\n",
    "def load_dataset():\n",
    "    train_dataset = TrainDataSet(image_paths=training_images, mask_paths=training_labels, transforms=train_transforms)\n",
    "    val_dataset = TrainDataSet(image_paths=val_images, mask_paths=val_labels, transforms=val_transforms)\n",
    "    train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                                  batch_size=model_config.train_batch_size,\n",
    "                                  # pin_memory= true allows faster data transport from cpu to gpu\n",
    "                                  num_workers=0, pin_memory=True, shuffle=False)\n",
    "    val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                                batch_size=model_config.valid_batch_size,\n",
    "                                num_workers=0, pin_memory=True, shuffle=False)\n",
    "    return train_dataloader, val_dataloader  # return train and val dataloaders\n",
    "\n",
    "\n",
    "# %%\n",
    "# test to see if dataloaders return desired batch size and visualize images to see if images are indeed transformed:\n",
    "train_dataloader, val_dataloader = load_dataset()\n",
    "images, labels = next(iter(train_dataloader))\n",
    "print(\"Images have a tensor size of {}, and Labels have a tensor size of {}\".\n",
    "      format(images.size(), labels.size()))\n",
    "images, labels = next(iter(val_dataloader))\n",
    "print(\"Images have a tensor size of {}, and Labels have a tensor size of {}\".\n",
    "      format(images.size(), labels.size()))\n",
    "\n",
    "\n",
    "# %%\n",
    "def visualize_images(dataset: torch.utils.data.Dataset, num_images: int):\n",
    "    indices = random.sample(range(len(dataset)), num_images)\n",
    "    fig, axes = plt.subplots(nrows=num_images, ncols=2, figsize=(10, 12))\n",
    "    fig.tight_layout()\n",
    "    for i, ax_row in enumerate(axes):\n",
    "        index = indices[i]\n",
    "        image, mask = dataset[index]\n",
    "        if dataset.transforms is not None:\n",
    "            ax_row[0].imshow(image.permute(1, 2, 0))\n",
    "        else:\n",
    "            ax_row[0].imshow(image)\n",
    "\n",
    "        ax_row[0].set_title(\"Image\")\n",
    "        ax_row[0].axis(\"off\")\n",
    "\n",
    "        if dataset.transforms is not None:\n",
    "            ax_row[1].imshow(mask.squeeze(0), cmap=\"gray\")\n",
    "        else:\n",
    "            ax_row[1].imshow(mask, cmap=\"gray\")\n",
    "        ax_row[1].set_title(\"Mask\")\n",
    "        ax_row[1].axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize = True  # always check if transforms properly applied before training\n",
    "if visualize:\n",
    "    original_dataset = TrainDataSet(image_paths=training_images, mask_paths=training_labels, transforms=None)\n",
    "    visualize_images(original_dataset, num_images=3)\n",
    "    train_dataset = TrainDataSet(image_paths=training_images, mask_paths=training_labels, transforms=train_transforms)\n",
    "    visualize_images(train_dataset, num_images=3)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    if model_config.pretrained_resnet:  # only pretrained resnet50 available\n",
    "        model = smp.DeepLabV3Plus(encoder_name=\"resnet50\", encoder_weights=model_config.key, encoder_depth=5,\n",
    "                                  decoder_channels=512, activation=None, in_channels=3, classes=13)\n",
    "    else:  # try different encoders\n",
    "        model = smp.DeepLabV3Plus(encoder_name=\"resnet50\", encoder_weights=\"imagenet\", encoder_depth=5,\n",
    "                                  decoder_channels=512, activation=None,\n",
    "                                  in_channels=3, classes=13)\n",
    "    model.to(model_config.device)  # move model to gpu\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_f1_score(y_pred: torch.Tensor, y_true: torch.Tensor):  # y_pred in probabilities\n",
    "    y_pred = y_pred.cpu().numpy().flatten()  # 1d numpy array\n",
    "    y_true = y_true.cpu().numpy().flatten()  # 1d numpy array\n",
    "    return f1_score(y_pred, y_true,\n",
    "                    average=\"weighted\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# finally run training:\n",
    "data_src = r\"C:\\Users\\Kevin\\Desktop\\deeplab_trainingset\"\n",
    "start_fold = model_config.start_fold\n",
    "\n",
    "# repeat for all number of folds:\n",
    "for fold in range(0, model_config.total_fold):\n",
    "    current_fold = start_fold + fold\n",
    "    fold_dir = r\"v11_fold{}\".format(current_fold)\n",
    "    image_path = os.path.join(data_src, fold_dir)\n",
    "    train_dir = os.path.join(image_path, \"training\")\n",
    "    val_dir = os.path.join(image_path, \"validation\")\n",
    "\n",
    "    train_image_dir = os.path.join(train_dir, \"im\")\n",
    "    train_label_dir = os.path.join(train_dir, 'label')\n",
    "    training_images = natsorted(\n",
    "        [os.path.join(train_image_dir, x) for x in os.listdir(train_image_dir) if x.endswith(\".png\")])\n",
    "    training_labels = natsorted(\n",
    "        [os.path.join(train_label_dir, x) for x in os.listdir(train_label_dir) if x.endswith(\".png\")])\n",
    "\n",
    "    val_image_dir = os.path.join(val_dir, \"im\")\n",
    "    val_label_dir = os.path.join(val_dir, 'label')\n",
    "    val_images = natsorted([os.path.join(val_image_dir, x) for x in os.listdir(val_image_dir) if x.endswith(\".png\")])\n",
    "    train_dataloader, valid_dataloader = load_dataset()  # load datasets\n",
    "    model = build_model()  # build model\n",
    "    # print(model)\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           lr=model_config.learning_rate,\n",
    "                           weight_decay=model_config.weight_decay)  # initialize optimizer\n",
    "    scheduler = lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                               T_max=model_config.T_max,\n",
    "                                               eta_min=model_config.eta_min)  # initialize LR scheduler\n",
    "    print(\"Training for Fold {}\".format(current_fold))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
