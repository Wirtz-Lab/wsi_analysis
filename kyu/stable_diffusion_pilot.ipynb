{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers==0.4.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from diffusers==0.4.0) (2022.10.31)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from diffusers==0.4.0) (6.0.0)\n",
      "Requirement already satisfied: requests in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from diffusers==0.4.0) (2.28.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from diffusers==0.4.0) (0.12.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from diffusers==0.4.0) (1.24.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from diffusers==0.4.0) (3.9.0)\n",
      "Requirement already satisfied: torch>=1.4 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from diffusers==0.4.0) (1.13.1)\n",
      "Requirement already satisfied: Pillow<10.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from diffusers==0.4.0) (9.4.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from huggingface-hub>=0.10.0->diffusers==0.4.0) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from huggingface-hub>=0.10.0->diffusers==0.4.0) (4.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from huggingface-hub>=0.10.0->diffusers==0.4.0) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from huggingface-hub>=0.10.0->diffusers==0.4.0) (23.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from importlib-metadata->diffusers==0.4.0) (3.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from requests->diffusers==0.4.0) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from requests->diffusers==0.4.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from requests->diffusers==0.4.0) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from requests->diffusers==0.4.0) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.10.0->diffusers==0.4.0) (0.4.6)\n",
      "Requirement already satisfied: transformers==4.24.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from transformers==4.24.0) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from transformers==4.24.0) (2022.10.31)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from transformers==4.24.0) (0.12.0)\n",
      "Requirement already satisfied: requests in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from transformers==4.24.0) (2.28.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from transformers==4.24.0) (1.24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from transformers==4.24.0) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from transformers==4.24.0) (3.9.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from transformers==4.24.0) (4.64.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from transformers==4.24.0) (0.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.24.0) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from tqdm>=4.27->transformers==4.24.0) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from requests->transformers==4.24.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from requests->transformers==4.24.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from requests->transformers==4.24.0) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from requests->transformers==4.24.0) (3.0.1)\n",
      "Requirement already satisfied: ipywidgets==7.7.2 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (7.7.2)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipywidgets==7.7.2) (6.20.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipywidgets==7.7.2) (5.8.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipywidgets==7.7.2) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipywidgets==7.7.2) (3.6.1)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipywidgets==7.7.2) (1.1.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipywidgets==7.7.2) (8.8.0)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.2) (1.5.6)\n",
      "Requirement already satisfied: psutil in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.2) (5.9.4)\n",
      "Requirement already satisfied: debugpy>=1.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.2) (1.6.5)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.2) (25.0.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.2) (6.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.2) (0.1.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.2) (23.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.2) (7.4.9)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets==7.7.2) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipython>=4.0.0->ipywidgets==7.7.2) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipython>=4.0.0->ipywidgets==7.7.2) (2.14.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipython>=4.0.0->ipywidgets==7.7.2) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipython>=4.0.0->ipywidgets==7.7.2) (0.18.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipython>=4.0.0->ipywidgets==7.7.2) (0.6.2)\n",
      "Requirement already satisfied: decorator in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipython>=4.0.0->ipywidgets==7.7.2) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipython>=4.0.0->ipywidgets==7.7.2) (0.7.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ipython>=4.0.0->ipywidgets==7.7.2) (0.4.6)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (6.5.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets==7.7.2) (0.8.3)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets==7.7.2) (5.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets==7.7.2) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets==7.7.2) (0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (3.1.2)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (0.4.8)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (21.3.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (0.17.1)\n",
      "Requirement already satisfied: nbformat in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (5.7.3)\n",
      "Requirement already satisfied: nbconvert>=5 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (7.2.8)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (0.15.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=4.0.0->ipywidgets==7.7.2) (0.2.6)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets==7.7.2) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets==7.7.2) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets==7.7.2) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=4.0.0->ipywidgets==7.7.2) (1.16.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets==7.7.2) (305)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets==7.7.2) (2.6.2)\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (0.2.2)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (2.1.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (6.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (4.11.1)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (2.0.4)\n",
      "Requirement already satisfied: bleach in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (5.0.1)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (0.7.2)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (1.2.1)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (0.7.1)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (2.1.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (1.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (0.2.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (4.17.3)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (2.16.2)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (2.0.10)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (21.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from importlib-metadata>=3.6->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (3.11.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (22.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (0.19.3)\n",
      "Requirement already satisfied: jupyter-server-terminals in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (0.4.4)\n",
      "Requirement already satisfied: jupyter-events>=0.4.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (0.6.3)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (3.6.2)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (1.4.2)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (0.5.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (3.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (2.21)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (0.1.4)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (6.0)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (0.1.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (2.0.4)\n",
      "Requirement already satisfied: uri-template in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (1.2.0)\n",
      "Requirement already satisfied: isoduration in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (2.3)\n",
      "Requirement already satisfied: webcolors>=1.11 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (1.12)\n",
      "Requirement already satisfied: fqdn in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (1.5.1)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from isoduration->jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.2) (1.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: ftfy in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (6.1.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from scipy) (1.24.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages (from ftfy) (0.2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install diffusers==0.4.0\n",
    "!pip install transformers==4.24.0\n",
    "!pip install ipywidgets==7.7.2\n",
    "!pip install scipy ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "access_token = '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'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0122f5f919cd439a849b8e5d6e94c01c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'clip_sample': False} were passed to PNDMScheduler, but are not expected and will be ignored. Please verify your scheduler_config.json configuration file.\n"
     ]
    }
   ],
   "source": [
    "experimental_pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=access_token)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m experimental_pipe \u001B[38;5;241m=\u001B[39m \u001B[43mexperimental_pipe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\diffusers\\pipeline_utils.py:177\u001B[0m, in \u001B[0;36mDiffusionPipeline.to\u001B[1;34m(self, torch_device)\u001B[0m\n\u001B[0;32m    171\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m module\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mfloat16 \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(torch_device) \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmps\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m    172\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    173\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipelines loaded with `torch_dtype=torch.float16` cannot be moved to `cpu` or `mps` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    174\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdue to the lack of support for `float16` operations on those devices in PyTorch. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    175\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease remove the `torch_dtype=torch.float16` argument, or use a `cuda` device.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    176\u001B[0m             )\n\u001B[1;32m--> 177\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch_device\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:989\u001B[0m, in \u001B[0;36mModule.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    985\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    986\u001B[0m                     non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[0;32m    987\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, non_blocking)\n\u001B[1;32m--> 989\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:641\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    639\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    640\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 641\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    643\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    644\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    645\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    646\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    651\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    652\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:641\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    639\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    640\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 641\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    643\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    644\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    645\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    646\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    651\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    652\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "    \u001B[1;31m[... skipping similar frames: Module._apply at line 641 (1 times)]\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:641\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    639\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    640\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 641\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    643\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    644\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    645\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    646\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    651\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    652\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:664\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    660\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    661\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    662\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    663\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 664\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    665\u001B[0m should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    666\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_use_set_data:\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:987\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    984\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m    985\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    986\u001B[0m                 non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[1;32m--> 987\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\torch\\cuda\\__init__.py:221\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    219\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    220\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 221\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    222\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    223\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    224\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "experimental_pipe = experimental_pipe.to(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kyuha\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\torch\\amp\\autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"LayerNormKernelImpl\" not implemented for 'Half'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m description_1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma photograph of an horse on moon\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m----> 3\u001B[0m   image_1 \u001B[38;5;241m=\u001B[39m \u001B[43mexperimental_pipe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdescription_1\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mimages[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m      4\u001B[0m image_1\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001B[0m, in \u001B[0;36mdecorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\diffusers\\pipelines\\stable_diffusion\\pipeline_stable_diffusion.py:219\u001B[0m, in \u001B[0;36mStableDiffusionPipeline.__call__\u001B[1;34m(self, prompt, height, width, num_inference_steps, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, output_type, return_dict, callback, callback_steps, **kwargs)\u001B[0m\n\u001B[0;32m    214\u001B[0m     logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[0;32m    215\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe following part of your input was truncated because CLIP can only handle sequences up to\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    216\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39mmodel_max_length\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m tokens: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mremoved_text\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    217\u001B[0m     )\n\u001B[0;32m    218\u001B[0m     text_input_ids \u001B[38;5;241m=\u001B[39m text_input_ids[:, : \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39mmodel_max_length]\n\u001B[1;32m--> 219\u001B[0m text_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtext_encoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext_input_ids\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    221\u001B[0m \u001B[38;5;66;03m# duplicate text embeddings for each generation per prompt\u001B[39;00m\n\u001B[0;32m    222\u001B[0m text_embeddings \u001B[38;5;241m=\u001B[39m text_embeddings\u001B[38;5;241m.\u001B[39mrepeat_interleave(num_images_per_prompt, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\transformers\\models\\clip\\modeling_clip.py:733\u001B[0m, in \u001B[0;36mCLIPTextModel.forward\u001B[1;34m(self, input_ids, attention_mask, position_ids, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    705\u001B[0m \u001B[38;5;129m@add_start_docstrings_to_model_forward\u001B[39m(CLIP_TEXT_INPUTS_DOCSTRING)\n\u001B[0;32m    706\u001B[0m \u001B[38;5;129m@replace_return_docstrings\u001B[39m(output_type\u001B[38;5;241m=\u001B[39mBaseModelOutputWithPooling, config_class\u001B[38;5;241m=\u001B[39mCLIPTextConfig)\n\u001B[0;32m    707\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    714\u001B[0m     return_dict: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    715\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[Tuple, BaseModelOutputWithPooling]:\n\u001B[0;32m    716\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    717\u001B[0m \u001B[38;5;124;03m    Returns:\u001B[39;00m\n\u001B[0;32m    718\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    731\u001B[0m \u001B[38;5;124;03m    >>> pooled_output = outputs.pooler_output  # pooled (EOS token) states\u001B[39;00m\n\u001B[0;32m    732\u001B[0m \u001B[38;5;124;03m    ```\"\"\"\u001B[39;00m\n\u001B[1;32m--> 733\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtext_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    734\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    735\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    736\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    737\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    738\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    739\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    740\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\transformers\\models\\clip\\modeling_clip.py:649\u001B[0m, in \u001B[0;36mCLIPTextTransformer.forward\u001B[1;34m(self, input_ids, attention_mask, position_ids, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    645\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    646\u001B[0m     \u001B[38;5;66;03m# [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\u001B[39;00m\n\u001B[0;32m    647\u001B[0m     attention_mask \u001B[38;5;241m=\u001B[39m _expand_mask(attention_mask, hidden_states\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[1;32m--> 649\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    650\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    651\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    652\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcausal_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcausal_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    653\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    654\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    655\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    656\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    658\u001B[0m last_hidden_state \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    659\u001B[0m last_hidden_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinal_layer_norm(last_hidden_state)\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\transformers\\models\\clip\\modeling_clip.py:578\u001B[0m, in \u001B[0;36mCLIPEncoder.forward\u001B[1;34m(self, inputs_embeds, attention_mask, causal_attention_mask, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    571\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[0;32m    572\u001B[0m         create_custom_forward(encoder_layer),\n\u001B[0;32m    573\u001B[0m         hidden_states,\n\u001B[0;32m    574\u001B[0m         attention_mask,\n\u001B[0;32m    575\u001B[0m         causal_attention_mask,\n\u001B[0;32m    576\u001B[0m     )\n\u001B[0;32m    577\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 578\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mencoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    579\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    580\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    581\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcausal_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    582\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    583\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    585\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    587\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\transformers\\models\\clip\\modeling_clip.py:320\u001B[0m, in \u001B[0;36mCLIPEncoderLayer.forward\u001B[1;34m(self, hidden_states, attention_mask, causal_attention_mask, output_attentions)\u001B[0m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m    310\u001B[0m \u001B[38;5;124;03m    hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    316\u001B[0m \u001B[38;5;124;03m        returned tensors for more detail.\u001B[39;00m\n\u001B[0;32m    317\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    318\u001B[0m residual \u001B[38;5;241m=\u001B[39m hidden_states\n\u001B[1;32m--> 320\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer_norm1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    321\u001B[0m hidden_states, attn_weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mself_attn(\n\u001B[0;32m    322\u001B[0m     hidden_states\u001B[38;5;241m=\u001B[39mhidden_states,\n\u001B[0;32m    323\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[0;32m    324\u001B[0m     causal_attention_mask\u001B[38;5;241m=\u001B[39mcausal_attention_mask,\n\u001B[0;32m    325\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[0;32m    326\u001B[0m )\n\u001B[0;32m    327\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m hidden_states\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\torch\\nn\\modules\\normalization.py:190\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\torch\\nn\\functional.py:2515\u001B[0m, in \u001B[0;36mlayer_norm\u001B[1;34m(input, normalized_shape, weight, bias, eps)\u001B[0m\n\u001B[0;32m   2511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_variadic(\u001B[38;5;28minput\u001B[39m, weight, bias):\n\u001B[0;32m   2512\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m   2513\u001B[0m         layer_norm, (\u001B[38;5;28minput\u001B[39m, weight, bias), \u001B[38;5;28minput\u001B[39m, normalized_shape, weight\u001B[38;5;241m=\u001B[39mweight, bias\u001B[38;5;241m=\u001B[39mbias, eps\u001B[38;5;241m=\u001B[39meps\n\u001B[0;32m   2514\u001B[0m     )\n\u001B[1;32m-> 2515\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer_norm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalized_shape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackends\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcudnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menabled\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: \"LayerNormKernelImpl\" not implemented for 'Half'"
     ]
    }
   ],
   "source": [
    "description_1 = \"a photograph of an horse on moon\"\n",
    "with autocast(\"cuda\"):\n",
    "  image_1 = experimental_pipe(description_1).images[0]\n",
    "image_1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "description_2 = \"dog sitting in a field of autumn leaves\"\n",
    "with autocast(\"cuda\"):\n",
    "  image_2 = experimental_pipe(description_2).images[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_images = 3\n",
    "description = [description_2]*num_images\n",
    "with autocast(\"cuda\"):\n",
    "  experiment_image = experimental_pipe(description).images\n",
    "\n",
    "grid = grids(experiment_image, rows=1, cols=3)\n",
    "grid"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
