{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 388,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_score,average_precision_score,precision_score,recall_score\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import NearestNeighbors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "outputs": [],
   "source": [
    "def contour2centroid(arr):\n",
    "    length = arr.shape[0]\n",
    "    sum_x = np.sum(arr[:, 0])\n",
    "    sum_y = np.sum(arr[:, 1])\n",
    "    return sum_x/length, sum_y/length"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "outputs": [],
   "source": [
    "#open manual annotated image from geojson (exported qupath image as geojason because paquo installation failed)\n",
    "src = r'\\\\fatherserverdw\\Q\\research\\images\\skin_aging\\hovernet_tile\\hovernet_manual_validation'\n",
    "manual = os.path.join(src,'manual_annotation')\n",
    "predicted = os.path.join(src,'predicted_nuclei_contour')\n",
    "raw_ims = os.path.join(src,'raw_image')\n",
    "raw_path = glob.glob(os.path.join(raw_ims,'*.tif'))\n",
    "pd_annotations = glob.glob(os.path.join(predicted,'*.json'))\n",
    "annotations = glob.glob(os.path.join(manual,'*.geojson'))\n",
    "img_names = os.listdir(manual)\n",
    "path = r'\\\\fatherserverdw\\Q\\research\\images\\skin_aging\\hovernet_tile\\hovernet_manual_validation\\dl_mask'\n",
    "# Note: these DL mask have issue with epidermal-dermal junction having pixel value above 12.\n",
    "dl_masks = glob.glob(os.path.join(path,'*.tif'))\n",
    "\n",
    "tissue_id = list(range(0,13))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "outputs": [],
   "source": [
    "#generate overall dataframe for csv\n",
    "columns = ['mean_jaccard','mean_dice1','mean_precision','mean_recall','aji','dice2','pq','sq','dq']\n",
    "scores_name = ['jaccard','dice','precision','recall','tissue_composition']\n",
    "\n",
    "for score in scores_name:\n",
    "    for i in range(1,13):\n",
    "        columns.append(score + '_id' + str(i))\n",
    "\n",
    "\n",
    "tissue_region_scores = pd.DataFrame(0.0, index=img_names,columns=columns)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "outputs": [],
   "source": [
    "raw_path_idx = 0\n",
    "\n",
    "for annotation in annotations:\n",
    "\n",
    "    with open(annotation) as f:\n",
    "      features = json.load(f)[\"features\"]\n",
    "    #iterate through other stuff\n",
    "    raw_img = cv2.imread(raw_path[raw_path_idx])\n",
    "    dim = raw_img.shape\n",
    "    image_size = (dim[0],dim[1])\n",
    "    img_name = img_names[raw_path_idx]\n",
    "     #open prediction\n",
    "    pd_annotation = pd_annotations[raw_path_idx]\n",
    "\n",
    "\n",
    "    man_coordinates = [np.squeeze(_['geometry']['coordinates']) for _ in features]\n",
    "    manual_df = pd.DataFrame({'contour':man_coordinates})\n",
    "    manual_df['centroid']=manual_df['contour'].apply(lambda row:contour2centroid(row))\n",
    "\n",
    "    with open(pd_annotation) as pd_f:\n",
    "      #bbox, centroid, contour\n",
    "      pd_features = json.load(pd_f)[\"nuc\"]\n",
    "\n",
    "    #create a list of predicted contours\n",
    "    pd_contours=[]\n",
    "    pd_centroids = []\n",
    "    for key in pd_features:\n",
    "        temp = pd_features.get(key)\n",
    "        pd_contours.append(np.array(temp.get('contour')))\n",
    "        pd_centroids.append(np.round(temp.get('centroid'),0).astype('int'))\n",
    "\n",
    "    predicted_df = pd.DataFrame({'contour':pd_contours,'centroid':pd_centroids})\n",
    "\n",
    "\n",
    "\n",
    "    #get size of origianl image\n",
    "    raw = glob.glob(os.path.join(raw_ims,'*.tif'))\n",
    "    raw_img = cv2.imread(raw[0])\n",
    "    dim = raw_img.shape\n",
    "    image_size = (dim[0],dim[1])\n",
    "\n",
    "    #create a list of manual centroids, and a list of predicted centroids\n",
    "    manual_centroid= np.array(manual_df['centroid'].values.tolist())\n",
    "    predicted_centroid= np.array(predicted_df['centroid'].values.tolist())\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, metric='euclidean').fit(predicted_centroid) #build model\n",
    "    distances, indices = nbrs.kneighbors(manual_centroid) #apply model\n",
    "    indices=np.squeeze(indices)\n",
    "\n",
    "\n",
    "\n",
    "    #false positive indexes\n",
    "    # (but we also need to add the ones with low iou,we don't know if it's a false positive or false negative\n",
    "    unpaired_predicted_idx_1 = [_ for _ in np.array(predicted_df.index) if _ not in np.unique(indices)]\n",
    "\n",
    "    predicted_df2 = predicted_df.iloc[indices]\n",
    "    linked_df = manual_df\n",
    "    linked_df['pred_contour'] =predicted_df2.contour.reset_index(drop=True)\n",
    "    linked_df['pred_centroid'] =predicted_df2.centroid.reset_index(drop=True)\n",
    "    linked_df['pred_idx'] = predicted_df2.index\n",
    "\n",
    "\n",
    "\n",
    "    scores=[]\n",
    "    paired_pred_idx = []\n",
    "    #label is the pixel value (color) from [1,384]\n",
    "    for index, row in linked_df.iterrows():\n",
    "        groundtruth_mask = np.zeros(image_size)\n",
    "        predicted_mask = np.zeros(image_size)\n",
    "        groundtruth_mask = cv2.fillPoly(groundtruth_mask, pts=[np.array(row['contour']).astype(np.int32)],  color=1)\n",
    "        predicted_mask = cv2.fillPoly(predicted_mask, pts=[np.array(row['pred_contour']).astype(np.int32)],  color=1)\n",
    "        score = jaccard_score(groundtruth_mask,predicted_mask, average=\"micro\")\n",
    "        scores.append(score)\n",
    "\n",
    "        #ashley added,if doesn't work, delete\n",
    "        if(score >= 0.5):\n",
    "            #add to paired nuclei idx\n",
    "            paired_pred_idx.append(row['pred_idx'])\n",
    "\n",
    "    unpaired_predicted_idx_2 =  set(indices) - set(paired_pred_idx)\n",
    "\n",
    "    unpaired_pred_contour = []\n",
    "    #iterate through idx list1\n",
    "    for idx in unpaired_predicted_idx_1:\n",
    "        unpaired_pred_contour.append(predicted_df.iloc[idx].contour)\n",
    "\n",
    "    for idx in unpaired_predicted_idx_2:\n",
    "        unpaired_pred_contour.append(predicted_df.iloc[idx].contour)\n",
    "\n",
    "    linked_df['jaccard_score']=scores\n",
    "\n",
    "    #test, compute metrics for paried nucleus\n",
    "    #add the score for each pair tp dataframe\n",
    "\n",
    "    #----metrics for each nuclei-----\n",
    "    #dice_1\n",
    "    dice1 = []\n",
    "    # prediction score\n",
    "    precision = []\n",
    "    recall=[]\n",
    "\n",
    "    #average precision score is for the whole image\n",
    "\n",
    "    #pq\n",
    "    paired_true=0\n",
    "    unpaired_true=0\n",
    "    paired_iou = []\n",
    "    #threshold for iou\n",
    "    match_iou = 0.5\n",
    "\n",
    "    #aji\n",
    "    paired_inter= []\n",
    "    paired_union = []\n",
    "    #dice2\n",
    "    paired_total=[]\n",
    "    #masks\n",
    "    unpaired_true_masks = []\n",
    "    paired_pred_masks = []\n",
    "    unpaired_pred_masks =[]\n",
    "\n",
    "\n",
    "    for index, row in linked_df.iterrows():\n",
    "        groundtruth_mask = np.zeros(image_size)\n",
    "        predicted_mask = np.zeros(image_size)\n",
    "        groundtruth_mask = cv2.fillPoly(groundtruth_mask, pts=[np.array(row['contour']).astype(np.int32)],  color=1)\n",
    "        predicted_mask = cv2.fillPoly(predicted_mask, pts=[np.array(row['pred_contour']).astype(np.int32)],  color=1)\n",
    "\n",
    "        inter1 = groundtruth_mask * predicted_mask\n",
    "        denom = groundtruth_mask + predicted_mask\n",
    "        dice = 2.0 * np.sum(inter1) / np.sum((denom+1.0e-6))\n",
    "        dice1.append(dice)\n",
    "\n",
    "        p = precision_score(groundtruth_mask,predicted_mask, average=\"micro\")\n",
    "        precision.append(p)\n",
    "\n",
    "        r = recall_score(groundtruth_mask,predicted_mask, average=\"micro\")\n",
    "        recall.append(r)\n",
    "\n",
    "        iou = jaccard_score(groundtruth_mask,predicted_mask, average=\"micro\")\n",
    "        if(iou >= 0.5):#different thresholds give different results\n",
    "            total = ( groundtruth_mask + predicted_mask).sum()\n",
    "            inter = ( groundtruth_mask * predicted_mask).sum()\n",
    "            paired_inter.append(inter)\n",
    "            paired_union.append(total-inter)\n",
    "            paired_total.append(total)\n",
    "            paired_pred_masks.append(predicted_mask)\n",
    "            paired_true += 1\n",
    "            paired_iou.append(iou)\n",
    "\n",
    "        else:\n",
    "            unpaired_true_masks.append(groundtruth_mask)\n",
    "            unpaired_true += 1\n",
    "\n",
    "    #add scores to dataframe\n",
    "    linked_df['dice1']=dice1\n",
    "    linked_df['precision']=precision\n",
    "    linked_df['recall'] = recall\n",
    "\n",
    "    #Panoptic Quality (not finished, this is for the whole image)\n",
    "    tp = paired_true #it's length\n",
    "    fp = len(unpaired_pred_contour)\n",
    "    fn = unpaired_true\n",
    "\n",
    "    # get the F1-score i.e DQ\n",
    "    dq = tp / (tp + 0.5 * fp + 0.5 * fn)\n",
    "\n",
    "    # get the SQ, no paired has 0 iou so not impact\n",
    "    sq = sum(paired_iou) / (tp + 1.0e-6)\n",
    "\n",
    "    #Panoptic Quality and aji is for the whole image\n",
    "    pq = dq * sq\n",
    "\n",
    "\n",
    "    #calcualte aji score for overall image\n",
    "    overall_inter = sum(paired_inter)\n",
    "    overall_union = sum(paired_union)\n",
    "    overall_total = sum(paired_total)\n",
    "\n",
    "    #calcuate dice2 here, because it doesn't include the unpaired nucleus\n",
    "    dice2  = 2 * overall_inter / overall_total\n",
    "\n",
    "    #add unpaired true to overall union\n",
    "    for up_true in unpaired_true_masks:\n",
    "        overall_union += ( up_true * 1).sum() #?does this work??\n",
    "\n",
    "    #add unpaired predicted to overall union\n",
    "    for up_pred in unpaired_pred_contour:\n",
    "        predicted_mask = np.zeros(image_size)\n",
    "        predicted_mask = cv2.fillPoly(predicted_mask, pts=[np.array(up_pred).astype(np.int32)],  color=1)\n",
    "        overall_union+= (predicted_mask * 1).sum()\n",
    "\n",
    "    #aji score\n",
    "    aji_score = overall_inter / overall_union\n",
    "\n",
    "    #overall mean\n",
    "    mean_dice1 = linked_df[\"dice1\"].mean()\n",
    "    mean_jaccard = linked_df[\"jaccard_score\"].mean()\n",
    "    mean_pre = linked_df[\"precision\"].mean()\n",
    "    mean_recall = linked_df[\"recall\"].mean()\n",
    "\n",
    "    #add score to csv\n",
    "    tissue_region_scores.loc[img_name] = pd.Series({'mean_jaccard':mean_jaccard,'mean_dice1':mean_dice1,'mean_precision':mean_pre,'mean_recall':mean_recall,'aji':aji_score,'dice2':dice2,'pq':pq,'sq':sq,'dq':dq})\n",
    "\n",
    "    linked_df.drop('pred_idx', axis=1, inplace=True)\n",
    "    linked_df.to_pickle(\"./{}.pkl\".format(img_name))\n",
    "\n",
    "\n",
    "\n",
    "    mask = dl_masks[raw_path_idx]\n",
    "    mask_img = Image.open(mask)\n",
    "    m_arr = np.array(mask_img)\n",
    "    m_arr[m_arr>12]=0\n",
    "    m_arr[m_arr==1]=2\n",
    "    m_arr[m_arr==12]=10\n",
    "    hist,bin_edges = np.histogram(m_arr,bins=range(0,14))\n",
    "\n",
    "    #create a list of composition\n",
    "    comp = hist/np.sum(hist)\n",
    "\n",
    "    #assign tissue id to each nuclei\n",
    "    ids = []\n",
    "    for idx, row in linked_df.iterrows():\n",
    "        cent = tuple(np.round(row['centroid']).astype(\"int32\"))\n",
    "        id = m_arr[cent]\n",
    "        ids.append(id)\n",
    "\n",
    "    linked_df['tissue_id']=ids\n",
    "\n",
    "\n",
    "\n",
    "    #this is used to calculate each individual tissue region's mean scores\n",
    "    tissue_region_count = np.zeros(shape=(len(tissue_id),4))\n",
    "    temp_tissue_region_scores = pd.DataFrame(0.0, index=tissue_id, columns=scores_name)\n",
    "\n",
    "    #iterate through dataframe again to calculate tissue region's mean scores\n",
    "    for idx,row in linked_df.iterrows():\n",
    "        id = row['tissue_id']\n",
    "        temp_tissue_region_scores.iloc[id]['jaccard'] += row['jaccard_score']\n",
    "        if(row['jaccard_score'] != 0):\n",
    "            tissue_region_count[id][0] += 1\n",
    "        temp_tissue_region_scores.iloc[id]['dice'] += row['dice1']\n",
    "        if(row['dice1'] != 0):\n",
    "            tissue_region_count[id][1] += 1\n",
    "        temp_tissue_region_scores.iloc[id]['precision'] += row['precision']\n",
    "        if(row['precision'] != 0):\n",
    "            tissue_region_count[id][2] += 1\n",
    "        temp_tissue_region_scores.iloc[id]['recall'] += row['recall']\n",
    "        if(row['recall'] != 0):\n",
    "            tissue_region_count[id][3] += 1\n",
    "\n",
    "    for idx, row in temp_tissue_region_scores.iterrows():\n",
    "\n",
    "        if(tissue_region_count[idx][0] != 0):\n",
    "            row['jaccard']  = row['jaccard'] / tissue_region_count[idx][0]\n",
    "        if(tissue_region_count[idx][1] != 0):\n",
    "            row['dice']  = row['dice'] / tissue_region_count[idx][1]\n",
    "        if(tissue_region_count[idx][2] != 0):\n",
    "            row['precision']  = row['precision'] / tissue_region_count[idx][2]\n",
    "        if(tissue_region_count[idx][3] != 0):\n",
    "            row['recall']  = row['recall'] / tissue_region_count[idx][3]\n",
    "    #loop through the tissue_score_df the stupid way\n",
    "    for score in scores_name[0:4]:\n",
    "        for i in range(1,13): #order is jaccard,dice,precision,recall\n",
    "            col_name = score + '_id' + str(i)\n",
    "            tissue_region_scores.iloc[raw_path_idx][col_name] = temp_tissue_region_scores.iloc[i][score]\n",
    "    #attach tissue composition\n",
    "    for i in range (1,13): #no 1 nor 12\n",
    "        col_name = 'tissue_composition' + '_id' + str(i)\n",
    "        tissue_region_scores.iloc[raw_path_idx][col_name] = comp[i]\n",
    "\n",
    "\n",
    "     #increment\n",
    "    raw_path_idx +=1\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "outputs": [
    {
     "data": {
      "text/plain": "                             mean_jaccard  mean_dice1  mean_precision  \\\nimID008_sec1_tile11.geojson      0.619867    0.712645        0.809288   \nimID008_sec1_tile12.geojson      0.599001    0.705896        0.847679   \nimID008_sec1_tile68.geojson      0.674853    0.751708        0.794418   \nimID008_sec1_tile74.geojson      0.590726    0.669767        0.753517   \nimID379_sec1_tile33.geojson      0.772015    0.851519        0.913930   \nimID379_sec1_tile92.geojson      0.659137    0.749382        0.809843   \n\n                             mean_recall       aji     dice2        pq  \\\nimID008_sec1_tile11.geojson     0.659163  0.605057  0.855908  0.624584   \nimID008_sec1_tile12.geojson     0.624160  0.527262  0.827546  0.558808   \nimID008_sec1_tile68.geojson     0.729442  0.697598  0.889533  0.686881   \nimID008_sec1_tile74.geojson     0.619792  0.625123  0.875086  0.616992   \nimID379_sec1_tile33.geojson     0.807336  0.732304  0.895436  0.720163   \nimID379_sec1_tile92.geojson     0.714566  0.652287  0.863803  0.644157   \n\n                                   sq        dq  jaccard_id1  ...  \\\nimID008_sec1_tile11.geojson  0.746031  0.837209          0.0  ...   \nimID008_sec1_tile12.geojson  0.699866  0.798450          0.0  ...   \nimID008_sec1_tile68.geojson  0.792366  0.866873          0.0  ...   \nimID008_sec1_tile74.geojson  0.766457  0.804992          0.0  ...   \nimID379_sec1_tile33.geojson  0.804182  0.895522          0.0  ...   \nimID379_sec1_tile92.geojson  0.745866  0.863636          0.0  ...   \n\n                             tissue_composition_id3  tissue_composition_id4  \\\nimID008_sec1_tile11.geojson                0.000372                0.000305   \nimID008_sec1_tile12.geojson                0.000000                0.000014   \nimID008_sec1_tile68.geojson                0.023084                0.176147   \nimID008_sec1_tile74.geojson                0.000170                0.000358   \nimID379_sec1_tile33.geojson                0.000000                0.000000   \nimID379_sec1_tile92.geojson                0.000000                0.000941   \n\n                             tissue_composition_id5  tissue_composition_id6  \\\nimID008_sec1_tile11.geojson                0.007173                0.000845   \nimID008_sec1_tile12.geojson                0.004174                0.000397   \nimID008_sec1_tile68.geojson                0.068317                0.018581   \nimID008_sec1_tile74.geojson                0.002524                0.000504   \nimID379_sec1_tile33.geojson                0.000000                0.000002   \nimID379_sec1_tile92.geojson                0.001419                0.000207   \n\n                             tissue_composition_id7  tissue_composition_id8  \\\nimID008_sec1_tile11.geojson                0.006889                0.005181   \nimID008_sec1_tile12.geojson                0.003879                0.001256   \nimID008_sec1_tile68.geojson                0.033856                0.029140   \nimID008_sec1_tile74.geojson                0.047542                0.003690   \nimID379_sec1_tile33.geojson                0.074866                0.003123   \nimID379_sec1_tile92.geojson                0.000195                0.004199   \n\n                             tissue_composition_id9  tissue_composition_id10  \\\nimID008_sec1_tile11.geojson                0.016980                 0.638486   \nimID008_sec1_tile12.geojson                0.022490                 0.966085   \nimID008_sec1_tile68.geojson                0.007967                 0.415447   \nimID008_sec1_tile74.geojson                0.017368                 0.886513   \nimID379_sec1_tile33.geojson                0.005014                 0.912527   \nimID379_sec1_tile92.geojson                0.013892                 0.971596   \n\n                             tissue_composition_id11  tissue_composition_id12  \nimID008_sec1_tile11.geojson                 0.000682                      0.0  \nimID008_sec1_tile12.geojson                 0.001705                      0.0  \nimID008_sec1_tile68.geojson                 0.227279                      0.0  \nimID008_sec1_tile74.geojson                 0.000881                      0.0  \nimID379_sec1_tile33.geojson                 0.004468                      0.0  \nimID379_sec1_tile92.geojson                 0.007551                      0.0  \n\n[6 rows x 69 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_jaccard</th>\n      <th>mean_dice1</th>\n      <th>mean_precision</th>\n      <th>mean_recall</th>\n      <th>aji</th>\n      <th>dice2</th>\n      <th>pq</th>\n      <th>sq</th>\n      <th>dq</th>\n      <th>jaccard_id1</th>\n      <th>...</th>\n      <th>tissue_composition_id3</th>\n      <th>tissue_composition_id4</th>\n      <th>tissue_composition_id5</th>\n      <th>tissue_composition_id6</th>\n      <th>tissue_composition_id7</th>\n      <th>tissue_composition_id8</th>\n      <th>tissue_composition_id9</th>\n      <th>tissue_composition_id10</th>\n      <th>tissue_composition_id11</th>\n      <th>tissue_composition_id12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>imID008_sec1_tile11.geojson</th>\n      <td>0.619867</td>\n      <td>0.712645</td>\n      <td>0.809288</td>\n      <td>0.659163</td>\n      <td>0.605057</td>\n      <td>0.855908</td>\n      <td>0.624584</td>\n      <td>0.746031</td>\n      <td>0.837209</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000372</td>\n      <td>0.000305</td>\n      <td>0.007173</td>\n      <td>0.000845</td>\n      <td>0.006889</td>\n      <td>0.005181</td>\n      <td>0.016980</td>\n      <td>0.638486</td>\n      <td>0.000682</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>imID008_sec1_tile12.geojson</th>\n      <td>0.599001</td>\n      <td>0.705896</td>\n      <td>0.847679</td>\n      <td>0.624160</td>\n      <td>0.527262</td>\n      <td>0.827546</td>\n      <td>0.558808</td>\n      <td>0.699866</td>\n      <td>0.798450</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000014</td>\n      <td>0.004174</td>\n      <td>0.000397</td>\n      <td>0.003879</td>\n      <td>0.001256</td>\n      <td>0.022490</td>\n      <td>0.966085</td>\n      <td>0.001705</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>imID008_sec1_tile68.geojson</th>\n      <td>0.674853</td>\n      <td>0.751708</td>\n      <td>0.794418</td>\n      <td>0.729442</td>\n      <td>0.697598</td>\n      <td>0.889533</td>\n      <td>0.686881</td>\n      <td>0.792366</td>\n      <td>0.866873</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.023084</td>\n      <td>0.176147</td>\n      <td>0.068317</td>\n      <td>0.018581</td>\n      <td>0.033856</td>\n      <td>0.029140</td>\n      <td>0.007967</td>\n      <td>0.415447</td>\n      <td>0.227279</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>imID008_sec1_tile74.geojson</th>\n      <td>0.590726</td>\n      <td>0.669767</td>\n      <td>0.753517</td>\n      <td>0.619792</td>\n      <td>0.625123</td>\n      <td>0.875086</td>\n      <td>0.616992</td>\n      <td>0.766457</td>\n      <td>0.804992</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000170</td>\n      <td>0.000358</td>\n      <td>0.002524</td>\n      <td>0.000504</td>\n      <td>0.047542</td>\n      <td>0.003690</td>\n      <td>0.017368</td>\n      <td>0.886513</td>\n      <td>0.000881</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>imID379_sec1_tile33.geojson</th>\n      <td>0.772015</td>\n      <td>0.851519</td>\n      <td>0.913930</td>\n      <td>0.807336</td>\n      <td>0.732304</td>\n      <td>0.895436</td>\n      <td>0.720163</td>\n      <td>0.804182</td>\n      <td>0.895522</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000002</td>\n      <td>0.074866</td>\n      <td>0.003123</td>\n      <td>0.005014</td>\n      <td>0.912527</td>\n      <td>0.004468</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>imID379_sec1_tile92.geojson</th>\n      <td>0.659137</td>\n      <td>0.749382</td>\n      <td>0.809843</td>\n      <td>0.714566</td>\n      <td>0.652287</td>\n      <td>0.863803</td>\n      <td>0.644157</td>\n      <td>0.745866</td>\n      <td>0.863636</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000941</td>\n      <td>0.001419</td>\n      <td>0.000207</td>\n      <td>0.000195</td>\n      <td>0.004199</td>\n      <td>0.013892</td>\n      <td>0.971596</td>\n      <td>0.007551</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows × 69 columns</p>\n</div>"
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tissue_region_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "outputs": [],
   "source": [
    "tissue_region_scores.to_csv('./out_overall.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#take stuff out and examine individual dataframes\n",
    "#score of 1 doesn't look right\n",
    "\n",
    "#image1 precision id8\n",
    "\n",
    "#load dataframe (pkl)\n",
    "#summarize some examples, crop them using contours\n",
    "#high score/ low score/ one high one low\n",
    "#anything that stands out\n",
    "\n",
    "#a window that is bigger than nuclei (square window 100 by 100), all crops have the same size\n",
    "#just crop raw imgae, and draw with python for GT and Predicted (different color)\n",
    "#\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_path_idx = 0\n",
    "annotation = annotations[0]\n",
    "with open(annotation) as f:\n",
    "  features = json.load(f)[\"features\"]\n",
    "#iterate through other stuff\n",
    "raw_img = cv2.imread(raw_path[raw_path_idx])\n",
    "dim = raw_img.shape\n",
    "image_size = (dim[0],dim[1])\n",
    "img_name = img_names[raw_path_idx]\n",
    " #open prediction\n",
    "pd_annotation = pd_annotations[raw_path_idx]\n",
    "\n",
    "\n",
    "man_coordinates = [np.squeeze(_['geometry']['coordinates']) for _ in features]\n",
    "manual_df = pd.DataFrame({'contour':man_coordinates})\n",
    "manual_df['centroid']=manual_df['contour'].apply(lambda row:contour2centroid(row))\n",
    "\n",
    "with open(pd_annotation) as pd_f:\n",
    "  #bbox, centroid, contour\n",
    "  pd_features = json.load(pd_f)[\"nuc\"]\n",
    "\n",
    "#create a list of predicted contours\n",
    "pd_contours=[]\n",
    "pd_centroids = []\n",
    "for key in pd_features:\n",
    "    temp = pd_features.get(key)\n",
    "    pd_contours.append(np.array(temp.get('contour')))\n",
    "    pd_centroids.append(np.round(temp.get('centroid'),0).astype('int'))\n",
    "\n",
    "predicted_df = pd.DataFrame({'contour':pd_contours,'centroid':pd_centroids})\n",
    "\n",
    "\n",
    "\n",
    "#get size of origianl image\n",
    "raw = glob.glob(os.path.join(raw_ims,'*.tif'))\n",
    "raw_img = cv2.imread(raw[0])\n",
    "dim = raw_img.shape\n",
    "image_size = (dim[0],dim[1])\n",
    "\n",
    "#create a list of manual centroids, and a list of predicted centroids\n",
    "manual_centroid= np.array(manual_df['centroid'].values.tolist())\n",
    "predicted_centroid= np.array(predicted_df['centroid'].values.tolist())\n",
    "nbrs = NearestNeighbors(n_neighbors=1, metric='euclidean').fit(predicted_centroid) #build model\n",
    "distances, indices = nbrs.kneighbors(manual_centroid) #apply model\n",
    "indices=np.squeeze(indices)\n",
    "\n",
    "\n",
    "\n",
    "#false positive indexes\n",
    "# (but we also need to add the ones with low iou,we don't know if it's a false positive or false negative\n",
    "unpaired_predicted_idx_1 = [_ for _ in np.array(predicted_df.index) if _ not in np.unique(indices)]\n",
    "\n",
    "predicted_df2 = predicted_df.iloc[indices]\n",
    "linked_df = manual_df\n",
    "linked_df['pred_contour'] =predicted_df2.contour.reset_index(drop=True)\n",
    "linked_df['pred_centroid'] =predicted_df2.centroid.reset_index(drop=True)\n",
    "linked_df['pred_idx'] = predicted_df2.index\n",
    "\n",
    "\n",
    "\n",
    "scores=[]\n",
    "paired_pred_idx = []\n",
    "#label is the pixel value (color) from [1,384]\n",
    "for index, row in linked_df.iterrows():\n",
    "    groundtruth_mask = np.zeros(image_size)\n",
    "    predicted_mask = np.zeros(image_size)\n",
    "    groundtruth_mask = cv2.fillPoly(groundtruth_mask, pts=[np.array(row['contour']).astype(np.int32)],  color=1)\n",
    "    predicted_mask = cv2.fillPoly(predicted_mask, pts=[np.array(row['pred_contour']).astype(np.int32)],  color=1)\n",
    "    score = jaccard_score(groundtruth_mask,predicted_mask, average=\"micro\")\n",
    "    scores.append(score)\n",
    "\n",
    "    #ashley added,if doesn't work, delete\n",
    "    if(score >= 0.5):\n",
    "        #add to paired nuclei idx\n",
    "        paired_pred_idx.append(row['pred_idx'])\n",
    "\n",
    "unpaired_predicted_idx_2 =  set(indices) - set(paired_pred_idx)\n",
    "\n",
    "unpaired_pred_contour = []\n",
    "#iterate through idx list1\n",
    "for idx in unpaired_predicted_idx_1:\n",
    "    unpaired_pred_contour.append(predicted_df.iloc[idx].contour)\n",
    "\n",
    "for idx in unpaired_predicted_idx_2:\n",
    "    unpaired_pred_contour.append(predicted_df.iloc[idx].contour)\n",
    "\n",
    "linked_df['jaccard_score']=scores\n",
    "\n",
    "#test, compute metrics for paried nucleus\n",
    "#add the score for each pair tp dataframe\n",
    "\n",
    "#----metrics for each nuclei-----\n",
    "#dice_1\n",
    "dice1 = []\n",
    "# prediction score\n",
    "precision = []\n",
    "recall=[]\n",
    "\n",
    "#average precision score is for the whole image\n",
    "\n",
    "#pq\n",
    "paired_true=0\n",
    "unpaired_true=0\n",
    "paired_iou = []\n",
    "#threshold for iou\n",
    "match_iou = 0.5\n",
    "\n",
    "#aji\n",
    "paired_inter= []\n",
    "paired_union = []\n",
    "#dice2\n",
    "paired_total=[]\n",
    "#masks\n",
    "unpaired_true_masks = []\n",
    "paired_pred_masks = []\n",
    "unpaired_pred_masks =[]\n",
    "\n",
    "\n",
    "for index, row in linked_df.iterrows():\n",
    "    groundtruth_mask = np.zeros(image_size)\n",
    "    predicted_mask = np.zeros(image_size)\n",
    "    groundtruth_mask = cv2.fillPoly(groundtruth_mask, pts=[np.array(row['contour']).astype(np.int32)],  color=1)\n",
    "    predicted_mask = cv2.fillPoly(predicted_mask, pts=[np.array(row['pred_contour']).astype(np.int32)],  color=1)\n",
    "\n",
    "    inter1 = groundtruth_mask * predicted_mask\n",
    "    denom = groundtruth_mask + predicted_mask\n",
    "    dice = 2.0 * np.sum(inter1) / np.sum((denom+1.0e-6))\n",
    "    dice1.append(dice)\n",
    "\n",
    "    p = precision_score(groundtruth_mask,predicted_mask, average=\"micro\")\n",
    "    precision.append(p)\n",
    "\n",
    "    r = recall_score(groundtruth_mask,predicted_mask, average=\"micro\")\n",
    "    recall.append(r)\n",
    "\n",
    "    iou = jaccard_score(groundtruth_mask,predicted_mask, average=\"micro\")\n",
    "    if(iou >= 0.5):#different thresholds give different results\n",
    "        total = ( groundtruth_mask + predicted_mask).sum()\n",
    "        inter = ( groundtruth_mask * predicted_mask).sum()\n",
    "        paired_inter.append(inter)\n",
    "        paired_union.append(total-inter)\n",
    "        paired_total.append(total)\n",
    "        paired_pred_masks.append(predicted_mask)\n",
    "        paired_true += 1\n",
    "        paired_iou.append(iou)\n",
    "\n",
    "    else:\n",
    "        unpaired_true_masks.append(groundtruth_mask)\n",
    "        unpaired_true += 1\n",
    "\n",
    "#add scores to dataframe\n",
    "linked_df['dice1']=dice1\n",
    "linked_df['precision']=precision\n",
    "linked_df['recall'] = recall\n",
    "\n",
    "#Panoptic Quality (not finished, this is for the whole image)\n",
    "tp = paired_true #it's length\n",
    "fp = len(unpaired_pred_contour)\n",
    "fn = unpaired_true\n",
    "\n",
    "# get the F1-score i.e DQ\n",
    "dq = tp / (tp + 0.5 * fp + 0.5 * fn)\n",
    "\n",
    "# get the SQ, no paired has 0 iou so not impact\n",
    "sq = sum(paired_iou) / (tp + 1.0e-6)\n",
    "\n",
    "#Panoptic Quality and aji is for the whole image\n",
    "pq = dq * sq\n",
    "\n",
    "\n",
    "#calcualte aji score for overall image\n",
    "overall_inter = sum(paired_inter)\n",
    "overall_union = sum(paired_union)\n",
    "overall_total = sum(paired_total)\n",
    "\n",
    "#calcuate dice2 here, because it doesn't include the unpaired nucleus\n",
    "dice2  = 2 * overall_inter / overall_total\n",
    "\n",
    "#add unpaired true to overall union\n",
    "for up_true in unpaired_true_masks:\n",
    "    overall_union += ( up_true * 1).sum() #?does this work??\n",
    "\n",
    "#add unpaired predicted to overall union\n",
    "for up_pred in unpaired_pred_contour:\n",
    "    predicted_mask = np.zeros(image_size)\n",
    "    predicted_mask = cv2.fillPoly(predicted_mask, pts=[np.array(up_pred).astype(np.int32)],  color=1)\n",
    "    overall_union+= (predicted_mask * 1).sum()\n",
    "\n",
    "#aji score\n",
    "aji_score = overall_inter / overall_union\n",
    "\n",
    "#overall mean\n",
    "mean_dice1 = linked_df[\"dice1\"].mean()\n",
    "mean_jaccard = linked_df[\"jaccard_score\"].mean()\n",
    "mean_pre = linked_df[\"precision\"].mean()\n",
    "mean_recall = linked_df[\"recall\"].mean()\n",
    "\n",
    "#add score to csv\n",
    "\n",
    "\n",
    "linked_df.drop('pred_idx', axis=1, inplace=True)\n",
    "linked_df.to_pickle(\"./{}.pkl\".format(img_name))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mask = dl_masks[raw_path_idx]\n",
    "mask_img = Image.open(mask)\n",
    "m_arr = np.array(mask_img)\n",
    "m_arr[m_arr>12]=0\n",
    "m_arr[m_arr==1]=2\n",
    "m_arr[m_arr==12]=10\n",
    "hist,bin_edges = np.histogram(m_arr,bins=range(0,14))\n",
    "\n",
    "#create a list of composition, 0,2,3,...9,10,11\n",
    "comp = hist/np.sum(hist)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "outputs": [
    {
     "data": {
      "text/plain": "array([7.10100e-03, 0.00000e+00, 3.15986e-01, 3.72000e-04, 3.05000e-04,\n       7.17300e-03, 8.45000e-04, 6.88900e-03, 5.18100e-03, 1.69800e-02,\n       6.38486e-01, 6.82000e-04, 0.00000e+00])"
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "outputs": [
    {
     "data": {
      "text/plain": "631972"
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_arr[m_arr==2].sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_arr[m_arr==12].sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "outputs": [
    {
     "data": {
      "text/plain": "array([2, 2, 2, ..., 2, 2, 2], dtype=uint8)"
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_arr[m_arr==2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "outputs": [
    {
     "data": {
      "text/plain": "array([  7101,      0, 315986,    372,    305,   7173,    845,   6889,\n         5181,  16980, 638486,    682,      0], dtype=int64)"
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#delete eveything after this line"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "#https://arxiv.org/pdf/1812.06499.pdf\n",
    "#this paper talks about aji, dice and pq scores\n",
    "\n",
    "#https://github.com/vqdang/hover_net/blob/master/metrics/stats_utils.py\n",
    "#code reference\n",
    "\n",
    "#summary\n",
    "#for individual pairs,the scores calculated are: iou, dice, precision, recall\n",
    "#for whole image, scores calculated are: Panoptic Quality(pq,sq,dq), aji, dice2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "#take a mean of each score\n",
    "#output as pickle\n",
    "#output overall score as csv: image name and scores,tissue composition (histagram), do this last (mean score per tissue object (give id to nuclei))\n",
    "#TODO: need to iterate through all images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "\n",
    "for idx,row in linked_df.iterrows():\n",
    "    id = row['tissue_id']\n",
    "    #tissue_region_scores.iloc[id]['jaccard'] = row['jaccard_score'] + tissue_region_scores.iloc[id]['jaccard']\n",
    "    tissue_region_scores.iloc[id]['jaccard'] += row['jaccard_score']\n",
    "    if(row['jaccard_score'] != 0):\n",
    "        tissue_region_count[id][0] += 1\n",
    "    tissue_region_scores.iloc[id]['dice'] += row['dice1']\n",
    "    if(row['dice1'] != 0):\n",
    "        tissue_region_count[id][1] += 1\n",
    "    tissue_region_scores.iloc[id]['precision'] += row['precision']\n",
    "    if(row['precision'] != 0):\n",
    "        tissue_region_count[id][2] += 1\n",
    "    tissue_region_scores.iloc[id]['recall'] += row['recall']\n",
    "    if(row['recall'] != 0):\n",
    "        tissue_region_count[id][3] += 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "#calculate the mean of the each reagion and output to pickle\n",
    "\n",
    "#count order: 'jaccard','dice','precision','recall'\n",
    "for idx, row in tissue_region_scores.iterrows():\n",
    "    #jaccard\n",
    "    if(tissue_region_count[idx][0] != 0):\n",
    "        row['jaccard']  = row['jaccard'] / tissue_region_count[idx][0]\n",
    "    if(tissue_region_count[idx][1] != 0):\n",
    "        row['dice']  = row['dice'] / tissue_region_count[idx][1]\n",
    "    if(tissue_region_count[idx][2] != 0):\n",
    "        row['precision']  = row['precision'] / tissue_region_count[idx][2]\n",
    "    if(tissue_region_count[idx][3] != 0):\n",
    "        row['recall']  = row['recall'] / tissue_region_count[idx][3]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "      recall   jaccard      dice  precision\n0   0.681377  0.157676  0.608191   0.679817\n1   0.805864  0.022737  0.828952   0.898037\n2   0.756199  0.010758  0.829018   0.951502\n3   0.000000  0.000000  0.000000   0.000000\n4   0.000000  0.000000  0.000000   0.000000\n5   0.679389  0.679389  0.805430   1.000000\n6   0.000000  0.000000  0.000000   0.000000\n7   0.736801  0.119594  0.822570   0.974602\n8   0.248227  0.248227  0.395480   1.000000\n9   0.694283  0.230769  0.810935   0.997114\n10  0.743659  0.004782  0.809294   0.926904\n11  0.000000  0.000000  0.000000   0.000000\n12  0.792110  0.010187  0.851816   0.946922\n13  0.000000  0.000000  0.000000   0.000000\n14  0.000000  0.000000  0.000000   0.000000\n15  0.000000  0.000000  0.000000   0.000000\n16  0.000000  0.000000  0.000000   0.000000\n17  0.000000  0.000000  0.000000   0.000000\n18  0.000000  0.000000  0.000000   0.000000\n19  0.000000  0.000000  0.000000   0.000000\n20  0.000000  0.000000  0.000000   0.000000\n21  0.000000  0.000000  0.000000   0.000000\n22  0.000000  0.000000  0.000000   0.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>recall</th>\n      <th>jaccard</th>\n      <th>dice</th>\n      <th>precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.681377</td>\n      <td>0.157676</td>\n      <td>0.608191</td>\n      <td>0.679817</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.805864</td>\n      <td>0.022737</td>\n      <td>0.828952</td>\n      <td>0.898037</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.756199</td>\n      <td>0.010758</td>\n      <td>0.829018</td>\n      <td>0.951502</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.679389</td>\n      <td>0.679389</td>\n      <td>0.805430</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.736801</td>\n      <td>0.119594</td>\n      <td>0.822570</td>\n      <td>0.974602</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.248227</td>\n      <td>0.248227</td>\n      <td>0.395480</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.694283</td>\n      <td>0.230769</td>\n      <td>0.810935</td>\n      <td>0.997114</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.743659</td>\n      <td>0.004782</td>\n      <td>0.809294</td>\n      <td>0.926904</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.792110</td>\n      <td>0.010187</td>\n      <td>0.851816</td>\n      <td>0.946922</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tissue_region_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#output overall score as csv: image name and scores,tissue composition (histagram), do this last (mean score per tissue object (give id to nuclei))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}