{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "#open manual annotated image from geojson (exported qupath image as geojason because paquo installation failed)\n",
    "src = r'\\\\fatherserverdw\\Q\\research\\images\\skin_aging\\hovernet_tile\\hovernet_manual_validation'\n",
    "manual = os.path.join(src,'manual_annotation')\n",
    "predicted = os.path.join(src,'predicted_nuclei_contour')\n",
    "raw_ims = os.path.join(src,'raw_image')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "#open manual annotations with json.load\n",
    "annotations = glob.glob(os.path.join(manual,'*.geojson'))\n",
    "annotation = annotations[1]\n",
    "with open(annotation) as f:\n",
    "  features = json.load(f)[\"features\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "#create a list of manual contours\n",
    "man_coordinates = [np.squeeze(_['geometry']['coordinates']) for _ in features]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               contour\n0    [[368, 427], [368, 428], [367, 428], [366, 429...\n1    [[242, 339], [241, 340], [239, 340], [238, 341...\n2    [[168, 364], [167, 365], [166, 365], [166, 366...\n3    [[322, 384], [321, 385], [320, 385], [319, 386...\n4    [[387, 334], [387, 335], [386, 335], [386, 336...\n..                                                 ...\n379  [[230.0, 311.0], [230.0, 313.0], [233.0, 313.0...\n380  [[370, 314], [370, 315], [369, 315], [369, 317...\n381  [[959.0, 403.0], [959.0, 404.0], [957.0, 404.0...\n382  [[543, 354], [543, 355], [542, 355], [542, 356...\n383  [[649, 491], [649, 492], [648, 492], [648, 493...\n\n[384 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[368, 427], [368, 428], [367, 428], [366, 429...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[242, 339], [241, 340], [239, 340], [238, 341...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[168, 364], [167, 365], [166, 365], [166, 366...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[322, 384], [321, 385], [320, 385], [319, 386...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[387, 334], [387, 335], [386, 335], [386, 336...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>379</th>\n      <td>[[230.0, 311.0], [230.0, 313.0], [233.0, 313.0...</td>\n    </tr>\n    <tr>\n      <th>380</th>\n      <td>[[370, 314], [370, 315], [369, 315], [369, 317...</td>\n    </tr>\n    <tr>\n      <th>381</th>\n      <td>[[959.0, 403.0], [959.0, 404.0], [957.0, 404.0...</td>\n    </tr>\n    <tr>\n      <th>382</th>\n      <td>[[543, 354], [543, 355], [542, 355], [542, 356...</td>\n    </tr>\n    <tr>\n      <th>383</th>\n      <td>[[649, 491], [649, 492], [648, 492], [648, 493...</td>\n    </tr>\n  </tbody>\n</table>\n<p>384 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_df = pd.DataFrame({'contour':man_coordinates})\n",
    "manual_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# def contour2centroid(c):\n",
    "#     M = cv2.moments(c)\n",
    "#     cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "#     cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "#     return np.array([cX,cY])\n",
    "\n",
    "def contour2centroid(arr):\n",
    "    length = arr.shape[0]\n",
    "    sum_x = np.sum(arr[:, 0])\n",
    "    sum_y = np.sum(arr[:, 1])\n",
    "    return sum_x/length, sum_y/length"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               contour  \\\n0    [[368, 427], [368, 428], [367, 428], [366, 429...   \n1    [[242, 339], [241, 340], [239, 340], [238, 341...   \n2    [[168, 364], [167, 365], [166, 365], [166, 366...   \n3    [[322, 384], [321, 385], [320, 385], [319, 386...   \n4    [[387, 334], [387, 335], [386, 335], [386, 336...   \n..                                                 ...   \n379  [[230.0, 311.0], [230.0, 313.0], [233.0, 313.0...   \n380  [[370, 314], [370, 315], [369, 315], [369, 317...   \n381  [[959.0, 403.0], [959.0, 404.0], [957.0, 404.0...   \n382  [[543, 354], [543, 355], [542, 355], [542, 356...   \n383  [[649, 491], [649, 492], [648, 492], [648, 493...   \n\n                                     centroid  \n0      (369.93939393939394, 438.969696969697)  \n1     (242.16666666666666, 346.2142857142857)  \n2    (172.02564102564102, 371.64102564102564)  \n3      (325.8695652173913, 392.4130434782609)  \n4      (390.0408163265306, 342.7959183673469)  \n..                                        ...  \n379   (248.45238095238096, 313.3095238095238)  \n380    (390.7014925373134, 322.2089552238806)  \n381               (961.75, 413.4935897435897)  \n382     (547.936170212766, 360.7659574468085)  \n383   (649.7631578947369, 497.42105263157896)  \n\n[384 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contour</th>\n      <th>centroid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[368, 427], [368, 428], [367, 428], [366, 429...</td>\n      <td>(369.93939393939394, 438.969696969697)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[242, 339], [241, 340], [239, 340], [238, 341...</td>\n      <td>(242.16666666666666, 346.2142857142857)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[168, 364], [167, 365], [166, 365], [166, 366...</td>\n      <td>(172.02564102564102, 371.64102564102564)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[322, 384], [321, 385], [320, 385], [319, 386...</td>\n      <td>(325.8695652173913, 392.4130434782609)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[387, 334], [387, 335], [386, 335], [386, 336...</td>\n      <td>(390.0408163265306, 342.7959183673469)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>379</th>\n      <td>[[230.0, 311.0], [230.0, 313.0], [233.0, 313.0...</td>\n      <td>(248.45238095238096, 313.3095238095238)</td>\n    </tr>\n    <tr>\n      <th>380</th>\n      <td>[[370, 314], [370, 315], [369, 315], [369, 317...</td>\n      <td>(390.7014925373134, 322.2089552238806)</td>\n    </tr>\n    <tr>\n      <th>381</th>\n      <td>[[959.0, 403.0], [959.0, 404.0], [957.0, 404.0...</td>\n      <td>(961.75, 413.4935897435897)</td>\n    </tr>\n    <tr>\n      <th>382</th>\n      <td>[[543, 354], [543, 355], [542, 355], [542, 356...</td>\n      <td>(547.936170212766, 360.7659574468085)</td>\n    </tr>\n    <tr>\n      <th>383</th>\n      <td>[[649, 491], [649, 492], [648, 492], [648, 493...</td>\n      <td>(649.7631578947369, 497.42105263157896)</td>\n    </tr>\n  </tbody>\n</table>\n<p>384 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_df['centroid']=manual_df['contour'].apply(lambda row:contour2centroid(row))\n",
    "manual_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "#open prediction\n",
    "pd_annotations = glob.glob(os.path.join(predicted,'*.json'))\n",
    "#open tile11\n",
    "pd_annotation = pd_annotations[0]\n",
    "with open(pd_annotation) as pd_f:\n",
    "  #bbox, centroid, contour\n",
    "  pd_features = json.load(pd_f)[\"nuc\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "#create a list of predicted contours\n",
    "pd_contours=[]\n",
    "pd_centroids = []\n",
    "for key in pd_features:\n",
    "    temp = pd_features.get(key)\n",
    "    pd_contours.append(np.array(temp.get('contour')))\n",
    "    pd_centroids.append(np.round(temp.get('centroid'),0).astype('int'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               contour    centroid\n0    [[667, 300], [666, 301], [666, 302], [667, 301...  [690, 305]\n1    [[615, 306], [614, 307], [611, 307], [610, 308...  [612, 315]\n2    [[517, 309], [516, 310], [513, 310], [513, 311...  [522, 318]\n3    [[675, 310], [674, 311], [673, 311], [672, 312...  [679, 318]\n4    [[503, 311], [501, 313], [499, 313], [497, 315...  [502, 318]\n..                                                 ...         ...\n342  [[310, 921], [310, 922], [309, 923], [307, 923...  [310, 927]\n343  [[698, 930], [698, 931], [697, 932], [698, 933...  [704, 938]\n344  [[206, 942], [205, 943], [204, 943], [203, 944...  [206, 945]\n345  [[331, 951], [327, 955], [327, 956], [326, 957...  [331, 958]\n346  [[599, 967], [598, 968], [596, 968], [595, 969...  [590, 973]\n\n[347 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contour</th>\n      <th>centroid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[667, 300], [666, 301], [666, 302], [667, 301...</td>\n      <td>[690, 305]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[615, 306], [614, 307], [611, 307], [610, 308...</td>\n      <td>[612, 315]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[517, 309], [516, 310], [513, 310], [513, 311...</td>\n      <td>[522, 318]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[675, 310], [674, 311], [673, 311], [672, 312...</td>\n      <td>[679, 318]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[503, 311], [501, 313], [499, 313], [497, 315...</td>\n      <td>[502, 318]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>[[310, 921], [310, 922], [309, 923], [307, 923...</td>\n      <td>[310, 927]</td>\n    </tr>\n    <tr>\n      <th>343</th>\n      <td>[[698, 930], [698, 931], [697, 932], [698, 933...</td>\n      <td>[704, 938]</td>\n    </tr>\n    <tr>\n      <th>344</th>\n      <td>[[206, 942], [205, 943], [204, 943], [203, 944...</td>\n      <td>[206, 945]</td>\n    </tr>\n    <tr>\n      <th>345</th>\n      <td>[[331, 951], [327, 955], [327, 956], [326, 957...</td>\n      <td>[331, 958]</td>\n    </tr>\n    <tr>\n      <th>346</th>\n      <td>[[599, 967], [598, 968], [596, 968], [595, 969...</td>\n      <td>[590, 973]</td>\n    </tr>\n  </tbody>\n</table>\n<p>347 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df = pd.DataFrame({'contour':pd_contours,'centroid':pd_centroids})\n",
    "predicted_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "#get size of origianl image\n",
    "raw = glob.glob(os.path.join(raw_ims,'*.tif'))\n",
    "raw_img = cv2.imread(raw[0])\n",
    "dim = raw_img.shape\n",
    "image_size = (dim[0],dim[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "#Link ground truth to predicted nuclei\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "#create a list of manual centroids, and a list of predicted centroids\n",
    "manual_centroid= np.array(manual_df['centroid'].values.tolist())\n",
    "predicted_centroid= np.array(predicted_df['centroid'].values.tolist())\n",
    "nbrs = NearestNeighbors(n_neighbors=1, metric='euclidean').fit(predicted_centroid) #build model\n",
    "distances, indices = nbrs.kneighbors(manual_centroid) #apply model\n",
    "indices=np.squeeze(indices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "17"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_fp = len(predicted_df)-len(np.unique(indices))\n",
    "N_fp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#a list of paired predicted contours\n",
    "paired_pred_contour=[]\n",
    "for idx in np.unique(indices):\n",
    "    paired_pred_contour.append(predicted_df.iloc[idx].contour)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "#false positive indexes\n",
    "# (but we also need to add the ones with low iou,we don't know if it's a false positive or false negative\n",
    "\n",
    "unpaired_predicted_idx = [_ for _ in np.array(predicted_df.index) if _ not in np.unique(indices)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "#a list of unpaired predicted contours\n",
    "unpaired_pred_contour=[] #we need to add more\n",
    "for idx in unpaired_predicted_idx:\n",
    "    unpaired_pred_contour.append(predicted_df.iloc[idx].contour)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "data": {
      "text/plain": "17"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "#a list of paired predicted contours\n",
    "paired_pred_contour=[]\n",
    "for idx in np.unique(indices):\n",
    "    paired_pred_contour.append(predicted_df.iloc[idx].contour)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               contour    centroid\n104  [[369, 428], [367, 430], [367, 431], [366, 432...  [370, 439]\n22   [[242, 338], [241, 339], [239, 339], [238, 340...  [242, 346]\n33   [[172, 363], [171, 364], [169, 364], [168, 365...  [173, 372]\n57   [[321, 384], [320, 385], [319, 385], [316, 388...  [325, 392]\n20   [[391, 334], [390, 335], [388, 335], [387, 336...  [390, 343]\n..                                                 ...         ...\n22   [[242, 338], [241, 339], [239, 339], [238, 340...  [242, 346]\n6    [[360, 314], [359, 315], [357, 315], [356, 316...  [377, 320]\n77   [[957, 405], [956, 406], [954, 406], [952, 408...  [960, 413]\n26   [[545, 354], [544, 355], [542, 355], [540, 357...  [549, 361]\n152  [[628, 461], [627, 462], [626, 462], [625, 463...  [629, 474]\n\n[384 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contour</th>\n      <th>centroid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>104</th>\n      <td>[[369, 428], [367, 430], [367, 431], [366, 432...</td>\n      <td>[370, 439]</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>[[242, 338], [241, 339], [239, 339], [238, 340...</td>\n      <td>[242, 346]</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>[[172, 363], [171, 364], [169, 364], [168, 365...</td>\n      <td>[173, 372]</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>[[321, 384], [320, 385], [319, 385], [316, 388...</td>\n      <td>[325, 392]</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>[[391, 334], [390, 335], [388, 335], [387, 336...</td>\n      <td>[390, 343]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>[[242, 338], [241, 339], [239, 339], [238, 340...</td>\n      <td>[242, 346]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[[360, 314], [359, 315], [357, 315], [356, 316...</td>\n      <td>[377, 320]</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>[[957, 405], [956, 406], [954, 406], [952, 408...</td>\n      <td>[960, 413]</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>[[545, 354], [544, 355], [542, 355], [540, 357...</td>\n      <td>[549, 361]</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>[[628, 461], [627, 462], [626, 462], [625, 463...</td>\n      <td>[629, 474]</td>\n    </tr>\n  </tbody>\n</table>\n<p>384 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df2 = predicted_df.iloc[indices]\n",
    "predicted_df2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               contour  \\\n0    [[368, 427], [368, 428], [367, 428], [366, 429...   \n1    [[242, 339], [241, 340], [239, 340], [238, 341...   \n2    [[168, 364], [167, 365], [166, 365], [166, 366...   \n3    [[322, 384], [321, 385], [320, 385], [319, 386...   \n4    [[387, 334], [387, 335], [386, 335], [386, 336...   \n..                                                 ...   \n379  [[230.0, 311.0], [230.0, 313.0], [233.0, 313.0...   \n380  [[370, 314], [370, 315], [369, 315], [369, 317...   \n381  [[959.0, 403.0], [959.0, 404.0], [957.0, 404.0...   \n382  [[543, 354], [543, 355], [542, 355], [542, 356...   \n383  [[649, 491], [649, 492], [648, 492], [648, 493...   \n\n                                     centroid  \\\n0      (369.93939393939394, 438.969696969697)   \n1     (242.16666666666666, 346.2142857142857)   \n2    (172.02564102564102, 371.64102564102564)   \n3      (325.8695652173913, 392.4130434782609)   \n4      (390.0408163265306, 342.7959183673469)   \n..                                        ...   \n379   (248.45238095238096, 313.3095238095238)   \n380    (390.7014925373134, 322.2089552238806)   \n381               (961.75, 413.4935897435897)   \n382     (547.936170212766, 360.7659574468085)   \n383   (649.7631578947369, 497.42105263157896)   \n\n                                          pred_contour pred_centroid  \n0    [[369, 428], [367, 430], [367, 431], [366, 432...    [370, 439]  \n1    [[242, 338], [241, 339], [239, 339], [238, 340...    [242, 346]  \n2    [[172, 363], [171, 364], [169, 364], [168, 365...    [173, 372]  \n3    [[321, 384], [320, 385], [319, 385], [316, 388...    [325, 392]  \n4    [[391, 334], [390, 335], [388, 335], [387, 336...    [390, 343]  \n..                                                 ...           ...  \n379  [[242, 338], [241, 339], [239, 339], [238, 340...    [242, 346]  \n380  [[360, 314], [359, 315], [357, 315], [356, 316...    [377, 320]  \n381  [[957, 405], [956, 406], [954, 406], [952, 408...    [960, 413]  \n382  [[545, 354], [544, 355], [542, 355], [540, 357...    [549, 361]  \n383  [[628, 461], [627, 462], [626, 462], [625, 463...    [629, 474]  \n\n[384 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contour</th>\n      <th>centroid</th>\n      <th>pred_contour</th>\n      <th>pred_centroid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[368, 427], [368, 428], [367, 428], [366, 429...</td>\n      <td>(369.93939393939394, 438.969696969697)</td>\n      <td>[[369, 428], [367, 430], [367, 431], [366, 432...</td>\n      <td>[370, 439]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[242, 339], [241, 340], [239, 340], [238, 341...</td>\n      <td>(242.16666666666666, 346.2142857142857)</td>\n      <td>[[242, 338], [241, 339], [239, 339], [238, 340...</td>\n      <td>[242, 346]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[168, 364], [167, 365], [166, 365], [166, 366...</td>\n      <td>(172.02564102564102, 371.64102564102564)</td>\n      <td>[[172, 363], [171, 364], [169, 364], [168, 365...</td>\n      <td>[173, 372]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[322, 384], [321, 385], [320, 385], [319, 386...</td>\n      <td>(325.8695652173913, 392.4130434782609)</td>\n      <td>[[321, 384], [320, 385], [319, 385], [316, 388...</td>\n      <td>[325, 392]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[387, 334], [387, 335], [386, 335], [386, 336...</td>\n      <td>(390.0408163265306, 342.7959183673469)</td>\n      <td>[[391, 334], [390, 335], [388, 335], [387, 336...</td>\n      <td>[390, 343]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>379</th>\n      <td>[[230.0, 311.0], [230.0, 313.0], [233.0, 313.0...</td>\n      <td>(248.45238095238096, 313.3095238095238)</td>\n      <td>[[242, 338], [241, 339], [239, 339], [238, 340...</td>\n      <td>[242, 346]</td>\n    </tr>\n    <tr>\n      <th>380</th>\n      <td>[[370, 314], [370, 315], [369, 315], [369, 317...</td>\n      <td>(390.7014925373134, 322.2089552238806)</td>\n      <td>[[360, 314], [359, 315], [357, 315], [356, 316...</td>\n      <td>[377, 320]</td>\n    </tr>\n    <tr>\n      <th>381</th>\n      <td>[[959.0, 403.0], [959.0, 404.0], [957.0, 404.0...</td>\n      <td>(961.75, 413.4935897435897)</td>\n      <td>[[957, 405], [956, 406], [954, 406], [952, 408...</td>\n      <td>[960, 413]</td>\n    </tr>\n    <tr>\n      <th>382</th>\n      <td>[[543, 354], [543, 355], [542, 355], [542, 356...</td>\n      <td>(547.936170212766, 360.7659574468085)</td>\n      <td>[[545, 354], [544, 355], [542, 355], [540, 357...</td>\n      <td>[549, 361]</td>\n    </tr>\n    <tr>\n      <th>383</th>\n      <td>[[649, 491], [649, 492], [648, 492], [648, 493...</td>\n      <td>(649.7631578947369, 497.42105263157896)</td>\n      <td>[[628, 461], [627, 462], [626, 462], [625, 463...</td>\n      <td>[629, 474]</td>\n    </tr>\n  </tbody>\n</table>\n<p>384 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linked_df = manual_df\n",
    "linked_df['pred_contour'] =predicted_df2.contour.reset_index(drop=True)\n",
    "linked_df['pred_centroid'] =predicted_df2.centroid.reset_index(drop=True)\n",
    "linked_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [18]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m groundtruth_mask \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mfillPoly(groundtruth_mask, pts\u001B[38;5;241m=\u001B[39m[np\u001B[38;5;241m.\u001B[39marray(row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontour\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mint32)],  color\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      7\u001B[0m predicted_mask \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mfillPoly(predicted_mask, pts\u001B[38;5;241m=\u001B[39m[np\u001B[38;5;241m.\u001B[39marray(row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpred_contour\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mint32)],  color\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m----> 8\u001B[0m score \u001B[38;5;241m=\u001B[39m \u001B[43mjaccard_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroundtruth_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43mpredicted_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmicro\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m scores\u001B[38;5;241m.\u001B[39mappend(score)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:795\u001B[0m, in \u001B[0;36mjaccard_score\u001B[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m    667\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mjaccard_score\u001B[39m(\n\u001B[0;32m    668\u001B[0m     y_true,\n\u001B[0;32m    669\u001B[0m     y_pred,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    675\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    676\u001B[0m ):\n\u001B[0;32m    677\u001B[0m     \u001B[38;5;124;03m\"\"\"Jaccard similarity coefficient score.\u001B[39;00m\n\u001B[0;32m    678\u001B[0m \n\u001B[0;32m    679\u001B[0m \u001B[38;5;124;03m    The Jaccard index [1], or Jaccard similarity coefficient, defined as\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    793\u001B[0m \u001B[38;5;124;03m    array([1. , 0. , 0.33...])\u001B[39;00m\n\u001B[0;32m    794\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 795\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[43m_check_set_wise_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    796\u001B[0m     samplewise \u001B[38;5;241m=\u001B[39m average \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    797\u001B[0m     MCM \u001B[38;5;241m=\u001B[39m multilabel_confusion_matrix(\n\u001B[0;32m    798\u001B[0m         y_true,\n\u001B[0;32m    799\u001B[0m         y_pred,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    802\u001B[0m         samplewise\u001B[38;5;241m=\u001B[39msamplewise,\n\u001B[0;32m    803\u001B[0m     )\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1357\u001B[0m, in \u001B[0;36m_check_set_wise_labels\u001B[1;34m(y_true, y_pred, average, labels, pos_label)\u001B[0m\n\u001B[0;32m   1354\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m average \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m average_options \u001B[38;5;129;01mand\u001B[39;00m average \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1355\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maverage has to be one of \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(average_options))\n\u001B[1;32m-> 1357\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1358\u001B[0m \u001B[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001B[39;00m\n\u001B[0;32m   1359\u001B[0m \u001B[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001B[39;00m\n\u001B[0;32m   1360\u001B[0m present_labels \u001B[38;5;241m=\u001B[39m unique_labels(y_true, y_pred)\u001B[38;5;241m.\u001B[39mtolist()\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:85\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001B[39;00m\n\u001B[0;32m     59\u001B[0m \n\u001B[0;32m     60\u001B[0m \u001B[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;124;03my_pred : array or indicator matrix\u001B[39;00m\n\u001B[0;32m     83\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     84\u001B[0m check_consistent_length(y_true, y_pred)\n\u001B[1;32m---> 85\u001B[0m type_true \u001B[38;5;241m=\u001B[39m \u001B[43mtype_of_target\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43my_true\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     86\u001B[0m type_pred \u001B[38;5;241m=\u001B[39m type_of_target(y_pred, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_pred\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     88\u001B[0m y_type \u001B[38;5;241m=\u001B[39m {type_true, type_pred}\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis\\lib\\site-packages\\sklearn\\utils\\multiclass.py:286\u001B[0m, in \u001B[0;36mtype_of_target\u001B[1;34m(y, input_name)\u001B[0m\n\u001B[0;32m    283\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sparse_pandas:\n\u001B[0;32m    284\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my cannot be class \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSparseSeries\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSparseArray\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 286\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mis_multilabel\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel-indicator\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    289\u001B[0m \u001B[38;5;66;03m# DeprecationWarning will be replaced by ValueError, see NEP 34\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;66;03m# https://numpy.org/neps/nep-0034-infer-dtype-is-object.html\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis\\lib\\site-packages\\sklearn\\utils\\multiclass.py:173\u001B[0m, in \u001B[0;36mis_multilabel\u001B[1;34m(y)\u001B[0m\n\u001B[0;32m    164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m    165\u001B[0m         \u001B[38;5;28mlen\u001B[39m(y\u001B[38;5;241m.\u001B[39mdata) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    166\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m np\u001B[38;5;241m.\u001B[39munique(y\u001B[38;5;241m.\u001B[39mdata)\u001B[38;5;241m.\u001B[39msize \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    170\u001B[0m         )\n\u001B[0;32m    171\u001B[0m     )\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munique\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(labels) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m3\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[0;32m    176\u001B[0m         y\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbiu\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m _is_integral_float(labels)  \u001B[38;5;66;03m# bool, int, uint\u001B[39;00m\n\u001B[0;32m    177\u001B[0m     )\n",
      "File \u001B[1;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36munique\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis\\lib\\site-packages\\numpy\\lib\\arraysetops.py:272\u001B[0m, in \u001B[0;36munique\u001B[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001B[0m\n\u001B[0;32m    270\u001B[0m ar \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masanyarray(ar)\n\u001B[0;32m    271\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 272\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43m_unique1d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_inverse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_counts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    273\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _unpack_tuple(ret)\n\u001B[0;32m    275\u001B[0m \u001B[38;5;66;03m# axis was specified and not None\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis\\lib\\site-packages\\numpy\\lib\\arraysetops.py:333\u001B[0m, in \u001B[0;36m_unique1d\u001B[1;34m(ar, return_index, return_inverse, return_counts)\u001B[0m\n\u001B[0;32m    331\u001B[0m     aux \u001B[38;5;241m=\u001B[39m ar[perm]\n\u001B[0;32m    332\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 333\u001B[0m     \u001B[43mar\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    334\u001B[0m     aux \u001B[38;5;241m=\u001B[39m ar\n\u001B[0;32m    335\u001B[0m mask \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mempty(aux\u001B[38;5;241m.\u001B[39mshape, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mbool_)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "scores=[]\n",
    "#label is the pixel value (color) from [1,384]\n",
    "for index, row in linked_df.iterrows():\n",
    "    groundtruth_mask = np.zeros(image_size)\n",
    "    predicted_mask = np.zeros(image_size)\n",
    "    groundtruth_mask = cv2.fillPoly(groundtruth_mask, pts=[np.array(row['contour']).astype(np.int32)],  color=1)\n",
    "    predicted_mask = cv2.fillPoly(predicted_mask, pts=[np.array(row['pred_contour']).astype(np.int32)],  color=1)\n",
    "    score = jaccard_score(groundtruth_mask,predicted_mask, average=\"micro\")\n",
    "    scores.append(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linked_df['jaccard_score']=scores\n",
    "linked_df #Look into why some cells have low score when centroids actually match"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(linked_df['jaccard_score'],100) #groundtruth has roughly 37 more nuclei 384 vs 347"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.mean(linked_df['jaccard_score'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_fast_pq(true, pred, match_iou=0.5):\n",
    "    \"\"\"`match_iou` is the IoU threshold level to determine the pairing between\n",
    "    GT instances `p` and prediction instances `g`. `p` and `g` is a pair\n",
    "    if IoU > `match_iou`. However, pair of `p` and `g` must be unique\n",
    "    (1 prediction instance to 1 GT instance mapping).\n",
    "\n",
    "    If `match_iou` < 0.5, Munkres assignment (solving minimum weight matching\n",
    "    in bipartite graphs) is caculated to find the maximal amount of unique pairing.\n",
    "\n",
    "    If `match_iou` >= 0.5, all IoU(p,g) > 0.5 pairing is proven to be unique and\n",
    "    the number of pairs is also maximal.\n",
    "\n",
    "    Returns:\n",
    "        [dq, sq, pq]: measurement statistic\n",
    "\n",
    "        [paired_true, paired_pred, unpaired_true, unpaired_pred]:\n",
    "                      pairing information to perform measurement\n",
    "\n",
    "    \"\"\"\n",
    "    assert match_iou >= 0.0, \"Cant' be negative\"\n",
    "\n",
    "    true = np.copy(true)\n",
    "    pred = np.copy(pred)\n",
    "    true_id_list = list(np.unique(true))\n",
    "    pred_id_list = list(np.unique(pred))\n",
    "\n",
    "    true_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for t in true_id_list[1:]:\n",
    "        t_mask = np.array(true == t, np.uint8)\n",
    "        true_masks.append(t_mask)\n",
    "\n",
    "    pred_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for p in pred_id_list[1:]:\n",
    "        p_mask = np.array(pred == p, np.uint8)\n",
    "        pred_masks.append(p_mask)\n",
    "\n",
    "    # prefill with value\n",
    "    pairwise_iou = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "\n",
    "    # caching pairwise iou\n",
    "    for true_id in true_id_list[1:]:  # 0-th is background\n",
    "        t_mask = true_masks[true_id]\n",
    "        pred_true_overlap = pred[t_mask > 0]\n",
    "        pred_true_overlap_id = np.unique(pred_true_overlap)\n",
    "        pred_true_overlap_id = list(pred_true_overlap_id)\n",
    "        for pred_id in pred_true_overlap_id:\n",
    "            if pred_id == 0:  # ignore\n",
    "                continue  # overlaping background\n",
    "            p_mask = pred_masks[pred_id]\n",
    "            total = (t_mask + p_mask).sum()\n",
    "            inter = (t_mask * p_mask).sum()\n",
    "            iou = inter / (total - inter)\n",
    "            pairwise_iou[true_id - 1, pred_id - 1] = iou\n",
    "    #\n",
    "    if match_iou >= 0.5:\n",
    "        paired_iou = pairwise_iou[pairwise_iou > match_iou]\n",
    "        pairwise_iou[pairwise_iou <= match_iou] = 0.0\n",
    "        paired_true, paired_pred = np.nonzero(pairwise_iou)\n",
    "        paired_iou = pairwise_iou[paired_true, paired_pred]\n",
    "        paired_true += 1  # index is instance id - 1\n",
    "        paired_pred += 1  # hence return back to original\n",
    "    else:  # * Exhaustive maximal unique pairing\n",
    "        #### Munkres pairing with scipy library\n",
    "        # the algorithm return (row indices, matched column indices)\n",
    "        # if there is multiple same cost in a row, index of first occurence\n",
    "        # is return, thus the unique pairing is ensure\n",
    "        # inverse pair to get high IoU as minimum\n",
    "        paired_true, paired_pred = linear_sum_assignment(-pairwise_iou)\n",
    "        ### extract the paired cost and remove invalid pair\n",
    "        paired_iou = pairwise_iou[paired_true, paired_pred]\n",
    "\n",
    "        # now select those above threshold level\n",
    "        # paired with iou = 0.0 i.e no intersection => FP or FN\n",
    "        paired_true = list(paired_true[paired_iou > match_iou] + 1)\n",
    "        paired_pred = list(paired_pred[paired_iou > match_iou] + 1)\n",
    "        paired_iou = paired_iou[paired_iou > match_iou]\n",
    "\n",
    "    # get the actual FP and FN\n",
    "    unpaired_true = [idx for idx in true_id_list[1:] if idx not in paired_true]\n",
    "    unpaired_pred = [idx for idx in pred_id_list[1:] if idx not in paired_pred]\n",
    "    # print(paired_iou.shape, paired_true.shape, len(unpaired_true), len(unpaired_pred))\n",
    "\n",
    "    #\n",
    "    tp = len(paired_true)\n",
    "    fp = len(unpaired_pred)\n",
    "    fn = len(unpaired_true)\n",
    "    # get the F1-score i.e DQ\n",
    "    dq = tp / (tp + 0.5 * fp + 0.5 * fn)\n",
    "    # get the SQ, no paired has 0 iou so not impact\n",
    "    sq = paired_iou.sum() / (tp + 1.0e-6)\n",
    "\n",
    "    return [dq, sq, dq * sq], [paired_true, paired_pred, unpaired_true, unpaired_pred]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_fast_aji_plus(true, pred):\n",
    "    \"\"\"AJI+, an AJI version with maximal unique pairing to obtain overall intersecion.\n",
    "    Every prediction instance is paired with at most 1 GT instance (1 to 1) mapping, unlike AJI\n",
    "    where a prediction instance can be paired against many GT instances (1 to many).\n",
    "    Remaining unpaired GT and Prediction instances will be added to the overall union.\n",
    "    The 1 to 1 mapping prevents AJI's over-penalisation from happening.\n",
    "\n",
    "    Fast computation requires instance IDs are in contiguous orderding i.e [1, 2, 3, 4]\n",
    "    not [2, 3, 6, 10]. Please call `remap_label` before hand and `by_size` flag has no\n",
    "    effect on the result.\n",
    "\n",
    "    \"\"\"\n",
    "    true = np.copy(true)  # ? do we need this\n",
    "    pred = np.copy(pred)\n",
    "    true_id_list = list(np.unique(true))\n",
    "    pred_id_list = list(np.unique(pred))\n",
    "\n",
    "    true_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for t in true_id_list[1:]:\n",
    "        t_mask = np.array(true == t, np.uint8)\n",
    "        true_masks.append(t_mask)\n",
    "\n",
    "    pred_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for p in pred_id_list[1:]:\n",
    "        p_mask = np.array(pred == p, np.uint8)\n",
    "        pred_masks.append(p_mask)\n",
    "\n",
    "    # prefill with value\n",
    "    pairwise_inter = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "    pairwise_union = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "\n",
    "    # caching pairwise\n",
    "    for true_id in true_id_list[1:]:  # 0-th is background\n",
    "        t_mask = true_masks[true_id]\n",
    "        pred_true_overlap = pred[t_mask > 0]\n",
    "        pred_true_overlap_id = np.unique(pred_true_overlap)\n",
    "        pred_true_overlap_id = list(pred_true_overlap_id)\n",
    "        for pred_id in pred_true_overlap_id:\n",
    "            if pred_id == 0:  # ignore\n",
    "                continue  # overlaping background\n",
    "\n",
    "            p_mask = pred_masks[pred_id]\n",
    "            total = (t_mask + p_mask).sum()\n",
    "            inter = (t_mask * p_mask).sum()\n",
    "            pairwise_inter[true_id - 1, pred_id - 1] = inter\n",
    "            pairwise_union[true_id - 1, pred_id - 1] = total - inter\n",
    "    #\n",
    "    pairwise_iou = pairwise_inter / (pairwise_union + 1.0e-6)\n",
    "    #### Munkres pairing to find maximal unique pairing\n",
    "    paired_true, paired_pred = linear_sum_assignment(-pairwise_iou)\n",
    "    ### extract the paired cost and remove invalid pair\n",
    "    paired_iou = pairwise_iou[paired_true, paired_pred]\n",
    "    # now select all those paired with iou != 0.0 i.e have intersection\n",
    "    paired_true = paired_true[paired_iou > 0.0]\n",
    "    paired_pred = paired_pred[paired_iou > 0.0]\n",
    "    paired_inter = pairwise_inter[paired_true, paired_pred]\n",
    "    paired_union = pairwise_union[paired_true, paired_pred]\n",
    "    paired_true = list(paired_true + 1)  # index to instance ID\n",
    "    paired_pred = list(paired_pred + 1)\n",
    "    overall_inter = paired_inter.sum()\n",
    "    overall_union = paired_union.sum()\n",
    "\n",
    "\n",
    "    # add all unpaired GT and Prediction into the union\n",
    "    unpaired_true = np.array(\n",
    "        [idx for idx in true_id_list[1:] if idx not in paired_true]\n",
    "    )\n",
    "    unpaired_pred = np.array(\n",
    "        [idx for idx in pred_id_list[1:] if idx not in paired_pred]\n",
    "    )\n",
    "    for true_id in unpaired_true:\n",
    "        overall_union += true_masks[true_id].sum()\n",
    "    for pred_id in unpaired_pred:\n",
    "        overall_union += pred_masks[pred_id].sum()\n",
    "    #\n",
    "    aji_score = overall_inter / overall_union\n",
    "    return aji_score\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [19]\u001B[0m, in \u001B[0;36m<cell line: 19>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     20\u001B[0m groundtruth_mask \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(image_size)\n\u001B[0;32m     21\u001B[0m predicted_mask \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(image_size)\n\u001B[1;32m---> 22\u001B[0m groundtruth_mask \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfillPoly\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroundtruth_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcontour\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint32\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[43mcolor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m predicted_mask \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mfillPoly(predicted_mask, pts\u001B[38;5;241m=\u001B[39m[np\u001B[38;5;241m.\u001B[39marray(row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpred_contour\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mint32)],  color\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m#inter1 = groundtruth_mask * predicted_mask\u001B[39;00m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m#denom = groundtruth_mask + predicted_mask\u001B[39;00m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m#dice = 2.0 * np.sum(inter1) / np.sum((denom+1.0e-6))\u001B[39;00m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m#dice1.append(dice)\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#test, compute metrics for paried nucleus\n",
    "#add the score for each pair tp dataframe\n",
    "\n",
    "#dice_1\n",
    "dice1 = []\n",
    "\n",
    "#pq\n",
    "paired_true=0\n",
    "unpaired_true=0\n",
    "paired_iou = []\n",
    "#threshold for iou\n",
    "match_iou = 0.5\n",
    "\n",
    "#aji\n",
    "paired_inter= []\n",
    "paired_union = []\n",
    "unpaired_true_arr = []\n",
    "\n",
    "for index, row in linked_df.iterrows():\n",
    "    groundtruth_mask = np.zeros(image_size)\n",
    "    predicted_mask = np.zeros(image_size)\n",
    "    groundtruth_mask = cv2.fillPoly(groundtruth_mask, pts=[np.array(row['contour']).astype(np.int32)],  color=1)\n",
    "    predicted_mask = cv2.fillPoly(predicted_mask, pts=[np.array(row['pred_contour']).astype(np.int32)],  color=1)\n",
    "\n",
    "    #inter1 = groundtruth_mask * predicted_mask\n",
    "    #denom = groundtruth_mask + predicted_mask\n",
    "    #dice = 2.0 * np.sum(inter1) / np.sum((denom+1.0e-6))\n",
    "    #dice1.append(dice)\n",
    "\n",
    "\n",
    "    iou = jaccard_score(groundtruth_mask,predicted_mask, average=\"micro\")\n",
    "    if(iou>0):\n",
    "        total = ( groundtruth_mask + predicted_mask).sum()\n",
    "        inter = ( groundtruth_mask * predicted_mask).sum()\n",
    "        paired_inter.append(inter)\n",
    "        paired_union.append(total-inter)\n",
    "    else:\n",
    "        #record unpaired_true\n",
    "        unpaired_true_arr.append(groundtruth_mask)\n",
    "\n",
    "    #iou is the same  as jaccard_score\n",
    "\n",
    "    #if(iou >= match_iou):\n",
    "        #paired_iou.append(iou)\n",
    "        #paired_true = paired_true+1\n",
    "    #extract unpaired nucleus\n",
    "    #else:\n",
    "        #unpaired_true  = unpaired_true+1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Panoptic Quality\n",
    "tp = paired_true\n",
    "fp = len(predicted_df)-len(np.unique(indices))\n",
    "fn = unpaired_true\n",
    "    # get the F1-score i.e DQ\n",
    "dq = tp / (tp + 0.5 * fp + 0.5 * fn)\n",
    "    # get the SQ, no paired has 0 iou so not impact\n",
    "sq = sum(paired_iou) / (tp + 1.0e-6)\n",
    "\n",
    "#Panoptic Quality and aji is for the whole image\n",
    "pq = dq * sq\n",
    "\n",
    "print(dq,sq,pq)\n",
    "\n",
    "#aji\n",
    "overall_inter = paired_inter.sum()\n",
    "overall_union = paired_union.sum()\n",
    "\n",
    "#TODO: add unpaired to overall union\n",
    "#add unpaired true\n",
    "for up_true in unpaired_true_arr:\n",
    "    overall_union += up_true.sum()\n",
    "#add unpaired predicted\n",
    "\n",
    "#aji score\n",
    "aji_score = overall_inter / overall_union"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#add metrics to dataframe\n",
    "#calculate aji\n",
    "linked_df['dice1']=dice1\n",
    "linked_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#ashley:try out the metrics, inputs are binary masks of groundtruth and predicted nucleus\n",
    "#their functions also convert the true and pred inputs to binary masks.\n",
    "# I think they just take in an integer array of an image\n",
    "\n",
    "#question: do you compute these scores for each nuclei with its pair and take an average, or do you do it on the overall image\n",
    "#i did it on the overall image\n",
    "dc1= get_dice_1(groundtruth_mask,predicted_mask)\n",
    "dc2 = get_fast_dice_2(groundtruth_mask,predicted_mask) #this equals dc1\n",
    "\n",
    "dq, sq, pq = get_fast_pq(groundtruth_mask,predicted_mask)[0]\n",
    "\n",
    "\n",
    "#TODO: need to modify the function because the function is expecting labeled masks\n",
    "aji = get_fast_aji_plus(groundtruth_mask,predicted_mask)\n",
    "\n",
    "#theyalso have a pair-coordinates function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "array([  0,   1,   2,   3,   5,   6,   7,   8,  10,  12,  13,  14,  15,\n        16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n        30,  31,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n        44,  45,  46,  47,  48,  49,  50,  51,  52,  54,  55,  56,  57,\n        58,  59,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n        72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n        85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n        98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n       111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124,\n       126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n       139, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n       166, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180,\n       181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193,\n       194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 207,\n       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n       221, 222, 223, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n       236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n       249, 250, 251, 252, 253, 254, 255, 256, 258, 259, 260, 261, 262,\n       263, 264, 265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276,\n       277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289,\n       290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302,\n       303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315,\n       316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328,\n       329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341,\n       342, 343, 344, 345, 346], dtype=int64)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(indices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#don't know what this does\n",
    "paired_true, paired_pred, unpaired_true, unpaired_pred = get_fast_pq(groundtruth_mask,predicted_mask)[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.mean(linked_df['jaccard_score'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_fast_pq(true, pred, match_iou=0.5):\n",
    "    \"\"\"`match_iou` is the IoU threshold level to determine the pairing between\n",
    "    GT instances `p` and prediction instances `g`. `p` and `g` is a pair\n",
    "    if IoU > `match_iou`. However, pair of `p` and `g` must be unique\n",
    "    (1 prediction instance to 1 GT instance mapping).\n",
    "\n",
    "    If `match_iou` < 0.5, Munkres assignment (solving minimum weight matching\n",
    "    in bipartite graphs) is caculated to find the maximal amount of unique pairing.\n",
    "\n",
    "    If `match_iou` >= 0.5, all IoU(p,g) > 0.5 pairing is proven to be unique and\n",
    "    the number of pairs is also maximal.\n",
    "\n",
    "    Returns:\n",
    "        [dq, sq, pq]: measurement statistic\n",
    "\n",
    "        [paired_true, paired_pred, unpaired_true, unpaired_pred]:\n",
    "                      pairing information to perform measurement\n",
    "\n",
    "    \"\"\"\n",
    "    assert match_iou >= 0.0, \"Cant' be negative\"\n",
    "\n",
    "    true = np.copy(true)\n",
    "    pred = np.copy(pred)\n",
    "    true_id_list = list(np.unique(true))\n",
    "    pred_id_list = list(np.unique(pred))\n",
    "\n",
    "    true_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for t in true_id_list[1:]:\n",
    "        t_mask = np.array(true == t, np.uint8)\n",
    "        true_masks.append(t_mask)\n",
    "\n",
    "    pred_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for p in pred_id_list[1:]:\n",
    "        p_mask = np.array(pred == p, np.uint8)\n",
    "        pred_masks.append(p_mask)\n",
    "\n",
    "    # prefill with value\n",
    "    pairwise_iou = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "\n",
    "    # caching pairwise iou\n",
    "    for true_id in true_id_list[1:]:  # 0-th is background\n",
    "        t_mask = true_masks[true_id]\n",
    "        pred_true_overlap = pred[t_mask > 0]\n",
    "        pred_true_overlap_id = np.unique(pred_true_overlap)\n",
    "        pred_true_overlap_id = list(pred_true_overlap_id)\n",
    "        for pred_id in pred_true_overlap_id:\n",
    "            if pred_id == 0:  # ignore\n",
    "                continue  # overlaping background\n",
    "            p_mask = pred_masks[pred_id]\n",
    "            total = (t_mask + p_mask).sum()\n",
    "            inter = (t_mask * p_mask).sum()\n",
    "            iou = inter / (total - inter)\n",
    "            pairwise_iou[true_id - 1, pred_id - 1] = iou\n",
    "    #\n",
    "    if match_iou >= 0.5:\n",
    "        paired_iou = pairwise_iou[pairwise_iou > match_iou]\n",
    "        pairwise_iou[pairwise_iou <= match_iou] = 0.0\n",
    "        paired_true, paired_pred = np.nonzero(pairwise_iou)\n",
    "        paired_iou = pairwise_iou[paired_true, paired_pred]\n",
    "        paired_true += 1  # index is instance id - 1\n",
    "        paired_pred += 1  # hence return back to original\n",
    "    else:  # * Exhaustive maximal unique pairing\n",
    "        #### Munkres pairing with scipy library\n",
    "        # the algorithm return (row indices, matched column indices)\n",
    "        # if there is multiple same cost in a row, index of first occurence\n",
    "        # is return, thus the unique pairing is ensure\n",
    "        # inverse pair to get high IoU as minimum\n",
    "        paired_true, paired_pred = linear_sum_assignment(-pairwise_iou)\n",
    "        ### extract the paired cost and remove invalid pair\n",
    "        paired_iou = pairwise_iou[paired_true, paired_pred]\n",
    "\n",
    "        # now select those above threshold level\n",
    "        # paired with iou = 0.0 i.e no intersection => FP or FN\n",
    "        paired_true = list(paired_true[paired_iou > match_iou] + 1)\n",
    "        paired_pred = list(paired_pred[paired_iou > match_iou] + 1)\n",
    "        paired_iou = paired_iou[paired_iou > match_iou]\n",
    "\n",
    "    # get the actual FP and FN\n",
    "    unpaired_true = [idx for idx in true_id_list[1:] if idx not in paired_true]\n",
    "    unpaired_pred = [idx for idx in pred_id_list[1:] if idx not in paired_pred]\n",
    "    # print(paired_iou.shape, paired_true.shape, len(unpaired_true), len(unpaired_pred))\n",
    "\n",
    "    #\n",
    "    tp = len(paired_true)\n",
    "    fp = len(unpaired_pred)\n",
    "    fn = len(unpaired_true)\n",
    "    # get the F1-score i.e DQ\n",
    "    dq = tp / (tp + 0.5 * fp + 0.5 * fn)\n",
    "    # get the SQ, no paired has 0 iou so not impact\n",
    "    sq = paired_iou.sum() / (tp + 1.0e-6)\n",
    "\n",
    "    return [dq, sq, dq * sq], [paired_true, paired_pred, unpaired_true, unpaired_pred]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_fast_aji_plus(true, pred):\n",
    "    \"\"\"AJI+, an AJI version with maximal unique pairing to obtain overall intersecion.\n",
    "    Every prediction instance is paired with at most 1 GT instance (1 to 1) mapping, unlike AJI\n",
    "    where a prediction instance can be paired against many GT instances (1 to many).\n",
    "    Remaining unpaired GT and Prediction instances will be added to the overall union.\n",
    "    The 1 to 1 mapping prevents AJI's over-penalisation from happening.\n",
    "\n",
    "    Fast computation requires instance IDs are in contiguous orderding i.e [1, 2, 3, 4]\n",
    "    not [2, 3, 6, 10]. Please call `remap_label` before hand and `by_size` flag has no\n",
    "    effect on the result.\n",
    "\n",
    "    \"\"\"\n",
    "    true = np.copy(true)  # ? do we need this\n",
    "    pred = np.copy(pred)\n",
    "    true_id_list = list(np.unique(true))\n",
    "    pred_id_list = list(np.unique(pred))\n",
    "\n",
    "    true_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for t in true_id_list[1:]:\n",
    "        t_mask = np.array(true == t, np.uint8)\n",
    "        true_masks.append(t_mask)\n",
    "\n",
    "    pred_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for p in pred_id_list[1:]:\n",
    "        p_mask = np.array(pred == p, np.uint8)\n",
    "        pred_masks.append(p_mask)\n",
    "\n",
    "    # prefill with value\n",
    "    pairwise_inter = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "    pairwise_union = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "\n",
    "    # caching pairwise\n",
    "    for true_id in true_id_list[1:]:  # 0-th is background\n",
    "        t_mask = true_masks[true_id]\n",
    "        pred_true_overlap = pred[t_mask > 0]\n",
    "        pred_true_overlap_id = np.unique(pred_true_overlap)\n",
    "        pred_true_overlap_id = list(pred_true_overlap_id)\n",
    "        for pred_id in pred_true_overlap_id:\n",
    "            if pred_id == 0:  # ignore\n",
    "                continue  # overlaping background\n",
    "\n",
    "            p_mask = pred_masks[pred_id]\n",
    "            total = (t_mask + p_mask).sum()\n",
    "            inter = (t_mask * p_mask).sum()\n",
    "            pairwise_inter[true_id - 1, pred_id - 1] = inter\n",
    "            pairwise_union[true_id - 1, pred_id - 1] = total - inter\n",
    "    #\n",
    "    pairwise_iou = pairwise_inter / (pairwise_union + 1.0e-6)\n",
    "    #### Munkres pairing to find maximal unique pairing\n",
    "    paired_true, paired_pred = linear_sum_assignment(-pairwise_iou)\n",
    "    ### extract the paired cost and remove invalid pair\n",
    "    paired_iou = pairwise_iou[paired_true, paired_pred]\n",
    "    # now select all those paired with iou != 0.0 i.e have intersection\n",
    "    paired_true = paired_true[paired_iou > 0.0]\n",
    "    paired_pred = paired_pred[paired_iou > 0.0]\n",
    "    paired_inter = pairwise_inter[paired_true, paired_pred]\n",
    "    paired_union = pairwise_union[paired_true, paired_pred]\n",
    "    paired_true = list(paired_true + 1)  # index to instance ID\n",
    "    paired_pred = list(paired_pred + 1)\n",
    "    overall_inter = paired_inter.sum()\n",
    "    overall_union = paired_union.sum()\n",
    "\n",
    "\n",
    "    # add all unpaired GT and Prediction into the union\n",
    "    unpaired_true = np.array(\n",
    "        [idx for idx in true_id_list[1:] if idx not in paired_true]\n",
    "    )\n",
    "    unpaired_pred = np.array(\n",
    "        [idx for idx in pred_id_list[1:] if idx not in paired_pred]\n",
    "    )\n",
    "    for true_id in unpaired_true:\n",
    "        overall_union += true_masks[true_id].sum()\n",
    "    for pred_id in unpaired_pred:\n",
    "        overall_union += pred_masks[pred_id].sum()\n",
    "    #\n",
    "    aji_score = overall_inter / overall_union\n",
    "    return aji_score\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8656294200848657 0.7460312648556475\n"
     ]
    }
   ],
   "source": [
    "#test, compute metrics for paried nucleus\n",
    "#add the score for each pair tp dataframe\n",
    "\n",
    "#dice_1\n",
    "dice1 = []\n",
    "\n",
    "#pq\n",
    "paired_true=0\n",
    "unpaired_true=0\n",
    "paired_iou = []\n",
    "#threshold for iou\n",
    "match_iou = 0.5\n",
    "\n",
    "#aji\n",
    "paired_inter= []\n",
    "paired_union = []\n",
    "\n",
    "\n",
    "for index, row in linked_df.iterrows():\n",
    "    groundtruth_mask = np.zeros(image_size)\n",
    "    predicted_mask = np.zeros(image_size)\n",
    "    groundtruth_mask = cv2.fillPoly(groundtruth_mask, pts=[np.array(row['contour']).astype(np.int32)],  color=1)\n",
    "    predicted_mask = cv2.fillPoly(predicted_mask, pts=[np.array(row['pred_contour']).astype(np.int32)],  color=1)\n",
    "\n",
    "    #inter1 = groundtruth_mask * predicted_mask\n",
    "    #denom = groundtruth_mask + predicted_mask\n",
    "    #dice = 2.0 * np.sum(inter1) / np.sum((denom+1.0e-6))\n",
    "    #dice1.append(dice)\n",
    "\n",
    "\n",
    "    iou = jaccard_score(groundtruth_mask,predicted_mask, average=\"micro\")\n",
    "    if(iou>0):\n",
    "        total = ( groundtruth_mask + predicted_mask).sum()\n",
    "        inter = ( groundtruth_mask * predicted_mask).sum()\n",
    "        paired_inter.append(inter)\n",
    "        paired_union.append(total-inter)\n",
    "\n",
    "\n",
    "    #iou is the same  as jaccard_score\n",
    "\n",
    "    #if(iou >= match_iou):\n",
    "        #paired_iou.append(iou)\n",
    "        #paired_true = paired_true+1\n",
    "    #extract unpaired nucleus\n",
    "    #else:\n",
    "        #unpaired_true  = unpaired_true+1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Panoptic Quality\n",
    "tp = paired_true\n",
    "fp = len(predicted_df)-len(np.unique(indices))\n",
    "fn = unpaired_true\n",
    "    # get the F1-score i.e DQ\n",
    "dq = tp / (tp + 0.5 * fp + 0.5 * fn)\n",
    "    # get the SQ, no paired has 0 iou so not impact\n",
    "sq = sum(paired_iou) / (tp + 1.0e-6)\n",
    "\n",
    "#Panoptic Quality and aji is for the whole image\n",
    "pq = dq * sq\n",
    "\n",
    "print(dq,sq,pq)\n",
    "\n",
    "#aji\n",
    "overall_inter = paired_inter.sum()\n",
    "overall_union = paired_union.sum()\n",
    "\n",
    "#add unpaired to overall union"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "306"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "78"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               contour  \\\n0    [[368, 427], [368, 428], [367, 428], [366, 429...   \n1    [[242, 339], [241, 340], [239, 340], [238, 341...   \n2    [[168, 364], [167, 365], [166, 365], [166, 366...   \n3    [[322, 384], [321, 385], [320, 385], [319, 386...   \n4    [[387, 334], [387, 335], [386, 335], [386, 336...   \n..                                                 ...   \n379  [[230.0, 311.0], [230.0, 313.0], [233.0, 313.0...   \n380  [[370, 314], [370, 315], [369, 315], [369, 317...   \n381  [[959.0, 403.0], [959.0, 404.0], [957.0, 404.0...   \n382  [[543, 354], [543, 355], [542, 355], [542, 356...   \n383  [[649, 491], [649, 492], [648, 492], [648, 493...   \n\n                                     centroid  \\\n0      (369.93939393939394, 438.969696969697)   \n1     (242.16666666666666, 346.2142857142857)   \n2    (172.02564102564102, 371.64102564102564)   \n3      (325.8695652173913, 392.4130434782609)   \n4      (390.0408163265306, 342.7959183673469)   \n..                                        ...   \n379   (248.45238095238096, 313.3095238095238)   \n380    (390.7014925373134, 322.2089552238806)   \n381               (961.75, 413.4935897435897)   \n382     (547.936170212766, 360.7659574468085)   \n383   (649.7631578947369, 497.42105263157896)   \n\n                                          pred_contour pred_centroid  \\\n0    [[369, 428], [367, 430], [367, 431], [366, 432...    [370, 439]   \n1    [[242, 338], [241, 339], [239, 339], [238, 340...    [242, 346]   \n2    [[172, 363], [171, 364], [169, 364], [168, 365...    [173, 372]   \n3    [[321, 384], [320, 385], [319, 385], [316, 388...    [325, 392]   \n4    [[391, 334], [390, 335], [388, 335], [387, 336...    [390, 343]   \n..                                                 ...           ...   \n379  [[242, 338], [241, 339], [239, 339], [238, 340...    [242, 346]   \n380  [[360, 314], [359, 315], [357, 315], [356, 316...    [377, 320]   \n381  [[957, 405], [956, 406], [954, 406], [952, 408...    [960, 413]   \n382  [[545, 354], [544, 355], [542, 355], [540, 357...    [549, 361]   \n383  [[628, 461], [627, 462], [626, 462], [625, 463...    [629, 474]   \n\n     jaccard_score       iou     dice1  \n0         0.776923  0.776923  0.872570  \n1         0.890152  0.890152  0.940000  \n2         0.854305  0.854305  0.919786  \n3         0.815873  0.815873  0.897033  \n4         0.821429  0.821429  0.900489  \n..             ...       ...       ...  \n379       0.000000  0.000000  0.000000  \n380       0.541069  0.541069  0.701606  \n381       0.730627  0.730627  0.843450  \n382       0.890977  0.890977  0.940476  \n383       0.000000  0.000000  0.000000  \n\n[384 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contour</th>\n      <th>centroid</th>\n      <th>pred_contour</th>\n      <th>pred_centroid</th>\n      <th>jaccard_score</th>\n      <th>iou</th>\n      <th>dice1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[368, 427], [368, 428], [367, 428], [366, 429...</td>\n      <td>(369.93939393939394, 438.969696969697)</td>\n      <td>[[369, 428], [367, 430], [367, 431], [366, 432...</td>\n      <td>[370, 439]</td>\n      <td>0.776923</td>\n      <td>0.776923</td>\n      <td>0.872570</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[242, 339], [241, 340], [239, 340], [238, 341...</td>\n      <td>(242.16666666666666, 346.2142857142857)</td>\n      <td>[[242, 338], [241, 339], [239, 339], [238, 340...</td>\n      <td>[242, 346]</td>\n      <td>0.890152</td>\n      <td>0.890152</td>\n      <td>0.940000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[168, 364], [167, 365], [166, 365], [166, 366...</td>\n      <td>(172.02564102564102, 371.64102564102564)</td>\n      <td>[[172, 363], [171, 364], [169, 364], [168, 365...</td>\n      <td>[173, 372]</td>\n      <td>0.854305</td>\n      <td>0.854305</td>\n      <td>0.919786</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[322, 384], [321, 385], [320, 385], [319, 386...</td>\n      <td>(325.8695652173913, 392.4130434782609)</td>\n      <td>[[321, 384], [320, 385], [319, 385], [316, 388...</td>\n      <td>[325, 392]</td>\n      <td>0.815873</td>\n      <td>0.815873</td>\n      <td>0.897033</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[387, 334], [387, 335], [386, 335], [386, 336...</td>\n      <td>(390.0408163265306, 342.7959183673469)</td>\n      <td>[[391, 334], [390, 335], [388, 335], [387, 336...</td>\n      <td>[390, 343]</td>\n      <td>0.821429</td>\n      <td>0.821429</td>\n      <td>0.900489</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>379</th>\n      <td>[[230.0, 311.0], [230.0, 313.0], [233.0, 313.0...</td>\n      <td>(248.45238095238096, 313.3095238095238)</td>\n      <td>[[242, 338], [241, 339], [239, 339], [238, 340...</td>\n      <td>[242, 346]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>380</th>\n      <td>[[370, 314], [370, 315], [369, 315], [369, 317...</td>\n      <td>(390.7014925373134, 322.2089552238806)</td>\n      <td>[[360, 314], [359, 315], [357, 315], [356, 316...</td>\n      <td>[377, 320]</td>\n      <td>0.541069</td>\n      <td>0.541069</td>\n      <td>0.701606</td>\n    </tr>\n    <tr>\n      <th>381</th>\n      <td>[[959.0, 403.0], [959.0, 404.0], [957.0, 404.0...</td>\n      <td>(961.75, 413.4935897435897)</td>\n      <td>[[957, 405], [956, 406], [954, 406], [952, 408...</td>\n      <td>[960, 413]</td>\n      <td>0.730627</td>\n      <td>0.730627</td>\n      <td>0.843450</td>\n    </tr>\n    <tr>\n      <th>382</th>\n      <td>[[543, 354], [543, 355], [542, 355], [542, 356...</td>\n      <td>(547.936170212766, 360.7659574468085)</td>\n      <td>[[545, 354], [544, 355], [542, 355], [540, 357...</td>\n      <td>[549, 361]</td>\n      <td>0.890977</td>\n      <td>0.890977</td>\n      <td>0.940476</td>\n    </tr>\n    <tr>\n      <th>383</th>\n      <td>[[649, 491], [649, 492], [648, 492], [648, 493...</td>\n      <td>(649.7631578947369, 497.42105263157896)</td>\n      <td>[[628, 461], [627, 462], [626, 462], [625, 463...</td>\n      <td>[629, 474]</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>384 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add metrics to dataframe\n",
    "#calculate aji\n",
    "linked_df['dice1']=dice1\n",
    "linked_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "#ashley:try out the metrics, inputs are binary masks of groundtruth and predicted nucleus\n",
    "#their functions also convert the true and pred inputs to binary masks.\n",
    "# I think they just take in an integer array of an image\n",
    "\n",
    "#question: do you compute these scores for each nuclei with its pair and take an average, or do you do it on the overall image\n",
    "#i did it on the overall image\n",
    "dc1= get_dice_1(groundtruth_mask,predicted_mask)\n",
    "dc2 = get_fast_dice_2(groundtruth_mask,predicted_mask) #this equals dc1\n",
    "\n",
    "dq, sq, pq = get_fast_pq(groundtruth_mask,predicted_mask)[0]\n",
    "\n",
    "\n",
    "#TODO: need to modify the function because the function is expecting labeled masks\n",
    "aji = get_fast_aji_plus(groundtruth_mask,predicted_mask)\n",
    "\n",
    "#theyalso have a pair-coordinates function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "#don't know what this does\n",
    "paired_true, paired_pred, unpaired_true, unpaired_pred = get_fast_pq(groundtruth_mask,predicted_mask)[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}