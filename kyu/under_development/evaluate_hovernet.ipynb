{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#open manual annotated image from geojson (exported qupath image as geojason because paquo installation failed)\n",
    "src = r'\\\\fatherserverdw\\Q\\research\\images\\skin_aging\\hovernet_tile\\hovernet_manual_validation'\n",
    "manual = os.path.join(src,'manual_annotation')\n",
    "predicted = os.path.join(src,'predicted_nuclei_contour')\n",
    "raw_ims = os.path.join(src,'raw_image')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#open manual annotations with json.load\n",
    "annotations = glob.glob(os.path.join(manual,'*.geojson'))\n",
    "annotation = annotations[1]\n",
    "with open(annotation) as f:\n",
    "  features = json.load(f)[\"features\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#create a list of manual contours\n",
    "man_coordinates = [np.squeeze(_['geometry']['coordinates']) for _ in features]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               contour\n0    [[368, 427], [368, 428], [367, 428], [366, 429...\n1    [[242, 339], [241, 340], [239, 340], [238, 341...\n2    [[168, 364], [167, 365], [166, 365], [166, 366...\n3    [[322, 384], [321, 385], [320, 385], [319, 386...\n4    [[387, 334], [387, 335], [386, 335], [386, 336...\n..                                                 ...\n379  [[230.0, 311.0], [230.0, 313.0], [233.0, 313.0...\n380  [[370, 314], [370, 315], [369, 315], [369, 317...\n381  [[959.0, 403.0], [959.0, 404.0], [957.0, 404.0...\n382  [[543, 354], [543, 355], [542, 355], [542, 356...\n383  [[649, 491], [649, 492], [648, 492], [648, 493...\n\n[384 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[368, 427], [368, 428], [367, 428], [366, 429...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[242, 339], [241, 340], [239, 340], [238, 341...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[168, 364], [167, 365], [166, 365], [166, 366...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[322, 384], [321, 385], [320, 385], [319, 386...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[387, 334], [387, 335], [386, 335], [386, 336...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>379</th>\n      <td>[[230.0, 311.0], [230.0, 313.0], [233.0, 313.0...</td>\n    </tr>\n    <tr>\n      <th>380</th>\n      <td>[[370, 314], [370, 315], [369, 315], [369, 317...</td>\n    </tr>\n    <tr>\n      <th>381</th>\n      <td>[[959.0, 403.0], [959.0, 404.0], [957.0, 404.0...</td>\n    </tr>\n    <tr>\n      <th>382</th>\n      <td>[[543, 354], [543, 355], [542, 355], [542, 356...</td>\n    </tr>\n    <tr>\n      <th>383</th>\n      <td>[[649, 491], [649, 492], [648, 492], [648, 493...</td>\n    </tr>\n  </tbody>\n</table>\n<p>384 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_df = pd.DataFrame({'contour':man_coordinates})\n",
    "manual_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# def contour2centroid(c):\n",
    "#     M = cv2.moments(c)\n",
    "#     cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "#     cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "#     return np.array([cX,cY])\n",
    "\n",
    "def contour2centroid(arr):\n",
    "    length = arr.shape[0]\n",
    "    sum_x = np.sum(arr[:, 0])\n",
    "    sum_y = np.sum(arr[:, 1])\n",
    "    return sum_x/length, sum_y/length"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               contour  \\\n0    [[368, 427], [368, 428], [367, 428], [366, 429...   \n1    [[242, 339], [241, 340], [239, 340], [238, 341...   \n2    [[168, 364], [167, 365], [166, 365], [166, 366...   \n3    [[322, 384], [321, 385], [320, 385], [319, 386...   \n4    [[387, 334], [387, 335], [386, 335], [386, 336...   \n..                                                 ...   \n379  [[230.0, 311.0], [230.0, 313.0], [233.0, 313.0...   \n380  [[370, 314], [370, 315], [369, 315], [369, 317...   \n381  [[959.0, 403.0], [959.0, 404.0], [957.0, 404.0...   \n382  [[543, 354], [543, 355], [542, 355], [542, 356...   \n383  [[649, 491], [649, 492], [648, 492], [648, 493...   \n\n                                     centroid  \n0      (369.93939393939394, 438.969696969697)  \n1     (242.16666666666666, 346.2142857142857)  \n2    (172.02564102564102, 371.64102564102564)  \n3      (325.8695652173913, 392.4130434782609)  \n4      (390.0408163265306, 342.7959183673469)  \n..                                        ...  \n379   (248.45238095238096, 313.3095238095238)  \n380    (390.7014925373134, 322.2089552238806)  \n381               (961.75, 413.4935897435897)  \n382     (547.936170212766, 360.7659574468085)  \n383   (649.7631578947369, 497.42105263157896)  \n\n[384 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contour</th>\n      <th>centroid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[368, 427], [368, 428], [367, 428], [366, 429...</td>\n      <td>(369.93939393939394, 438.969696969697)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[242, 339], [241, 340], [239, 340], [238, 341...</td>\n      <td>(242.16666666666666, 346.2142857142857)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[168, 364], [167, 365], [166, 365], [166, 366...</td>\n      <td>(172.02564102564102, 371.64102564102564)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[322, 384], [321, 385], [320, 385], [319, 386...</td>\n      <td>(325.8695652173913, 392.4130434782609)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[387, 334], [387, 335], [386, 335], [386, 336...</td>\n      <td>(390.0408163265306, 342.7959183673469)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>379</th>\n      <td>[[230.0, 311.0], [230.0, 313.0], [233.0, 313.0...</td>\n      <td>(248.45238095238096, 313.3095238095238)</td>\n    </tr>\n    <tr>\n      <th>380</th>\n      <td>[[370, 314], [370, 315], [369, 315], [369, 317...</td>\n      <td>(390.7014925373134, 322.2089552238806)</td>\n    </tr>\n    <tr>\n      <th>381</th>\n      <td>[[959.0, 403.0], [959.0, 404.0], [957.0, 404.0...</td>\n      <td>(961.75, 413.4935897435897)</td>\n    </tr>\n    <tr>\n      <th>382</th>\n      <td>[[543, 354], [543, 355], [542, 355], [542, 356...</td>\n      <td>(547.936170212766, 360.7659574468085)</td>\n    </tr>\n    <tr>\n      <th>383</th>\n      <td>[[649, 491], [649, 492], [648, 492], [648, 493...</td>\n      <td>(649.7631578947369, 497.42105263157896)</td>\n    </tr>\n  </tbody>\n</table>\n<p>384 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_df['centroid']=manual_df['contour'].apply(lambda row:contour2centroid(row))\n",
    "manual_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#open prediction\n",
    "pd_annotations = glob.glob(os.path.join(predicted,'*.json'))\n",
    "#open tile11\n",
    "pd_annotation = pd_annotations[0]\n",
    "with open(pd_annotation) as pd_f:\n",
    "  #bbox, centroid, contour\n",
    "  pd_features = json.load(pd_f)[\"nuc\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#create a list of predicted contours\n",
    "pd_contours=[]\n",
    "pd_centroids = []\n",
    "for key in pd_features:\n",
    "    temp = pd_features.get(key)\n",
    "    pd_contours.append(np.array(temp.get('contour')))\n",
    "    pd_centroids.append(np.round(temp.get('centroid'),0).astype('int'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               contour    centroid\n0    [[667, 300], [666, 301], [666, 302], [667, 301...  [690, 305]\n1    [[615, 306], [614, 307], [611, 307], [610, 308...  [612, 315]\n2    [[517, 309], [516, 310], [513, 310], [513, 311...  [522, 318]\n3    [[675, 310], [674, 311], [673, 311], [672, 312...  [679, 318]\n4    [[503, 311], [501, 313], [499, 313], [497, 315...  [502, 318]\n..                                                 ...         ...\n342  [[310, 921], [310, 922], [309, 923], [307, 923...  [310, 927]\n343  [[698, 930], [698, 931], [697, 932], [698, 933...  [704, 938]\n344  [[206, 942], [205, 943], [204, 943], [203, 944...  [206, 945]\n345  [[331, 951], [327, 955], [327, 956], [326, 957...  [331, 958]\n346  [[599, 967], [598, 968], [596, 968], [595, 969...  [590, 973]\n\n[347 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contour</th>\n      <th>centroid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[667, 300], [666, 301], [666, 302], [667, 301...</td>\n      <td>[690, 305]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[615, 306], [614, 307], [611, 307], [610, 308...</td>\n      <td>[612, 315]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[517, 309], [516, 310], [513, 310], [513, 311...</td>\n      <td>[522, 318]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[675, 310], [674, 311], [673, 311], [672, 312...</td>\n      <td>[679, 318]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[503, 311], [501, 313], [499, 313], [497, 315...</td>\n      <td>[502, 318]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>[[310, 921], [310, 922], [309, 923], [307, 923...</td>\n      <td>[310, 927]</td>\n    </tr>\n    <tr>\n      <th>343</th>\n      <td>[[698, 930], [698, 931], [697, 932], [698, 933...</td>\n      <td>[704, 938]</td>\n    </tr>\n    <tr>\n      <th>344</th>\n      <td>[[206, 942], [205, 943], [204, 943], [203, 944...</td>\n      <td>[206, 945]</td>\n    </tr>\n    <tr>\n      <th>345</th>\n      <td>[[331, 951], [327, 955], [327, 956], [326, 957...</td>\n      <td>[331, 958]</td>\n    </tr>\n    <tr>\n      <th>346</th>\n      <td>[[599, 967], [598, 968], [596, 968], [595, 969...</td>\n      <td>[590, 973]</td>\n    </tr>\n  </tbody>\n</table>\n<p>347 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df = pd.DataFrame({'contour':pd_contours,'centroid':pd_centroids})\n",
    "predicted_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#get size of origianl image\n",
    "raw = glob.glob(os.path.join(raw_ims,'*.tif'))\n",
    "raw_img = cv2.imread(raw[0])\n",
    "dim = raw_img.shape\n",
    "image_size = (dim[0],dim[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#Link ground truth to predicted nuclei\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "#create a list of manual centroids, and a list of predicted centroids\n",
    "manual_centroid= np.array(manual_df['centroid'].values.tolist())\n",
    "predicted_centroid= np.array(predicted_df['centroid'].values.tolist())\n",
    "nbrs = NearestNeighbors(n_neighbors=1, metric='euclidean').fit(predicted_centroid) #build model\n",
    "distances, indices = nbrs.kneighbors(manual_centroid) #apply model\n",
    "indices=np.squeeze(indices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               contour    centroid\n104  [[369, 428], [367, 430], [367, 431], [366, 432...  [370, 439]\n22   [[242, 338], [241, 339], [239, 339], [238, 340...  [242, 346]\n33   [[172, 363], [171, 364], [169, 364], [168, 365...  [173, 372]\n57   [[321, 384], [320, 385], [319, 385], [316, 388...  [325, 392]\n20   [[391, 334], [390, 335], [388, 335], [387, 336...  [390, 343]\n..                                                 ...         ...\n22   [[242, 338], [241, 339], [239, 339], [238, 340...  [242, 346]\n6    [[360, 314], [359, 315], [357, 315], [356, 316...  [377, 320]\n77   [[957, 405], [956, 406], [954, 406], [952, 408...  [960, 413]\n26   [[545, 354], [544, 355], [542, 355], [540, 357...  [549, 361]\n152  [[628, 461], [627, 462], [626, 462], [625, 463...  [629, 474]\n\n[384 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contour</th>\n      <th>centroid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>104</th>\n      <td>[[369, 428], [367, 430], [367, 431], [366, 432...</td>\n      <td>[370, 439]</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>[[242, 338], [241, 339], [239, 339], [238, 340...</td>\n      <td>[242, 346]</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>[[172, 363], [171, 364], [169, 364], [168, 365...</td>\n      <td>[173, 372]</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>[[321, 384], [320, 385], [319, 385], [316, 388...</td>\n      <td>[325, 392]</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>[[391, 334], [390, 335], [388, 335], [387, 336...</td>\n      <td>[390, 343]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>[[242, 338], [241, 339], [239, 339], [238, 340...</td>\n      <td>[242, 346]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[[360, 314], [359, 315], [357, 315], [356, 316...</td>\n      <td>[377, 320]</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>[[957, 405], [956, 406], [954, 406], [952, 408...</td>\n      <td>[960, 413]</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>[[545, 354], [544, 355], [542, 355], [540, 357...</td>\n      <td>[549, 361]</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>[[628, 461], [627, 462], [626, 462], [625, 463...</td>\n      <td>[629, 474]</td>\n    </tr>\n  </tbody>\n</table>\n<p>384 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df2 = predicted_df.iloc[indices]\n",
    "predicted_df2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               contour  \\\n0    [[368, 427], [368, 428], [367, 428], [366, 429...   \n1    [[242, 339], [241, 340], [239, 340], [238, 341...   \n2    [[168, 364], [167, 365], [166, 365], [166, 366...   \n3    [[322, 384], [321, 385], [320, 385], [319, 386...   \n4    [[387, 334], [387, 335], [386, 335], [386, 336...   \n..                                                 ...   \n379  [[230.0, 311.0], [230.0, 313.0], [233.0, 313.0...   \n380  [[370, 314], [370, 315], [369, 315], [369, 317...   \n381  [[959.0, 403.0], [959.0, 404.0], [957.0, 404.0...   \n382  [[543, 354], [543, 355], [542, 355], [542, 356...   \n383  [[649, 491], [649, 492], [648, 492], [648, 493...   \n\n                                     centroid  \\\n0      (369.93939393939394, 438.969696969697)   \n1     (242.16666666666666, 346.2142857142857)   \n2    (172.02564102564102, 371.64102564102564)   \n3      (325.8695652173913, 392.4130434782609)   \n4      (390.0408163265306, 342.7959183673469)   \n..                                        ...   \n379   (248.45238095238096, 313.3095238095238)   \n380    (390.7014925373134, 322.2089552238806)   \n381               (961.75, 413.4935897435897)   \n382     (547.936170212766, 360.7659574468085)   \n383   (649.7631578947369, 497.42105263157896)   \n\n                                          pred_contour pred_centroid  \n0    [[369, 428], [367, 430], [367, 431], [366, 432...    [370, 439]  \n1    [[242, 338], [241, 339], [239, 339], [238, 340...    [242, 346]  \n2    [[172, 363], [171, 364], [169, 364], [168, 365...    [173, 372]  \n3    [[321, 384], [320, 385], [319, 385], [316, 388...    [325, 392]  \n4    [[391, 334], [390, 335], [388, 335], [387, 336...    [390, 343]  \n..                                                 ...           ...  \n379  [[242, 338], [241, 339], [239, 339], [238, 340...    [242, 346]  \n380  [[360, 314], [359, 315], [357, 315], [356, 316...    [377, 320]  \n381  [[957, 405], [956, 406], [954, 406], [952, 408...    [960, 413]  \n382  [[545, 354], [544, 355], [542, 355], [540, 357...    [549, 361]  \n383  [[628, 461], [627, 462], [626, 462], [625, 463...    [629, 474]  \n\n[384 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contour</th>\n      <th>centroid</th>\n      <th>pred_contour</th>\n      <th>pred_centroid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[368, 427], [368, 428], [367, 428], [366, 429...</td>\n      <td>(369.93939393939394, 438.969696969697)</td>\n      <td>[[369, 428], [367, 430], [367, 431], [366, 432...</td>\n      <td>[370, 439]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[242, 339], [241, 340], [239, 340], [238, 341...</td>\n      <td>(242.16666666666666, 346.2142857142857)</td>\n      <td>[[242, 338], [241, 339], [239, 339], [238, 340...</td>\n      <td>[242, 346]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[168, 364], [167, 365], [166, 365], [166, 366...</td>\n      <td>(172.02564102564102, 371.64102564102564)</td>\n      <td>[[172, 363], [171, 364], [169, 364], [168, 365...</td>\n      <td>[173, 372]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[322, 384], [321, 385], [320, 385], [319, 386...</td>\n      <td>(325.8695652173913, 392.4130434782609)</td>\n      <td>[[321, 384], [320, 385], [319, 385], [316, 388...</td>\n      <td>[325, 392]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[387, 334], [387, 335], [386, 335], [386, 336...</td>\n      <td>(390.0408163265306, 342.7959183673469)</td>\n      <td>[[391, 334], [390, 335], [388, 335], [387, 336...</td>\n      <td>[390, 343]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>379</th>\n      <td>[[230.0, 311.0], [230.0, 313.0], [233.0, 313.0...</td>\n      <td>(248.45238095238096, 313.3095238095238)</td>\n      <td>[[242, 338], [241, 339], [239, 339], [238, 340...</td>\n      <td>[242, 346]</td>\n    </tr>\n    <tr>\n      <th>380</th>\n      <td>[[370, 314], [370, 315], [369, 315], [369, 317...</td>\n      <td>(390.7014925373134, 322.2089552238806)</td>\n      <td>[[360, 314], [359, 315], [357, 315], [356, 316...</td>\n      <td>[377, 320]</td>\n    </tr>\n    <tr>\n      <th>381</th>\n      <td>[[959.0, 403.0], [959.0, 404.0], [957.0, 404.0...</td>\n      <td>(961.75, 413.4935897435897)</td>\n      <td>[[957, 405], [956, 406], [954, 406], [952, 408...</td>\n      <td>[960, 413]</td>\n    </tr>\n    <tr>\n      <th>382</th>\n      <td>[[543, 354], [543, 355], [542, 355], [542, 356...</td>\n      <td>(547.936170212766, 360.7659574468085)</td>\n      <td>[[545, 354], [544, 355], [542, 355], [540, 357...</td>\n      <td>[549, 361]</td>\n    </tr>\n    <tr>\n      <th>383</th>\n      <td>[[649, 491], [649, 492], [648, 492], [648, 493...</td>\n      <td>(649.7631578947369, 497.42105263157896)</td>\n      <td>[[628, 461], [627, 462], [626, 462], [625, 463...</td>\n      <td>[629, 474]</td>\n    </tr>\n  </tbody>\n</table>\n<p>384 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linked_df = manual_df\n",
    "linked_df['pred_contour'] =predicted_df2.contour.reset_index(drop=True)\n",
    "linked_df['pred_centroid'] =predicted_df2.centroid.reset_index(drop=True)\n",
    "linked_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m groundtruth_mask \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mfillPoly(groundtruth_mask, pts\u001B[38;5;241m=\u001B[39m[np\u001B[38;5;241m.\u001B[39marray(row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontour\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mint32)],  color\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      7\u001B[0m predicted_mask \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mfillPoly(predicted_mask, pts\u001B[38;5;241m=\u001B[39m[np\u001B[38;5;241m.\u001B[39marray(row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpred_contour\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mint32)],  color\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m----> 8\u001B[0m score \u001B[38;5;241m=\u001B[39m \u001B[43mjaccard_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroundtruth_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43mpredicted_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmicro\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m scores\u001B[38;5;241m.\u001B[39mappend(score)\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:795\u001B[0m, in \u001B[0;36mjaccard_score\u001B[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m    667\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mjaccard_score\u001B[39m(\n\u001B[0;32m    668\u001B[0m     y_true,\n\u001B[0;32m    669\u001B[0m     y_pred,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    675\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    676\u001B[0m ):\n\u001B[0;32m    677\u001B[0m     \u001B[38;5;124;03m\"\"\"Jaccard similarity coefficient score.\u001B[39;00m\n\u001B[0;32m    678\u001B[0m \n\u001B[0;32m    679\u001B[0m \u001B[38;5;124;03m    The Jaccard index [1], or Jaccard similarity coefficient, defined as\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    793\u001B[0m \u001B[38;5;124;03m    array([1. , 0. , 0.33...])\u001B[39;00m\n\u001B[0;32m    794\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 795\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[43m_check_set_wise_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    796\u001B[0m     samplewise \u001B[38;5;241m=\u001B[39m average \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    797\u001B[0m     MCM \u001B[38;5;241m=\u001B[39m multilabel_confusion_matrix(\n\u001B[0;32m    798\u001B[0m         y_true,\n\u001B[0;32m    799\u001B[0m         y_pred,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    802\u001B[0m         samplewise\u001B[38;5;241m=\u001B[39msamplewise,\n\u001B[0;32m    803\u001B[0m     )\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1357\u001B[0m, in \u001B[0;36m_check_set_wise_labels\u001B[1;34m(y_true, y_pred, average, labels, pos_label)\u001B[0m\n\u001B[0;32m   1354\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m average \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m average_options \u001B[38;5;129;01mand\u001B[39;00m average \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1355\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maverage has to be one of \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(average_options))\n\u001B[1;32m-> 1357\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1358\u001B[0m \u001B[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001B[39;00m\n\u001B[0;32m   1359\u001B[0m \u001B[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001B[39;00m\n\u001B[0;32m   1360\u001B[0m present_labels \u001B[38;5;241m=\u001B[39m unique_labels(y_true, y_pred)\u001B[38;5;241m.\u001B[39mtolist()\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:86\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     84\u001B[0m check_consistent_length(y_true, y_pred)\n\u001B[0;32m     85\u001B[0m type_true \u001B[38;5;241m=\u001B[39m type_of_target(y_true, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 86\u001B[0m type_pred \u001B[38;5;241m=\u001B[39m \u001B[43mtype_of_target\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43my_pred\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     88\u001B[0m y_type \u001B[38;5;241m=\u001B[39m {type_true, type_pred}\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m}:\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\sklearn\\utils\\multiclass.py:286\u001B[0m, in \u001B[0;36mtype_of_target\u001B[1;34m(y, input_name)\u001B[0m\n\u001B[0;32m    283\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sparse_pandas:\n\u001B[0;32m    284\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my cannot be class \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSparseSeries\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSparseArray\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 286\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mis_multilabel\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel-indicator\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    289\u001B[0m \u001B[38;5;66;03m# DeprecationWarning will be replaced by ValueError, see NEP 34\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;66;03m# https://numpy.org/neps/nep-0034-infer-dtype-is-object.html\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\sklearn\\utils\\multiclass.py:173\u001B[0m, in \u001B[0;36mis_multilabel\u001B[1;34m(y)\u001B[0m\n\u001B[0;32m    164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m    165\u001B[0m         \u001B[38;5;28mlen\u001B[39m(y\u001B[38;5;241m.\u001B[39mdata) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    166\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m np\u001B[38;5;241m.\u001B[39munique(y\u001B[38;5;241m.\u001B[39mdata)\u001B[38;5;241m.\u001B[39msize \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    170\u001B[0m         )\n\u001B[0;32m    171\u001B[0m     )\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munique\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(labels) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m3\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[0;32m    176\u001B[0m         y\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbiu\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m _is_integral_float(labels)  \u001B[38;5;66;03m# bool, int, uint\u001B[39;00m\n\u001B[0;32m    177\u001B[0m     )\n",
      "File \u001B[1;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36munique\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\numpy\\lib\\arraysetops.py:272\u001B[0m, in \u001B[0;36munique\u001B[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001B[0m\n\u001B[0;32m    270\u001B[0m ar \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masanyarray(ar)\n\u001B[0;32m    271\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 272\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43m_unique1d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_inverse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_counts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    273\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _unpack_tuple(ret)\n\u001B[0;32m    275\u001B[0m \u001B[38;5;66;03m# axis was specified and not None\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\wsi_analysis\\lib\\site-packages\\numpy\\lib\\arraysetops.py:325\u001B[0m, in \u001B[0;36m_unique1d\u001B[1;34m(ar, return_index, return_inverse, return_counts)\u001B[0m\n\u001B[0;32m    320\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_unique1d\u001B[39m(ar, return_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, return_inverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    321\u001B[0m               return_counts\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m    322\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    323\u001B[0m \u001B[38;5;124;03m    Find the unique elements of an array, ignoring shape.\u001B[39;00m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 325\u001B[0m     ar \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masanyarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mar\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflatten\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    327\u001B[0m     optional_indices \u001B[38;5;241m=\u001B[39m return_index \u001B[38;5;129;01mor\u001B[39;00m return_inverse\n\u001B[0;32m    329\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m optional_indices:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "scores=[]\n",
    "#label is the pixel value (color) from [1,384]\n",
    "for index, row in linked_df.iterrows():\n",
    "    groundtruth_mask = np.zeros(image_size)\n",
    "    predicted_mask = np.zeros(image_size)\n",
    "    groundtruth_mask = cv2.fillPoly(groundtruth_mask, pts=[np.array(row['contour']).astype(np.int32)],  color=1)\n",
    "    predicted_mask = cv2.fillPoly(predicted_mask, pts=[np.array(row['pred_contour']).astype(np.int32)],  color=1)\n",
    "    score = jaccard_score(groundtruth_mask,predicted_mask, average=\"micro\")\n",
    "    scores.append(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linked_df['jaccard_score']=scores\n",
    "linked_df #Look into why some cells have low score when centroids actually match"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(linked_df['jaccard_score'],100) #groundtruth has roughly 37 more nuclei 384 vs 347"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.mean(linked_df['jaccard_score'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "# --------------------------Optimised for Speed\n",
    "def get_fast_aji(true, pred):\n",
    "    \"\"\"AJI version distributed by MoNuSeg, has no permutation problem but suffered from\n",
    "    over-penalisation similar to DICE2.\n",
    "\n",
    "    Fast computation requires instance IDs are in contiguous orderding i.e [1, 2, 3, 4]\n",
    "    not [2, 3, 6, 10]. Please call `remap_label` before hand and `by_size` flag has no\n",
    "    effect on the result.\n",
    "\n",
    "    \"\"\"\n",
    "    true = np.copy(true)  # ? do we need this\n",
    "    pred = np.copy(pred)\n",
    "    true_id_list = list(np.unique(true))\n",
    "    pred_id_list = list(np.unique(pred))\n",
    "\n",
    "    true_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for t in true_id_list[1:]:\n",
    "        t_mask = np.array(true == t, np.uint8)\n",
    "        true_masks.append(t_mask)\n",
    "\n",
    "    pred_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for p in pred_id_list[1:]:\n",
    "        p_mask = np.array(pred == p, np.uint8)\n",
    "        pred_masks.append(p_mask)\n",
    "\n",
    "    # prefill with value\n",
    "    pairwise_inter = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "    pairwise_union = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "\n",
    "    # caching pairwise\n",
    "    for true_id in true_id_list[1:]:  # 0-th is background\n",
    "        t_mask = true_masks[true_id]\n",
    "        pred_true_overlap = pred[t_mask > 0]\n",
    "        pred_true_overlap_id = np.unique(pred_true_overlap)\n",
    "        pred_true_overlap_id = list(pred_true_overlap_id)\n",
    "        for pred_id in pred_true_overlap_id:\n",
    "            if pred_id == 0:  # ignore\n",
    "                continue  # overlaping background\n",
    "            p_mask = pred_masks[pred_id]\n",
    "            total = (t_mask + p_mask).sum()\n",
    "            inter = (t_mask * p_mask).sum()\n",
    "            pairwise_inter[true_id - 1, pred_id - 1] = inter\n",
    "            pairwise_union[true_id - 1, pred_id - 1] = total - inter\n",
    "\n",
    "    pairwise_iou = pairwise_inter / (pairwise_union + 1.0e-6)\n",
    "    # pair of pred that give highest iou for each true, dont care\n",
    "    # about reusing pred instance multiple times\n",
    "    paired_pred = np.argmax(pairwise_iou, axis=1)\n",
    "    pairwise_iou = np.max(pairwise_iou, axis=1)\n",
    "    # exlude those dont have intersection\n",
    "    paired_true = np.nonzero(pairwise_iou > 0.0)[0]\n",
    "    paired_pred = paired_pred[paired_true]\n",
    "    # print(paired_true.shape, paired_pred.shape)\n",
    "    overall_inter = (pairwise_inter[paired_true, paired_pred]).sum()\n",
    "    overall_union = (pairwise_union[paired_true, paired_pred]).sum()\n",
    "\n",
    "    paired_true = list(paired_true + 1)  # index to instance ID\n",
    "    paired_pred = list(paired_pred + 1)\n",
    "    # add all unpaired GT and Prediction into the union\n",
    "    unpaired_true = np.array(\n",
    "        [idx for idx in true_id_list[1:] if idx not in paired_true]\n",
    "    )\n",
    "    unpaired_pred = np.array(\n",
    "        [idx for idx in pred_id_list[1:] if idx not in paired_pred]\n",
    "    )\n",
    "    for true_id in unpaired_true:\n",
    "        overall_union += true_masks[true_id].sum()\n",
    "    for pred_id in unpaired_pred:\n",
    "        overall_union += pred_masks[pred_id].sum()\n",
    "\n",
    "    aji_score = overall_inter / overall_union\n",
    "    return aji_score\n",
    "\n",
    "\n",
    "#####\n",
    "def get_fast_aji_plus(true, pred):\n",
    "    \"\"\"AJI+, an AJI version with maximal unique pairing to obtain overall intersecion.\n",
    "    Every prediction instance is paired with at most 1 GT instance (1 to 1) mapping, unlike AJI\n",
    "    where a prediction instance can be paired against many GT instances (1 to many).\n",
    "    Remaining unpaired GT and Prediction instances will be added to the overall union.\n",
    "    The 1 to 1 mapping prevents AJI's over-penalisation from happening.\n",
    "\n",
    "    Fast computation requires instance IDs are in contiguous orderding i.e [1, 2, 3, 4]\n",
    "    not [2, 3, 6, 10]. Please call `remap_label` before hand and `by_size` flag has no\n",
    "    effect on the result.\n",
    "\n",
    "    \"\"\"\n",
    "    true = np.copy(true)  # ? do we need this\n",
    "    pred = np.copy(pred)\n",
    "    true_id_list = list(np.unique(true))\n",
    "    pred_id_list = list(np.unique(pred))\n",
    "\n",
    "    true_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for t in true_id_list[1:]:\n",
    "        t_mask = np.array(true == t, np.uint8)\n",
    "        true_masks.append(t_mask)\n",
    "\n",
    "    pred_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for p in pred_id_list[1:]:\n",
    "        p_mask = np.array(pred == p, np.uint8)\n",
    "        pred_masks.append(p_mask)\n",
    "\n",
    "    # prefill with value\n",
    "    pairwise_inter = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "    pairwise_union = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "\n",
    "    # caching pairwise\n",
    "    for true_id in true_id_list[1:]:  # 0-th is background\n",
    "        t_mask = true_masks[true_id]\n",
    "        pred_true_overlap = pred[t_mask > 0]\n",
    "        pred_true_overlap_id = np.unique(pred_true_overlap)\n",
    "        pred_true_overlap_id = list(pred_true_overlap_id)\n",
    "        for pred_id in pred_true_overlap_id:\n",
    "            if pred_id == 0:  # ignore\n",
    "                continue  # overlaping background\n",
    "            p_mask = pred_masks[pred_id]\n",
    "            total = (t_mask + p_mask).sum()\n",
    "            inter = (t_mask * p_mask).sum()\n",
    "            pairwise_inter[true_id - 1, pred_id - 1] = inter\n",
    "            pairwise_union[true_id - 1, pred_id - 1] = total - inter\n",
    "    #\n",
    "    pairwise_iou = pairwise_inter / (pairwise_union + 1.0e-6)\n",
    "    #### Munkres pairing to find maximal unique pairing\n",
    "    paired_true, paired_pred = linear_sum_assignment(-pairwise_iou)\n",
    "    ### extract the paired cost and remove invalid pair\n",
    "    paired_iou = pairwise_iou[paired_true, paired_pred]\n",
    "    # now select all those paired with iou != 0.0 i.e have intersection\n",
    "    paired_true = paired_true[paired_iou > 0.0]\n",
    "    paired_pred = paired_pred[paired_iou > 0.0]\n",
    "    paired_inter = pairwise_inter[paired_true, paired_pred]\n",
    "    paired_union = pairwise_union[paired_true, paired_pred]\n",
    "    paired_true = list(paired_true + 1)  # index to instance ID\n",
    "    paired_pred = list(paired_pred + 1)\n",
    "    overall_inter = paired_inter.sum()\n",
    "    overall_union = paired_union.sum()\n",
    "    # add all unpaired GT and Prediction into the union\n",
    "    unpaired_true = np.array(\n",
    "        [idx for idx in true_id_list[1:] if idx not in paired_true]\n",
    "    )\n",
    "    unpaired_pred = np.array(\n",
    "        [idx for idx in pred_id_list[1:] if idx not in paired_pred]\n",
    "    )\n",
    "    for true_id in unpaired_true:\n",
    "        overall_union += true_masks[true_id].sum()\n",
    "    for pred_id in unpaired_pred:\n",
    "        overall_union += pred_masks[pred_id].sum()\n",
    "    #\n",
    "    aji_score = overall_inter / overall_union\n",
    "    return aji_score\n",
    "\n",
    "\n",
    "#####\n",
    "def get_fast_pq(true, pred, match_iou=0.5):\n",
    "    \"\"\"`match_iou` is the IoU threshold level to determine the pairing between\n",
    "    GT instances `p` and prediction instances `g`. `p` and `g` is a pair\n",
    "    if IoU > `match_iou`. However, pair of `p` and `g` must be unique\n",
    "    (1 prediction instance to 1 GT instance mapping).\n",
    "\n",
    "    If `match_iou` < 0.5, Munkres assignment (solving minimum weight matching\n",
    "    in bipartite graphs) is caculated to find the maximal amount of unique pairing.\n",
    "\n",
    "    If `match_iou` >= 0.5, all IoU(p,g) > 0.5 pairing is proven to be unique and\n",
    "    the number of pairs is also maximal.\n",
    "\n",
    "    Fast computation requires instance IDs are in contiguous orderding\n",
    "    i.e [1, 2, 3, 4] not [2, 3, 6, 10]. Please call `remap_label` beforehand\n",
    "    and `by_size` flag has no effect on the result.\n",
    "\n",
    "    Returns:\n",
    "        [dq, sq, pq]: measurement statistic\n",
    "\n",
    "        [paired_true, paired_pred, unpaired_true, unpaired_pred]:\n",
    "                      pairing information to perform measurement\n",
    "\n",
    "    \"\"\"\n",
    "    assert match_iou >= 0.0, \"Cant' be negative\"\n",
    "\n",
    "    true = np.copy(true)\n",
    "    pred = np.copy(pred)\n",
    "    true_id_list = list(np.unique(true))\n",
    "    pred_id_list = list(np.unique(pred))\n",
    "\n",
    "    true_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for t in true_id_list[1:]:\n",
    "        t_mask = np.array(true == t, np.uint8)\n",
    "        true_masks.append(t_mask)\n",
    "\n",
    "    pred_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for p in pred_id_list[1:]:\n",
    "        p_mask = np.array(pred == p, np.uint8)\n",
    "        pred_masks.append(p_mask)\n",
    "\n",
    "    # prefill with value\n",
    "    pairwise_iou = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "\n",
    "    # caching pairwise iou\n",
    "    for true_id in true_id_list[1:]:  # 0-th is background\n",
    "        t_mask = true_masks[true_id]\n",
    "        pred_true_overlap = pred[t_mask > 0]\n",
    "        pred_true_overlap_id = np.unique(pred_true_overlap)\n",
    "        pred_true_overlap_id = list(pred_true_overlap_id)\n",
    "        for pred_id in pred_true_overlap_id:\n",
    "            if pred_id == 0:  # ignore\n",
    "                continue  # overlaping background\n",
    "            p_mask = pred_masks[pred_id]\n",
    "            total = (t_mask + p_mask).sum()\n",
    "            inter = (t_mask * p_mask).sum()\n",
    "            iou = inter / (total - inter)\n",
    "            pairwise_iou[true_id - 1, pred_id - 1] = iou\n",
    "    #\n",
    "    if match_iou >= 0.5:\n",
    "        paired_iou = pairwise_iou[pairwise_iou > match_iou]\n",
    "        pairwise_iou[pairwise_iou <= match_iou] = 0.0\n",
    "        paired_true, paired_pred = np.nonzero(pairwise_iou)\n",
    "        paired_iou = pairwise_iou[paired_true, paired_pred]\n",
    "        paired_true += 1  # index is instance id - 1\n",
    "        paired_pred += 1  # hence return back to original\n",
    "    else:  # * Exhaustive maximal unique pairing\n",
    "        #### Munkres pairing with scipy library\n",
    "        # the algorithm return (row indices, matched column indices)\n",
    "        # if there is multiple same cost in a row, index of first occurence\n",
    "        # is return, thus the unique pairing is ensure\n",
    "        # inverse pair to get high IoU as minimum\n",
    "        paired_true, paired_pred = linear_sum_assignment(-pairwise_iou)\n",
    "        ### extract the paired cost and remove invalid pair\n",
    "        paired_iou = pairwise_iou[paired_true, paired_pred]\n",
    "\n",
    "        # now select those above threshold level\n",
    "        # paired with iou = 0.0 i.e no intersection => FP or FN\n",
    "        paired_true = list(paired_true[paired_iou > match_iou] + 1)\n",
    "        paired_pred = list(paired_pred[paired_iou > match_iou] + 1)\n",
    "        paired_iou = paired_iou[paired_iou > match_iou]\n",
    "\n",
    "    # get the actual FP and FN\n",
    "    unpaired_true = [idx for idx in true_id_list[1:] if idx not in paired_true]\n",
    "    unpaired_pred = [idx for idx in pred_id_list[1:] if idx not in paired_pred]\n",
    "    # print(paired_iou.shape, paired_true.shape, len(unpaired_true), len(unpaired_pred))\n",
    "\n",
    "    #\n",
    "    tp = len(paired_true)\n",
    "    fp = len(unpaired_pred)\n",
    "    fn = len(unpaired_true)\n",
    "    # get the F1-score i.e DQ\n",
    "    dq = tp / (tp + 0.5 * fp + 0.5 * fn)\n",
    "    # get the SQ, no paired has 0 iou so not impact\n",
    "    sq = paired_iou.sum() / (tp + 1.0e-6)\n",
    "\n",
    "    return [dq, sq, dq * sq], [paired_true, paired_pred, unpaired_true, unpaired_pred]\n",
    "\n",
    "\n",
    "#####\n",
    "def get_fast_dice_2(true, pred):\n",
    "    \"\"\"Ensemble dice.\"\"\"\n",
    "    true = np.copy(true)\n",
    "    pred = np.copy(pred)\n",
    "    true_id = list(np.unique(true))\n",
    "    pred_id = list(np.unique(pred))\n",
    "\n",
    "    overall_total = 0\n",
    "    overall_inter = 0\n",
    "\n",
    "    true_masks = [np.zeros(true.shape)]\n",
    "    for t in true_id[1:]:\n",
    "        t_mask = np.array(true == t, np.uint8)\n",
    "        true_masks.append(t_mask)\n",
    "\n",
    "    pred_masks = [np.zeros(true.shape)]\n",
    "    for p in pred_id[1:]:\n",
    "        p_mask = np.array(pred == p, np.uint8)\n",
    "        pred_masks.append(p_mask)\n",
    "\n",
    "    for true_idx in range(1, len(true_id)):\n",
    "        t_mask = true_masks[true_idx]\n",
    "        pred_true_overlap = pred[t_mask > 0]\n",
    "        pred_true_overlap_id = np.unique(pred_true_overlap)\n",
    "        pred_true_overlap_id = list(pred_true_overlap_id)\n",
    "        try:  # blinly remove background\n",
    "            pred_true_overlap_id.remove(0)\n",
    "        except ValueError:\n",
    "            pass  # just mean no background\n",
    "        for pred_idx in pred_true_overlap_id:\n",
    "            p_mask = pred_masks[pred_idx]\n",
    "            total = (t_mask + p_mask).sum()\n",
    "            inter = (t_mask * p_mask).sum()\n",
    "            overall_total += total\n",
    "            overall_inter += inter\n",
    "\n",
    "    return 2 * overall_inter / overall_total\n",
    "\n",
    "\n",
    "#####--------------------------As pseudocode\n",
    "def get_dice_1(true, pred):\n",
    "    \"\"\"Traditional dice.\"\"\"\n",
    "    # cast to binary 1st\n",
    "    true = np.copy(true)\n",
    "    pred = np.copy(pred)\n",
    "    true[true > 0] = 1\n",
    "    pred[pred > 0] = 1\n",
    "    inter = true * pred\n",
    "    denom = true + pred\n",
    "    return 2.0 * np.sum(inter) / np.sum(denom)\n",
    "\n",
    "\n",
    "####\n",
    "def get_dice_2(true, pred):\n",
    "    \"\"\"Ensemble Dice as used in Computational Precision Medicine Challenge.\"\"\"\n",
    "    true = np.copy(true)\n",
    "    pred = np.copy(pred)\n",
    "    true_id = list(np.unique(true))\n",
    "    pred_id = list(np.unique(pred))\n",
    "    # remove background aka id 0\n",
    "    true_id.remove(0)\n",
    "    pred_id.remove(0)\n",
    "\n",
    "    total_markup = 0\n",
    "    total_intersect = 0\n",
    "    for t in true_id:\n",
    "        t_mask = np.array(true == t, np.uint8)\n",
    "        for p in pred_id:\n",
    "            p_mask = np.array(pred == p, np.uint8)\n",
    "            intersect = p_mask * t_mask\n",
    "            if intersect.sum() > 0:\n",
    "                total_intersect += intersect.sum()\n",
    "                total_markup += t_mask.sum() + p_mask.sum()\n",
    "    return 2 * total_intersect / total_markup\n",
    "\n",
    "\n",
    "#####\n",
    "def remap_label(pred, by_size=False):\n",
    "    \"\"\"Rename all instance id so that the id is contiguous i.e [0, 1, 2, 3]\n",
    "    not [0, 2, 4, 6]. The ordering of instances (which one comes first)\n",
    "    is preserved unless by_size=True, then the instances will be reordered\n",
    "    so that bigger nucler has smaller ID.\n",
    "\n",
    "    Args:\n",
    "        pred    : the 2d array contain instances where each instances is marked\n",
    "                  by non-zero integer\n",
    "        by_size : renaming with larger nuclei has smaller id (on-top)\n",
    "\n",
    "    \"\"\"\n",
    "    pred_id = list(np.unique(pred))\n",
    "    pred_id.remove(0)\n",
    "    if len(pred_id) == 0:\n",
    "        return pred  # no label\n",
    "    if by_size:\n",
    "        pred_size = []\n",
    "        for inst_id in pred_id:\n",
    "            size = (pred == inst_id).sum()\n",
    "            pred_size.append(size)\n",
    "        # sort the id by size in descending order\n",
    "        pair_list = zip(pred_id, pred_size)\n",
    "        pair_list = sorted(pair_list, key=lambda x: x[1], reverse=True)\n",
    "        pred_id, pred_size = zip(*pair_list)\n",
    "\n",
    "    new_pred = np.zeros(pred.shape, np.int32)\n",
    "    for idx, inst_id in enumerate(pred_id):\n",
    "        new_pred[pred == inst_id] = idx + 1\n",
    "    return new_pred\n",
    "\n",
    "\n",
    "#####\n",
    "def pair_coordinates(setA, setB, radius):\n",
    "    \"\"\"Use the Munkres or Kuhn-Munkres algorithm to find the most optimal\n",
    "    unique pairing (largest possible match) when pairing points in set B\n",
    "    against points in set A, using distance as cost function.\n",
    "\n",
    "    Args:\n",
    "        setA, setB: np.array (float32) of size Nx2 contains the of XY coordinate\n",
    "                    of N different points\n",
    "        radius: valid area around a point in setA to consider\n",
    "                a given coordinate in setB a candidate for match\n",
    "    Return:\n",
    "        pairing: pairing is an array of indices\n",
    "        where point at index pairing[0] in set A paired with point\n",
    "        in set B at index pairing[1]\n",
    "        unparedA, unpairedB: remaining poitn in set A and set B unpaired\n",
    "\n",
    "    \"\"\"\n",
    "    # * Euclidean distance as the cost matrix\n",
    "    pair_distance = scipy.spatial.distance.cdist(setA, setB, metric='euclidean')\n",
    "\n",
    "    # * Munkres pairing with scipy library\n",
    "    # the algorithm return (row indices, matched column indices)\n",
    "    # if there is multiple same cost in a row, index of first occurence\n",
    "    # is return, thus the unique pairing is ensured\n",
    "    indicesA, paired_indicesB = linear_sum_assignment(pair_distance)\n",
    "\n",
    "    # extract the paired cost and remove instances\n",
    "    # outside of designated radius\n",
    "    pair_cost = pair_distance[indicesA, paired_indicesB]\n",
    "\n",
    "    pairedA = indicesA[pair_cost <= radius]\n",
    "    pairedB = paired_indicesB[pair_cost <= radius]\n",
    "\n",
    "    pairing = np.concatenate([pairedA[:,None], pairedB[:,None]], axis=-1)\n",
    "    unpairedA = np.delete(np.arange(setA.shape[0]), pairedA)\n",
    "    unpairedB = np.delete(np.arange(setB.shape[0]), pairedB)\n",
    "    return pairing, unpairedA, unpairedB"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "groundtruth_mask = np.zeros(image_size).astype('uint8')\n",
    "predicted_mask = np.zeros(image_size).astype('uint8')\n",
    "for index, row in linked_df.iterrows():\n",
    "    groundtruth_mask = cv2.fillPoly(groundtruth_mask, pts=[np.array(row['contour']).astype(np.int32)],  color=1)\n",
    "    predicted_mask = cv2.fillPoly(predicted_mask, pts=[np.array(row['pred_contour']).astype(np.int32)],  color=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "#ashley:try out the metrics, inputs are binary mask of all the nucleus\n",
    "dc1= get_dice_1(groundtruth_mask,predicted_mask)\n",
    "dc2 = get_fast_dice_2(groundtruth_mask,predicted_mask) #this equals dc1\n",
    "\n",
    "dq, sq, pq = get_fast_pq(groundtruth_mask,predicted_mask)[0]\n",
    "aji = get_fast_aji_plus(groundtruth_mask,predicted_mask)\n",
    "\n",
    "#they also have a pair-coordinates function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "#don't know what this does\n",
    "paired_true, paired_pred, unpaired_true, unpaired_pred = get_fast_pq(groundtruth_mask,predicted_mask)[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}