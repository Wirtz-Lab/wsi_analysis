{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "#cycle gan does unpaired learning\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T14:20:49.489853Z",
     "end_time": "2023-04-07T14:20:49.511594Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "#create a list of image file paths\n",
    "# https://cs230.stanford.edu/blog/datapipeline/#best-practices\n",
    "\n",
    "DATA_DIR = r\"\\\\shelter\\Kyu\\unstain2stain\\unstain2stain_tile\\train\"\n",
    "train_he = sorted(glob.glob(os.path.join(*[DATA_DIR, 'HE\\OTS_14684_2_he\\*.png'])))\n",
    "train_unstained = sorted(glob.glob(os.path.join(*[DATA_DIR,'Unstained\\OTS_14684_2\\*.png'])))\n",
    "val_he = sorted(glob.glob(os.path.join(*[DATA_DIR, 'HE\\OTS_14684_3_he\\*.png'])))\n",
    "val_unstained = sorted(glob.glob(os.path.join(*[DATA_DIR, 'Unstained\\OTS_14684_3\\*.png'])))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T14:20:49.656566Z",
     "end_time": "2023-04-07T14:20:49.792564Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 1024\n",
    "IMG_HEIGHT = 1024\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T14:20:49.849527Z",
     "end_time": "2023-04-07T14:20:49.870777Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "#image pre-process\n",
    "def random_crop(image):\n",
    "  cropped_image = tf.image.random_crop(\n",
    "      image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "  return cropped_image\n",
    "\n",
    "# normalizing the images to [-1, 1]\n",
    "def normalize(image,label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = (image / 127.5) - 1\n",
    "  return image\n",
    "\n",
    "def random_jitter(image,label):\n",
    "  # resizing to 286 x 286 x 3\n",
    "  image = tf.image.resize(image, [286, 286],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "  # randomly cropping to 256 x 256 x 3\n",
    "  image = random_crop(image)\n",
    "\n",
    "  # random mirroring\n",
    "  image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "  return image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T14:20:50.007023Z",
     "end_time": "2023-04-07T14:20:50.013279Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def preprocess_image_train(image):\n",
    "  image = random_jitter(image)\n",
    "  image = normalize(image)\n",
    "  return image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T14:20:50.175834Z",
     "end_time": "2023-04-07T14:20:50.199143Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def preprocess_image_test(image):\n",
    "  image = normalize(image)\n",
    "  return image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T14:20:51.177840Z",
     "end_time": "2023-04-07T14:20:51.185625Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "#copied from kyu\n",
    "def read_image(image_path, mask=False):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    # image = cv2.imread(image_path.decode('UTF-8'))\n",
    "    if mask:\n",
    "        image = tf.image.decode_png(image, channels=1)\n",
    "        image.set_shape([None, None, 1])\n",
    "        image = tf.image.resize(images=image, size=[IMG_WIDTH, IMG_WIDTH])\n",
    "        # image[image==13]=0\n",
    "        image = tf.where(tf.equal(image, 13), tf.zeros_like(image), image)\n",
    "    else:\n",
    "        image = tf.image.decode_png(image, channels=3)\n",
    "        image.set_shape([None, None, 3])\n",
    "        image = tf.image.resize(images=image, size=[IMG_WIDTH, IMG_WIDTH])\n",
    "        # image = image / 127.5 - 1 #[-1 1]\n",
    "        image = image/255 #[0 1]\n",
    "    return image\n",
    "\n",
    "def load_data(image_list):\n",
    "    image = read_image(image_list)\n",
    "    #mask = read_image(mask_list)\n",
    "    return image\n",
    "\n",
    "def data_generator(image_list):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image_list,labels)\n",
    "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    # dataset = dataset.map(lambda x,y: tf.numpy_function(load_data, [x,y], Tout=tf.uint8))\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    # dataset = dataset.prefetch(1) #added this to always prefetch 1 batch\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T14:21:58.701516Z",
     "end_time": "2023-04-07T14:21:58.716938Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[75], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m unstained_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mdata_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_unstained\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m he_dataset \u001B[38;5;241m=\u001B[39m data_generator(train_he)\n",
      "Cell \u001B[1;32mIn[74], line 25\u001B[0m, in \u001B[0;36mdata_generator\u001B[1;34m(image_list)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdata_generator\u001B[39m(image_list):\n\u001B[1;32m---> 25\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mfrom_tensor_slices(image_list,\u001B[43mlabels\u001B[49m)\n\u001B[0;32m     26\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mmap(load_data, num_parallel_calls\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mAUTOTUNE)\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;66;03m# dataset = dataset.map(lambda x,y: tf.numpy_function(load_data, [x,y], Tout=tf.uint8))\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "unstained_dataset = data_generator(train_unstained)\n",
    "he_dataset = data_generator(train_he)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T14:17:05.371568Z",
     "end_time": "2023-04-07T14:17:05.386425Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "#feed into a model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T14:17:05.515778Z",
     "end_time": "2023-04-07T14:17:05.542490Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "dataset, metadata = tfds.load('cycle_gan/horse2zebra',\n",
    "                              with_info=True, as_supervised=True)\n",
    "\n",
    "train_horses, train_zebras = dataset['trainA'], dataset['trainB']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T14:17:05.770077Z",
     "end_time": "2023-04-07T14:17:05.839424Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "<PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_horses"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T14:23:52.279975Z",
     "end_time": "2023-04-07T14:23:52.308160Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "def preprocess_image_train(image, label):\n",
    "  image = random_jitter(image)\n",
    "  image = normalize(image)\n",
    "  return image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T14:25:28.852170Z",
     "end_time": "2023-04-07T14:25:28.868521Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "def random_jitter(image):\n",
    "  # resizing to 286 x 286 x 3\n",
    "  image = tf.image.resize(image, [286, 286],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "  # randomly cropping to 256 x 256 x 3\n",
    "  image = random_crop(image)\n",
    "\n",
    "  # random mirroring\n",
    "  image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "  return image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T14:26:13.956251Z",
     "end_time": "2023-04-07T14:26:13.995801Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# normalizing the images to [-1, 1]\n",
    "def normalize(image):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = (image / 127.5) - 1\n",
    "  return image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T14:26:26.458574Z",
     "end_time": "2023-04-07T14:26:26.474199Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "train_horses = train_horses.cache().map(\n",
    "    preprocess_image_train, num_parallel_calls=AUTOTUNE).shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T14:26:26.879844Z",
     "end_time": "2023-04-07T14:26:26.917555Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "assertion failed: [Need value.shape >= size, got ] [286 286 3] [1024 1024 3]\n\t [[{{node random_crop/Assert/Assert}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[85], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m sample_horse \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_horses\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:761\u001B[0m, in \u001B[0;36mOwnedIterator.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    759\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    760\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 761\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    762\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mOutOfRangeError:\n\u001B[0;32m    763\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:744\u001B[0m, in \u001B[0;36mOwnedIterator._next_internal\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    741\u001B[0m \u001B[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001B[39;00m\n\u001B[0;32m    742\u001B[0m \u001B[38;5;66;03m# to communicate that there is no more data to iterate over.\u001B[39;00m\n\u001B[0;32m    743\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecution_mode(context\u001B[38;5;241m.\u001B[39mSYNC):\n\u001B[1;32m--> 744\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterator_get_next\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    745\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator_resource\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    746\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_output_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    747\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_shapes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_output_shapes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    749\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    750\u001B[0m     \u001B[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001B[39;00m\n\u001B[0;32m    751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_element_spec\u001B[38;5;241m.\u001B[39m_from_compatible_tensor_list(ret)  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:2727\u001B[0m, in \u001B[0;36miterator_get_next\u001B[1;34m(iterator, output_types, output_shapes, name)\u001B[0m\n\u001B[0;32m   2725\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m   2726\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m-> 2727\u001B[0m   \u001B[43m_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from_not_ok_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2728\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_FallbackException:\n\u001B[0;32m   2729\u001B[0m   \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6941\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[1;34m(e, name)\u001B[0m\n\u001B[0;32m   6939\u001B[0m message \u001B[38;5;241m=\u001B[39m e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6940\u001B[0m \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m-> 6941\u001B[0m \u001B[43msix\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_status_to_exception\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m<string>:3\u001B[0m, in \u001B[0;36mraise_from\u001B[1;34m(value, from_value)\u001B[0m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: assertion failed: [Need value.shape >= size, got ] [286 286 3] [1024 1024 3]\n\t [[{{node random_crop/Assert/Assert}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "sample_horse = next(iter(train_horses))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\labadmin\\AppData\\Local\\Temp\\ipykernel_14728\\24941931.py:2 preprocess_image_train  *\n        image = random_jitter(image)\n    C:\\Users\\labadmin\\AppData\\Local\\Temp\\ipykernel_14728\\2093225660.py:20 random_jitter  *\n        image = random_crop(image)\n    C:\\Users\\labadmin\\AppData\\Local\\Temp\\ipykernel_14728\\2093225660.py:3 random_crop  *\n        cropped_image = tf.image.random_crop(\n    C:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py:402 random_crop\n        math_ops.reduce_all(shape >= size),\n    C:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1817 wrapper\n        return fn(x, y, *args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:4048 greater_equal\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    C:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    C:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3561 _create_op_internal\n        ret = Operation(\n    C:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    C:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 4 and 3 for '{{node random_crop/GreaterEqual}} = GreaterEqual[T=DT_INT32](random_crop/Shape, random_crop/size)' with input shapes: [4], [3].\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[64], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m unstained_dataset \u001B[38;5;241m=\u001B[39m \u001B[43munstained_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreprocess_image_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mAUTOTUNE\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshuffle(\n\u001B[0;32m      3\u001B[0m     BUFFER_SIZE)\u001B[38;5;241m.\u001B[39mbatch(BATCH_SIZE)\n\u001B[0;32m      5\u001B[0m he_dataset \u001B[38;5;241m=\u001B[39m he_dataset\u001B[38;5;241m.\u001B[39mcache()\u001B[38;5;241m.\u001B[39mmap(\n\u001B[0;32m      6\u001B[0m     preprocess_image_train, num_parallel_calls\u001B[38;5;241m=\u001B[39mAUTOTUNE)\u001B[38;5;241m.\u001B[39mshuffle(\n\u001B[0;32m      7\u001B[0m     BUFFER_SIZE)\u001B[38;5;241m.\u001B[39mbatch(BATCH_SIZE)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1863\u001B[0m, in \u001B[0;36mDatasetV2.map\u001B[1;34m(self, map_func, num_parallel_calls, deterministic)\u001B[0m\n\u001B[0;32m   1861\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m MapDataset(\u001B[38;5;28mself\u001B[39m, map_func, preserve_cardinality\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m   1862\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1863\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mParallelMapDataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1864\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1865\u001B[0m \u001B[43m      \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1866\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1867\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdeterministic\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1868\u001B[0m \u001B[43m      \u001B[49m\u001B[43mpreserve_cardinality\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5020\u001B[0m, in \u001B[0;36mParallelMapDataset.__init__\u001B[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001B[0m\n\u001B[0;32m   5018\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_dataset \u001B[38;5;241m=\u001B[39m input_dataset\n\u001B[0;32m   5019\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_inter_op_parallelism \u001B[38;5;241m=\u001B[39m use_inter_op_parallelism\n\u001B[1;32m-> 5020\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func \u001B[38;5;241m=\u001B[39m \u001B[43mStructuredFunctionWrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   5021\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5022\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_transformation_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5023\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5024\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_legacy_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_legacy_function\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5025\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m deterministic \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   5026\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deterministic \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdefault\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4218\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__\u001B[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001B[0m\n\u001B[0;32m   4211\u001B[0m       warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   4212\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   4213\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moption is set, this option does not apply to tf.data functions. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   4214\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo force eager execution of tf.data functions, please use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   4215\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   4216\u001B[0m     fn_factory \u001B[38;5;241m=\u001B[39m trace_tf_function(defun_kwargs)\n\u001B[1;32m-> 4218\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function \u001B[38;5;241m=\u001B[39m \u001B[43mfn_factory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4219\u001B[0m \u001B[38;5;66;03m# There is no graph to add in eager mode.\u001B[39;00m\n\u001B[0;32m   4220\u001B[0m add_to_graph \u001B[38;5;241m&\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly()\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3150\u001B[0m, in \u001B[0;36mFunction.get_concrete_function\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3141\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_concrete_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   3142\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001B[39;00m\n\u001B[0;32m   3143\u001B[0m \n\u001B[0;32m   3144\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3148\u001B[0m \u001B[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001B[39;00m\n\u001B[0;32m   3149\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m-> 3150\u001B[0m   graph_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_concrete_function_garbage_collected(\n\u001B[0;32m   3151\u001B[0m       \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   3152\u001B[0m   graph_function\u001B[38;5;241m.\u001B[39m_garbage_collector\u001B[38;5;241m.\u001B[39mrelease()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   3153\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m graph_function\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3116\u001B[0m, in \u001B[0;36mFunction._get_concrete_function_garbage_collected\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3114\u001B[0m   args, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   3115\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m-> 3116\u001B[0m   graph_function, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3117\u001B[0m   seen_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[0;32m   3118\u001B[0m   captured \u001B[38;5;241m=\u001B[39m object_identity\u001B[38;5;241m.\u001B[39mObjectIdentitySet(\n\u001B[0;32m   3119\u001B[0m       graph_function\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39minternal_captures)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463\u001B[0m, in \u001B[0;36mFunction._maybe_define_function\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m   3459\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_define_function_with_shape_relaxation(\n\u001B[0;32m   3460\u001B[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001B[0;32m   3462\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_cache\u001B[38;5;241m.\u001B[39mmissed\u001B[38;5;241m.\u001B[39madd(call_context_key)\n\u001B[1;32m-> 3463\u001B[0m graph_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_graph_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3464\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_cache\u001B[38;5;241m.\u001B[39mprimary[cache_key] \u001B[38;5;241m=\u001B[39m graph_function\n\u001B[0;32m   3466\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m graph_function, filtered_flat_args\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298\u001B[0m, in \u001B[0;36mFunction._create_graph_function\u001B[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[0;32m   3293\u001B[0m missing_arg_names \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m   3294\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (arg, i) \u001B[38;5;28;01mfor\u001B[39;00m i, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(missing_arg_names)\n\u001B[0;32m   3295\u001B[0m ]\n\u001B[0;32m   3296\u001B[0m arg_names \u001B[38;5;241m=\u001B[39m base_arg_names \u001B[38;5;241m+\u001B[39m missing_arg_names\n\u001B[0;32m   3297\u001B[0m graph_function \u001B[38;5;241m=\u001B[39m ConcreteFunction(\n\u001B[1;32m-> 3298\u001B[0m     \u001B[43mfunc_graph_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc_graph_from_py_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3299\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3300\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_python_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3301\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3302\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3303\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_signature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3304\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3305\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3306\u001B[0m \u001B[43m        \u001B[49m\u001B[43marg_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43marg_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3307\u001B[0m \u001B[43m        \u001B[49m\u001B[43moverride_flat_arg_shapes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverride_flat_arg_shapes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3308\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapture_by_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_capture_by_value\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m   3309\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_attributes,\n\u001B[0;32m   3310\u001B[0m     function_spec\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_spec,\n\u001B[0;32m   3311\u001B[0m     \u001B[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001B[39;00m\n\u001B[0;32m   3312\u001B[0m     \u001B[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001B[39;00m\n\u001B[0;32m   3313\u001B[0m     \u001B[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001B[39;00m\n\u001B[0;32m   3314\u001B[0m     \u001B[38;5;66;03m# ConcreteFunction.\u001B[39;00m\n\u001B[0;32m   3315\u001B[0m     shared_func_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   3316\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m graph_function\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func\u001B[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001B[0m\n\u001B[0;32m   1004\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1005\u001B[0m   _, original_func \u001B[38;5;241m=\u001B[39m tf_decorator\u001B[38;5;241m.\u001B[39munwrap(python_func)\n\u001B[1;32m-> 1007\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m python_func(\u001B[38;5;241m*\u001B[39mfunc_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfunc_kwargs)\n\u001B[0;32m   1009\u001B[0m \u001B[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[39;00m\n\u001B[0;32m   1010\u001B[0m \u001B[38;5;66;03m# TensorArrays and `None`s.\u001B[39;00m\n\u001B[0;32m   1011\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m nest\u001B[38;5;241m.\u001B[39mmap_structure(convert, func_outputs,\n\u001B[0;32m   1012\u001B[0m                                   expand_composites\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4195\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001B[1;34m(*args)\u001B[0m\n\u001B[0;32m   4189\u001B[0m \u001B[38;5;129m@eager_function\u001B[39m\u001B[38;5;241m.\u001B[39mdefun_with_attributes(\n\u001B[0;32m   4190\u001B[0m     input_signature\u001B[38;5;241m=\u001B[39mstructure\u001B[38;5;241m.\u001B[39mget_flat_tensor_specs(\n\u001B[0;32m   4191\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_structure),\n\u001B[0;32m   4192\u001B[0m     autograph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   4193\u001B[0m     attributes\u001B[38;5;241m=\u001B[39mdefun_kwargs)\n\u001B[0;32m   4194\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_fn\u001B[39m(\u001B[38;5;241m*\u001B[39margs):  \u001B[38;5;66;03m# pylint: disable=missing-docstring\u001B[39;00m\n\u001B[1;32m-> 4195\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mwrapper_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4196\u001B[0m   ret \u001B[38;5;241m=\u001B[39m structure\u001B[38;5;241m.\u001B[39mto_tensor_list(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_structure, ret)\n\u001B[0;32m   4197\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m [ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(t) \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m ret]\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4125\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001B[1;34m(*args)\u001B[0m\n\u001B[0;32m   4123\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _should_unpack(nested_args):\n\u001B[0;32m   4124\u001B[0m   nested_args \u001B[38;5;241m=\u001B[39m (nested_args,)\n\u001B[1;32m-> 4125\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[43mautograph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtf_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mag_ctx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnested_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4126\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _should_pack(ret):\n\u001B[0;32m   4127\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(ret)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:695\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    693\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[0;32m    694\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 695\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mag_error_metadata\u001B[38;5;241m.\u001B[39mto_exception(e)\n\u001B[0;32m    696\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    697\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    C:\\Users\\labadmin\\AppData\\Local\\Temp\\ipykernel_14728\\24941931.py:2 preprocess_image_train  *\n        image = random_jitter(image)\n    C:\\Users\\labadmin\\AppData\\Local\\Temp\\ipykernel_14728\\2093225660.py:20 random_jitter  *\n        image = random_crop(image)\n    C:\\Users\\labadmin\\AppData\\Local\\Temp\\ipykernel_14728\\2093225660.py:3 random_crop  *\n        cropped_image = tf.image.random_crop(\n    C:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py:402 random_crop\n        math_ops.reduce_all(shape >= size),\n    C:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1817 wrapper\n        return fn(x, y, *args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:4048 greater_equal\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    C:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    C:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3561 _create_op_internal\n        ret = Operation(\n    C:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    C:\\ProgramData\\Anaconda3\\envs\\wsi_analysis39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 4 and 3 for '{{node random_crop/GreaterEqual}} = GreaterEqual[T=DT_INT32](random_crop/Shape, random_crop/size)' with input shapes: [4], [3].\n"
     ]
    }
   ],
   "source": [
    "unstained_dataset = unstained_dataset.cache().map(\n",
    "    preprocess_image_train, num_parallel_calls=AUTOTUNE).shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "he_dataset = he_dataset.cache().map(\n",
    "    preprocess_image_train, num_parallel_calls=AUTOTUNE).shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
