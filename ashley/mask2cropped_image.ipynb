{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS=None\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "from copy import deepcopy\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from glob import glob"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "from ctypes.util import *\n",
    "from ctypes import *\n",
    "find_library(\"libopenslide-0.dll\")\n",
    "lib = cdll.LoadLibrary(find_library(\"libopenslide-0.dll\"))\n",
    "import openslide"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "# open both wsi and annotation map\n",
    "wsi_src = r'\\\\fatherserverdw\\kyuex\\great'\n",
    "wsipaths = glob(os.path.join(wsi_src,'*ndpi'))\n",
    "iter_order = [2,10,5,4,6,11,7,9,8,12,3,1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "#todo:add class id and track area of each class\n",
    "#add maximum overlapp\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kyuha\\AppData\\Local\\Temp\\ipykernel_5488\\1101146299.py:39: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  imcrop_masked = np.multiply(np.array(imcrop),objmask[..., None].astype(np.bool))\n"
     ]
    }
   ],
   "source": [
    "for wsipath in wsipaths[0:1]:\n",
    "    wsi = openslide.OpenSlide(wsipath)\n",
    "    annotation_pth = wsipath.replace('ndpi','png')\n",
    "    annotation = Image.open(annotation_pth)  #40X resolution\n",
    "\n",
    "    #create folders for mskcrop and imcrop\n",
    "    folder_name = os.path.basename(wsipath)\n",
    "    folder_name = folder_name.removesuffix('.ndpi')\n",
    "    dirName1 = r'\\\\fatherserverdw\\kyuex\\great\\mask and crop\\{}imcrop'.format(folder_name)\n",
    "    dirName2 = r'\\\\fatherserverdw\\kyuex\\great\\mask and crop\\{}mskcrop'.format(folder_name)\n",
    "    if not os.path.exists(dirName1):\n",
    "        os.mkdir(dirName1)\n",
    "    if not os.path.exists(dirName2):\n",
    "        os.mkdir(dirName2)\n",
    "\n",
    "    #resize wsi image\n",
    "    target_level = 2\n",
    "    rsf = wsi.level_downsamples[target_level]\n",
    "    target_dim = wsi.level_dimensions[target_level]\n",
    "    annotation_resized = annotation.resize(target_dim,resample=0) #this step is a bottleneck\n",
    "    annotation_resized_arr = np.array(annotation_resized)\n",
    "\n",
    "    for classid in iter_order:\n",
    "    #get only the region with the particular class id\n",
    "        class_annotation = annotation_resized_arr == classid\n",
    "        labeled_map = measure.label(class_annotation)\n",
    "        regionprops = measure.regionprops(labeled_map)\n",
    "        boundboxes = [_.bbox for _ in regionprops]\n",
    "\n",
    "        for objID, boundbox in enumerate(boundboxes):\n",
    "            #crop at the boundaries\n",
    "            objmask =  deepcopy(labeled_map)\n",
    "            objmask[objmask != objID + 1] = 0\n",
    "            objmask[objmask == objID + 1]= classid#this field was class id\n",
    "            objmask = objmask[boundbox[0]:boundbox[2], boundbox[1]:boundbox[3]]\n",
    "            h, w = boundbox[2] - boundbox[0], boundbox[3] - boundbox[1]\n",
    "            #read cropped region\n",
    "            imcrop = wsi.read_region(location=(round(boundbox[1]*rsf), round(boundbox[0]*rsf)), level=target_level, size=(w, h))\n",
    "            imcrop_masked = np.multiply(np.array(imcrop),objmask[..., None].astype(np.bool))\n",
    "\n",
    "\n",
    "            Image.fromarray((imcrop_masked).astype(np.uint8)).save(r'\\\\fatherserverdw\\kyuex\\great\\mask and crop\\{}imcrop\\class{}_obj{}.png'.format(folder_name,classid, objID))\n",
    "            Image.fromarray(objmask.astype(np.uint8)).save(r'\\\\fatherserverdw\\kyuex\\great\\mask and crop\\{}mskcrop\\classnew{}_obj{}.png'.format(folder_name,classid, objID))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "(74880, 36608)"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation.size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "(18720, 9152)"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_resized.size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#----end,test code-------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "wsipath = wsipaths[0]\n",
    "#anno_src = os.path.expanduser(r'\\\\Users\\kyuha\\PycharmProjects\\wsi_analysis\\ashley')\n",
    "#anno_fn = '1C1temp.png'\n",
    "#annotation_map_path = os.path.join(anno_src, anno_fn)\n",
    "wsi = openslide.OpenSlide(wsipath)\n",
    "annotation_pth = wsipath.replace('ndpi','png')\n",
    "annotation = Image.open(annotation_pth)  #40X resolution\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "folder_name = os.path.basename(wsipath)\n",
    "folder_name = folder_name.removesuffix('.ndpi')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kyuha\\AppData\\Local\\Temp\\ipykernel_5488\\253837825.py:4: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  annotation_resized = annotation.resize(target_dim,resample=Image.BICUBIC) #this step is a bottleneck\n"
     ]
    }
   ],
   "source": [
    "target_level = 2\n",
    "rsf = wsi.level_downsamples[target_level]\n",
    "target_dim = wsi.level_dimensions[target_level]\n",
    "annotation_resized = annotation.resize(target_dim,resample=0) #this step is a bottleneck\n",
    "annotation_resized_arr = np.array(annotation_resized)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kyuha\\AppData\\Local\\Temp\\ipykernel_5488\\1725907988.py:18: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  imcrop_masked = np.multiply(np.array(imcrop),objmask[..., None].astype(np.bool))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [116]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      7\u001B[0m boundboxes \u001B[38;5;241m=\u001B[39m [_\u001B[38;5;241m.\u001B[39mbbox \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m regionprops]\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m objID, boundbox \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(boundboxes):\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;66;03m#crop at the boundaries\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m     objmask \u001B[38;5;241m=\u001B[39m  \u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabeled_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m     objmask[objmask \u001B[38;5;241m!=\u001B[39m objID \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     13\u001B[0m     objmask[objmask \u001B[38;5;241m==\u001B[39m objID \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m=\u001B[39m classid\u001B[38;5;66;03m#this field was class id\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\wsi_analysis\\lib\\copy.py:153\u001B[0m, in \u001B[0;36mdeepcopy\u001B[1;34m(x, memo, _nil)\u001B[0m\n\u001B[0;32m    151\u001B[0m copier \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__deepcopy__\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    152\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 153\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m     reductor \u001B[38;5;241m=\u001B[39m dispatch_table\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#labeled_map = measure.label(annotation_resized_arr)\n",
    "for classid in iter_order:\n",
    "    #get only the region with the particular class id\n",
    "    class_annotation = annotation_resized_arr == classid\n",
    "    labeled_map = measure.label(class_annotation)\n",
    "    regionprops = measure.regionprops(labeled_map)\n",
    "    boundboxes = [_.bbox for _ in regionprops]\n",
    "\n",
    "    for objID, boundbox in enumerate(boundboxes):\n",
    "        #crop at the boundaries\n",
    "        objmask =  deepcopy(labeled_map)\n",
    "        objmask[objmask != objID + 1] = 0\n",
    "        objmask[objmask == objID + 1]= classid#this field was class id\n",
    "        objmask = objmask[boundbox[0]:boundbox[2], boundbox[1]:boundbox[3]]\n",
    "        h, w = boundbox[2] - boundbox[0], boundbox[3] - boundbox[1]\n",
    "        #read cropped region\n",
    "        imcrop = wsi.read_region(location=(round(boundbox[1]*rsf), round(boundbox[0]*rsf)), level=target_level, size=(w, h))\n",
    "        imcrop_masked = np.multiply(np.array(imcrop),objmask[..., None].astype(np.bool))\n",
    "\n",
    "        #create two folders (for crop and mask)\n",
    "        dirName1 = r'\\\\fatherserverdw\\kyuex\\great\\mask and crop\\{}imcrop'.format(folder_name)\n",
    "        dirName2 = r'\\\\fatherserverdw\\kyuex\\great\\mask and crop\\{}mskcrop'.format(folder_name)\n",
    "\n",
    "        if not os.path.exists(dirName1):\n",
    "            os.mkdir(dirName1)\n",
    "\n",
    "        if not os.path.exists(dirName2):\n",
    "            os.mkdir(dirName2)\n",
    "\n",
    "        Image.fromarray((imcrop_masked).astype(np.uint8)).save(r'\\\\fatherserverdw\\kyuex\\great\\mask and crop\\{}imcrop\\class{}_obj{}.png'.format(folder_name,classid, objID))\n",
    "        Image.fromarray(objmask.astype(np.uint8)).save(r'\\\\fatherserverdw\\kyuex\\great\\mask and crop\\{}mskcrop\\classnew{}_obj{}.png'.format(folder_name,classid, objID))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#---unedited---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this code is just for only one object in each class, don't use\n",
    "labeled_map = measure.label(annotation_resized_arr.astype(np.bool))\n",
    "regionprops = measure.regionprops(labeled_map)\n",
    "boundboxes = [_.bbox for _ in regionprops]\n",
    "for objID, boundbox in enumerate(boundboxes): #iterate each connected object on deeplab mask\n",
    "    connected_obj_mask = labeled_map == objID +1\n",
    "    dlmask = np.multiply(annotation_resized_arr,connected_obj_mask)\n",
    "    dlmask = dlmask[boundbox[0]:boundbox[2], boundbox[1]:boundbox[3]]\n",
    "    h, w = boundbox[2] - boundbox[0], boundbox[3] - boundbox[1]\n",
    "    imcrop = wsi.read_region(location=(round(boundbox[1]*rsf), round(boundbox[0]*rsf)), level=target_level, size=(w, h))\n",
    "    imcrop_masked = np.multiply(np.array(imcrop),dlmask[..., None].astype(np.bool))\n",
    "    Image.fromarray((imcrop_masked).astype(np.uint8)).save('imcrop/obj{}.png'.format(objID))\n",
    "    Image.fromarray(dlmask.astype(np.uint8)).save('mskcrop/obj{}.png'.format(objID))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# iterate each class and each annotation object to make a crop\n",
    "# for classid in iter_order:\n",
    "#     annotation2crop = np.zeros_like(annotation)\n",
    "#     #all annotation for the current class id\n",
    "#     annotation2crop[np.array(annotation) == classid] = 1\n",
    "#     labeled_map = measure.label(annotation2crop)\n",
    "#     #regionprops has properties of the label\n",
    "#     regionprops = measure.regionprops(labeled_map)\n",
    "#     #bounboxes is a tuple, (min_row, min_col, max_row, max_col)\n",
    "#     boundboxes = list()\n",
    "#     for region in regionprops:\n",
    "#         boundboxes.append(region.bbox)\n",
    "#\n",
    "#     for objID, boundbox in enumerate(boundboxes):\n",
    "#         #crop at the boundaries\n",
    "#         objmask = deepcopy(labeled_map)\n",
    "#         objmask[objmask != objID + 1] = 0\n",
    "#         objmask[objmask == objID + 1] = 1\n",
    "#\n",
    "#         objmask = objmask[boundbox[0]:boundbox[2], boundbox[1]:boundbox[3]]\n",
    "#         h, w = boundbox[2] - boundbox[0], boundbox[3] - boundbox[1]\n",
    "#\n",
    "#         #read cropped region\n",
    "#         imcrop = wsi.read_region(location=(boundbox[1], boundbox[0]), level=target_level, size=(w, h)).convert(\n",
    "#             'RGB')  #use level 2, more zoomed in\n",
    "#         imcrop = np.array(imcrop)\n",
    "#\n",
    "#         #create mask to crop out the extra space around the annotation\n",
    "#         objmask = deepcopy(labeled_map)\n",
    "#         objmask[objmask != 1] = 0\n",
    "#         objmask[objmask == 1] = 1\n",
    "#         #boundbox = [round(_/10) for _ in boundbox] #downsize by 10\n",
    "#         objmask2 = objmask[boundbox[0]:boundbox[2],\n",
    "#                    boundbox[1]:boundbox[3]]  #crop out the objmask2, typecast to integer\n",
    "#\n",
    "#         #enlarge objmask2 by 10 to get objmask3, take transpose of objmask3 to get objmask4\n",
    "#         #new_shape = list(objmask2.shape)\n",
    "#         #new_shape = [_*10 for _ in new_shape]\n",
    "#         #objmask3 = cv2.resize(objmask2.astype(np.float),tuple(new_shape), interpolation = cv2.INTER_NEAREST)#NEAREST preserves pixel value\n",
    "#\n",
    "#         #find boundary of objmask3, use cv2 contour\n",
    "#         #this gives you a list of bounding pixels\\\n",
    "#         #objmask3_img = Image.fromarray(objmask3.astype(np.uint8))\n",
    "#\n",
    "#         #objmask3_array = np.asarray(objmask3_img)\n",
    "#\n",
    "#         #this gives me a list of tuples\n",
    "#         #contour, hierarchy = cv2.findContours(objmask3_array, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "#\n",
    "#         #loop through each pixel in bound_objmask3\n",
    "#         #contour = np.array(contour)\n",
    "#         #contour = contour.squeeze()\n",
    "#\n",
    "#         #for count,pix1 in enumerate(contour):\n",
    "#         # while(count < len(contour) - 2): #is this right??\n",
    "#         # for i in range(1, 5): #set n = 2 (split into two equal parts)\n",
    "#         #   a = float((i) / 5)        # rescale 0 < i < n --> 0 < a < 1\n",
    "#         #  x3 = (1 - a) * pix1[0] + a * contour[count+1][0]    # interpolate x coordinate\n",
    "#         #   y3= (1 - a) * pix1[1] + a * contour[count+1][1]   # interpolate y coordinate\n",
    "#         #   objmask3[int(x3),int(y3)] = 1 #add equidistant pixel to objmask3\n",
    "#\n",
    "#         objmask4 = np.dstack([objmask2.transpose()] * 3)  #change shape of objmask3\n",
    "#\n",
    "#         objmask2[objmask2 == 1] = classid  #Question: what does this do again?\n",
    "#\n",
    "#         #crop out the area outside the annotation using multiplication\n",
    "#         imcrop_masked = np.multiply(objmask4, imcrop)\n",
    "#\n",
    "#         Image.fromarray((imcrop_masked).astype(np.uint8)).save('imcrop/class{}_obj{}.png'.format(classid, objID))\n",
    "#         Image.fromarray(objmask2.astype(np.uint8)).save('mskcrop/classnew{}_obj{}.png'.format(classid, objID))\n",
    "\n",
    "        #equidistant point\n",
    "        #find bounding pixels, find point between neighboring pixels, add that pixel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}