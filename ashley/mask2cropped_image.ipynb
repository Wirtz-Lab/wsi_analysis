{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import os\n",
    "from openslide import OpenSlide\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS=None\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "from copy import deepcopy\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# open both wsi and annotation map\n",
    "wsi_src = os.path.expanduser(r'\\\\fatherserverdw\\Q\\research\\images\\CLUE\\3D study\\he\\c1')\n",
    "wsi_fn = '1C1.ndpi'\n",
    "wsipath = os.path.join(wsi_src, wsi_fn)\n",
    "\n",
    "#anno_src = os.path.expanduser(r'\\\\Users\\kyuha\\PycharmProjects\\wsi_analysis\\ashley')\n",
    "#anno_fn = '1C1temp.png'\n",
    "#annotation_map_path = os.path.join(anno_src, anno_fn)\n",
    "wsi = OpenSlide(wsipath)\n",
    "annotation = Image.open('1C1.png')  #40X resolution\n",
    "iter_order = [2,10,5,4,6,11,7,9,8,12,3,1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "target_level = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "rsf = wsi.level_downsamples[target_level]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "target_dim = wsi.level_dimensions[target_level]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "annotation_resized = annotation.resize(target_dim,resample=0) #this step is a bottleneck"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "annotation_resized_arr = np.array(annotation_resized)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "labeled_map = measure.label(annotation_resized_arr.astype(np.bool))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "regionprops = measure.regionprops(labeled_map)\n",
    "boundboxes = [_.bbox for _ in regionprops]\n",
    "for objID, boundbox in enumerate(boundboxes): #iterate each connected object on deeplab mask\n",
    "    connected_obj_mask = labeled_map == objID +1\n",
    "    dlmask = np.multiply(annotation_resized_arr,connected_obj_mask)\n",
    "    dlmask = dlmask[boundbox[0]:boundbox[2], boundbox[1]:boundbox[3]]\n",
    "    h, w = boundbox[2] - boundbox[0], boundbox[3] - boundbox[1]\n",
    "    imcrop = wsi.read_region(location=(round(boundbox[1]*rsf), round(boundbox[0]*rsf)), level=target_level, size=(w, h))\n",
    "    imcrop_masked = np.multiply(np.array(imcrop),dlmask[..., None].astype(np.bool))\n",
    "    Image.fromarray((imcrop_masked).astype(np.uint8)).save('imcrop/obj{}.png'.format(objID))\n",
    "    Image.fromarray(dlmask.astype(np.uint8)).save('mskcrop/obj{}.png'.format(objID))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'imcrop/class2_obj0.png'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-41-019331204c7c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     18\u001B[0m         \u001B[0mimcrop\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mwsi\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_region\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlocation\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mround\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mboundbox\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mrsf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mround\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mboundbox\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mrsf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtarget_level\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mh\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[0mimcrop_masked\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmultiply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimcrop\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mobjmask\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m...\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbool\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m         \u001B[0mImage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfromarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimcrop_masked\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muint8\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'imcrop/class{}_obj{}.png'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclassid\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mobjID\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     21\u001B[0m         \u001B[0mImage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfromarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobjmask\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muint8\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'mskcrop/classnew{}_obj{}.png'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclassid\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mobjID\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\digital_pathology\\lib\\site-packages\\PIL\\Image.py\u001B[0m in \u001B[0;36msave\u001B[1;34m(self, fp, format, **params)\u001B[0m\n\u001B[0;32m   2207\u001B[0m                 \u001B[0mfp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbuiltins\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"r+b\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2208\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2209\u001B[1;33m                 \u001B[0mfp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbuiltins\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"w+b\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2210\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2211\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mOSError\u001B[0m: [Errno 22] Invalid argument: 'imcrop/class2_obj0.png'"
     ]
    }
   ],
   "source": [
    "#labeled connected objects in deeplab mask\n",
    "#iterate each connected object and make the deeplab mask\n",
    "\n",
    "for classid in iter_order:\n",
    "    #all annotation for the current class id\n",
    "    annotation2crop = annotation_resized == classid\n",
    "    #label this class object\n",
    "    labeled_map = measure.label(annotation2crop)\n",
    "    #regionprops has properties of the label\n",
    "    regionprops = measure.regionprops(labeled_map)\n",
    "    #bounboxes is a tuple, (min_row, min_col, max_row, max_col)\n",
    "    boundboxes = [_.bbox for _ in regionprops]\n",
    "    for objID, boundbox in enumerate(boundboxes):\n",
    "        #crop at the boundaries\n",
    "        objmask =  deepcopy(labeled_map)\n",
    "        objmask[objmask != objID + 1] = 0\n",
    "        objmask[objmask == objID + 1]= classid#this field was class id\n",
    "        objmask = objmask[boundbox[0]:boundbox[2], boundbox[1]:boundbox[3]]\n",
    "        h, w = boundbox[2] - boundbox[0], boundbox[3] - boundbox[1]\n",
    "        #read cropped region\n",
    "        imcrop = wsi.read_region(location=(round(boundbox[1]*rsf), round(boundbox[0]*rsf)), level=target_level, size=(w, h))\n",
    "        imcrop_masked = np.multiply(np.array(imcrop),objmask[..., None].astype(np.bool))\n",
    "        Image.fromarray((imcrop_masked).astype(np.uint8)).save('imcrop/class{}_obj{}.png'.format(classid, objID))\n",
    "        Image.fromarray(objmask.astype(np.uint8)).save('mskcrop/classnew{}_obj{}.png'.format(classid, objID))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# iterate each class and each annotation object to make a crop\n",
    "# for classid in iter_order:\n",
    "#     annotation2crop = np.zeros_like(annotation)\n",
    "#     #all annotation for the current class id\n",
    "#     annotation2crop[np.array(annotation) == classid] = 1\n",
    "#     labeled_map = measure.label(annotation2crop)\n",
    "#     #regionprops has properties of the label\n",
    "#     regionprops = measure.regionprops(labeled_map)\n",
    "#     #bounboxes is a tuple, (min_row, min_col, max_row, max_col)\n",
    "#     boundboxes = list()\n",
    "#     for region in regionprops:\n",
    "#         boundboxes.append(region.bbox)\n",
    "#\n",
    "#     for objID, boundbox in enumerate(boundboxes):\n",
    "#         #crop at the boundaries\n",
    "#         objmask = deepcopy(labeled_map)\n",
    "#         objmask[objmask != objID + 1] = 0\n",
    "#         objmask[objmask == objID + 1] = 1\n",
    "#\n",
    "#         objmask = objmask[boundbox[0]:boundbox[2], boundbox[1]:boundbox[3]]\n",
    "#         h, w = boundbox[2] - boundbox[0], boundbox[3] - boundbox[1]\n",
    "#\n",
    "#         #read cropped region\n",
    "#         imcrop = wsi.read_region(location=(boundbox[1], boundbox[0]), level=target_level, size=(w, h)).convert(\n",
    "#             'RGB')  #use level 2, more zoomed in\n",
    "#         imcrop = np.array(imcrop)\n",
    "#\n",
    "#         #create mask to crop out the extra space around the annotation\n",
    "#         objmask = deepcopy(labeled_map)\n",
    "#         objmask[objmask != 1] = 0\n",
    "#         objmask[objmask == 1] = 1\n",
    "#         #boundbox = [round(_/10) for _ in boundbox] #downsize by 10\n",
    "#         objmask2 = objmask[boundbox[0]:boundbox[2],\n",
    "#                    boundbox[1]:boundbox[3]]  #crop out the objmask2, typecast to integer\n",
    "#\n",
    "#         #enlarge objmask2 by 10 to get objmask3, take transpose of objmask3 to get objmask4\n",
    "#         #new_shape = list(objmask2.shape)\n",
    "#         #new_shape = [_*10 for _ in new_shape]\n",
    "#         #objmask3 = cv2.resize(objmask2.astype(np.float),tuple(new_shape), interpolation = cv2.INTER_NEAREST)#NEAREST preserves pixel value\n",
    "#\n",
    "#         #find boundary of objmask3, use cv2 contour\n",
    "#         #this gives you a list of bounding pixels\\\n",
    "#         #objmask3_img = Image.fromarray(objmask3.astype(np.uint8))\n",
    "#\n",
    "#         #objmask3_array = np.asarray(objmask3_img)\n",
    "#\n",
    "#         #this gives me a list of tuples\n",
    "#         #contour, hierarchy = cv2.findContours(objmask3_array, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "#\n",
    "#         #loop through each pixel in bound_objmask3\n",
    "#         #contour = np.array(contour)\n",
    "#         #contour = contour.squeeze()\n",
    "#\n",
    "#         #for count,pix1 in enumerate(contour):\n",
    "#         # while(count < len(contour) - 2): #is this right??\n",
    "#         # for i in range(1, 5): #set n = 2 (split into two equal parts)\n",
    "#         #   a = float((i) / 5)        # rescale 0 < i < n --> 0 < a < 1\n",
    "#         #  x3 = (1 - a) * pix1[0] + a * contour[count+1][0]    # interpolate x coordinate\n",
    "#         #   y3= (1 - a) * pix1[1] + a * contour[count+1][1]   # interpolate y coordinate\n",
    "#         #   objmask3[int(x3),int(y3)] = 1 #add equidistant pixel to objmask3\n",
    "#\n",
    "#         objmask4 = np.dstack([objmask2.transpose()] * 3)  #change shape of objmask3\n",
    "#\n",
    "#         objmask2[objmask2 == 1] = classid  #Question: what does this do again?\n",
    "#\n",
    "#         #crop out the area outside the annotation using multiplication\n",
    "#         imcrop_masked = np.multiply(objmask4, imcrop)\n",
    "#\n",
    "#         Image.fromarray((imcrop_masked).astype(np.uint8)).save('imcrop/class{}_obj{}.png'.format(classid, objID))\n",
    "#         Image.fromarray(objmask2.astype(np.uint8)).save('mskcrop/classnew{}_obj{}.png'.format(classid, objID))\n",
    "\n",
    "        #equidistant point\n",
    "        #find bounding pixels, find point between neighboring pixels, add that pixel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}